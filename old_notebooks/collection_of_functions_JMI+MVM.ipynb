{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collection_of_functions_JMI+MVM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kBzlzWjALWPH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jirvingphd/my_data_science_notes/blob/master/collection_of_functions_JMI%2BMVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SBhJ_lZ1PAJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mod1Project EDA Functions"
      ]
    },
    {
      "metadata": {
        "id": "j2ce0GJ4G6LQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def multiplot"
      ]
    },
    {
      "metadata": {
        "id": "1MvjuUrnO49G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MULTIPLOT\n",
        "from string import ascii_letters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def multiplot(df):\n",
        "    \"\"\"Plots results from df.corr() in a correlation heat map for multicollinearity.\n",
        "    Returns fig, ax objects\"\"\"\n",
        "    sns.set(style=\"white\")\n",
        "\n",
        "    # Compute the correlation matrix\n",
        "    corr = df.corr()\n",
        "\n",
        "    # Generate a mask for the upper triangle\n",
        "    mask = np.zeros_like(corr, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "    # Set up the matplotlib figure\n",
        "    f, ax = plt.subplots(figsize=(16, 16))\n",
        "\n",
        "    # Generate a custom diverging colormap\n",
        "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "    # Draw the heatmap with the mask and correct aspect ratio\n",
        "    sns.heatmap(corr, mask=mask, annot=True, cmap=cmap, center=0,\n",
        "                \n",
        "    square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "    return f, ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-NNitpsHEyD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def plot_hist_scat_sns [USE ME!!!!]"
      ]
    },
    {
      "metadata": {
        "id": "HkbFmEd2PJG0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plots histogram and scatter (vs price) side by side\n",
        "# Plots histogram and scatter (vs price) side by side\n",
        "def plot_hist_scat_sns(df, target='index'):\n",
        "    \"\"\"Plots seaborne distplots and regplots for columns im datamframe vs target.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): DataFrame.describe() columns will be used. \n",
        "    target = name of column containing target variable.assume first coluumn. \n",
        "    \n",
        "    Returns:\n",
        "    Figures for each column vs target with 2 subplots.\n",
        "   \"\"\"\n",
        "    import matplotlib.ticker as mtick\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    \n",
        "    with plt.style.context(('dark_background')):\n",
        "        ###  DEFINE AESTHETIC CUSTOMIZATIONS  -------------------------------##\n",
        "\n",
        "\n",
        "#         plt.style.use('dark_background')\n",
        "        figsize=(9,7)\n",
        "\n",
        "        # Axis Label fonts\n",
        "        fontTitle = {'fontsize': 14,\n",
        "                   'fontweight': 'bold',\n",
        "                    'fontfamily':'serif'}\n",
        "\n",
        "        fontAxis = {'fontsize': 12,\n",
        "                   'fontweight': 'medium',\n",
        "                    'fontfamily':'serif'}\n",
        "\n",
        "        fontTicks = {'fontsize': 8,\n",
        "                   'fontweight':'medium',\n",
        "                    'fontfamily':'serif'}\n",
        "\n",
        "        # Formatting dollar sign labels\n",
        "        fmtPrice = '${x:,.0f}'\n",
        "        tickPrice = mtick.StrMethodFormatter(fmtPrice)\n",
        "\n",
        "\n",
        "        ###  PLOTTING ----------------------------- ------------------------ ##\n",
        "\n",
        "        # Loop through dataframe to plot\n",
        "        for column in df.describe():\n",
        "#             print(f'\\nCurrent column: {column}')\n",
        "\n",
        "            # Create figure with subplots for current column\n",
        "            fig, ax = plt.subplots(figsize=figsize, ncols=2, nrows=2)\n",
        "\n",
        "            ##  SUBPLOT 1 --------------------------------------------------##\n",
        "            i,j = 0,0\n",
        "            ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
        "\n",
        "            # Define graphing keyword dictionaries for distplot (Subplot 1)\n",
        "            hist_kws = {\"linewidth\": 1, \"alpha\": 1, \"color\": 'blue','edgecolor':'w'}\n",
        "            kde_kws = {\"color\": \"white\", \"linewidth\": 1, \"label\": \"KDE\"}\n",
        "\n",
        "            # Plot distplot on ax[i,j] using hist_kws and kde_kws\n",
        "            sns.distplot(df[column], norm_hist=True, kde=True,\n",
        "                         hist_kws = hist_kws, kde_kws = kde_kws,\n",
        "                         label=column+' histogram', ax=ax[i,j])\n",
        "\n",
        "\n",
        "            # Set x axis label\n",
        "            ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
        "\n",
        "            # Get x-ticks, rotate labels, and return\n",
        "            xticklab1 = ax[i,j].get_xticklabels(which = 'both')\n",
        "            ax[i,j].set_xticklabels(labels=xticklab1, fontdict=fontTicks, rotation=0)\n",
        "            ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "\n",
        "            # Set y-label \n",
        "            ax[i,j].set_ylabel('Density',fontdict=fontAxis)\n",
        "            yticklab1=ax[i,j].get_yticklabels(which='both')\n",
        "            ax[i,j].set_yticklabels(labels=yticklab1,fontdict=fontTicks)\n",
        "            ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "\n",
        "            # Set y-grid\n",
        "            ax[i, j].set_axisbelow(True)\n",
        "            ax[i, j].grid(axis='y',ls='--')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ##  SUBPLOT 2-------------------------------------------------- ##\n",
        "            i,j = 0,1\n",
        "            ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
        "\n",
        "            # Define the kwd dictionaries for scatter and regression line (subplot 2)\n",
        "            line_kws={\"color\":\"white\",\"alpha\":0.5,\"lw\":4,\"ls\":\":\"}\n",
        "            scatter_kws={'s': 2, 'alpha': 0.5,'marker':'.','color':'blue'}\n",
        "\n",
        "            # Plot regplot on ax[i,j] using line_kws and scatter_kws\n",
        "            sns.regplot(df[column], df[target], \n",
        "                        line_kws = line_kws,\n",
        "                        scatter_kws = scatter_kws,\n",
        "                        ax=ax[i,j])\n",
        "\n",
        "            # Set x-axis label\n",
        "            ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
        "\n",
        "             # Get x ticks, rotate labels, and return\n",
        "            xticklab2=ax[i,j].get_xticklabels(which='both')\n",
        "            ax[i,j].set_xticklabels(labels=xticklab2,fontdict=fontTicks, rotation=0)\n",
        "            ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "            # Set  y-axis label\n",
        "            ax[i,j].set_ylabel(target,fontdict=fontAxis)\n",
        "\n",
        "            # Get, set, and format y-axis Price labels\n",
        "            yticklab = ax[i,j].get_yticklabels()\n",
        "            ax[i,j].set_yticklabels(yticklab,fontdict=fontTicks)\n",
        "            ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "    #         ax[i,j].get_yaxis().set_major_formatter(tickPrice) \n",
        "\n",
        "            # Set y-grid\n",
        "            ax[i, j].set_axisbelow(True)\n",
        "            ax[i, j].grid(axis='y',ls='--')       \n",
        "\n",
        "            ## ---------- Final layout adjustments ----------- ##\n",
        "            # Deleted unused subplots \n",
        "            fig.delaxes(ax[1,1])\n",
        "            fig.delaxes(ax[1,0])\n",
        "\n",
        "            # Optimizing spatial layout\n",
        "            fig.tight_layout()\n",
        "            figtitle=column+'_dist_regr_plots.png'\n",
        "#             plt.savefig(figtitle)\n",
        "    return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdMC4IZpPZQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AXq6az6PaG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Outliers & Data Transformation\n"
      ]
    },
    {
      "metadata": {
        "id": "Jq_t_sfB1AQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "detect_outliers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sTc63KdeH4Sy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def detect_outliers"
      ]
    },
    {
      "metadata": {
        "id": "b89S82jSO-nF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tukey's method using IQR to eliminate \n",
        "def detect_outliers(df, n, features):\n",
        "    \"\"\"Uses Tukey's method to return outer of interquartile ranges to return indices if outliers in a dataframe.\n",
        "    Parameters:\n",
        "    df (DataFrame): DataFrane containing columns of features\n",
        "    n: default is 0, multiple outlier cutoff  \n",
        "    \n",
        "    Returns:\n",
        "    Index of outliers for .loc\n",
        "    \n",
        "    Examples:\n",
        "    Outliers_to_drop = detect_outliers(data,2,[\"col1\",\"col2\"]) Returning value\n",
        "    df.loc[Outliers_to_drop] # Show the outliers rows\n",
        "    data= data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n",
        "\"\"\"\n",
        "\n",
        "# Drop outliers    \n",
        "\n",
        "    outlier_indices = []\n",
        "    # iterate over features(columns)\n",
        "    for col in features:\n",
        "        \n",
        "        # 1st quartile (25%)\n",
        "        Q1 = np.percentile(df[col], 25)\n",
        "        # 3rd quartile (75%)\n",
        "        Q3 = np.percentile(df[col],75)\n",
        "        \n",
        "        # Interquartile range (IQR)\n",
        "        IQR = Q3 - Q1\n",
        "        # outlier step\n",
        "        outlier_step = 1.5 * IQR\n",
        "        \n",
        "        # Determine a list of indices of outliers for feature col\n",
        "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n",
        "        \n",
        "        # append the found outlier indices for col to the list of outlier indices \n",
        "        outlier_indices.extend(outlier_list_col)\n",
        "        \n",
        "        # select observations containing more than 2 outliers\n",
        "        outlier_indices = Counter(outlier_indices)        \n",
        "        multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
        "    return multiple_outliers \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpH90jjiPoiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# describe_outliers -- calls detect_outliers\n",
        "def describe_outliers(df):\n",
        "    \"\"\" Returns a new_df of outliers, and % outliers each col using detect_outliers.\n",
        "    \"\"\"\n",
        "    out_count = 0\n",
        "    new_df = pd.DataFrame(columns=['total_outliers', 'percent_total'])\n",
        "    for col in df.columns:\n",
        "        outies = detect_outliers(df[col])\n",
        "        out_count += len(outies) \n",
        "        new_df.loc[col] = [len(outies), round((len(outies)/len(df.index))*100, 2)]\n",
        "    new_df.loc['grand_total'] = [sum(new_df['total_outliers']), sum(new_df['percent_total'])]\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIBGj_jHPic0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "R5R59smnP4ae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mod 2 Project-Specific Functions"
      ]
    },
    {
      "metadata": {
        "id": "v-CYH4Q3F8LO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SQL"
      ]
    },
    {
      "metadata": {
        "id": "QqrpTr6GIBZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def get_col_info"
      ]
    },
    {
      "metadata": {
        "id": "_AuIQg3-F_dt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  get_col_info(col_name):\n",
        "    \"\"\"Gets the column names and data types from the alchamey inspector object.\n",
        "    Returns column_info dataframe of table details.\n",
        "    \"\"\"\n",
        "    col_list = inspector.get_columns(col_name)\n",
        "    \n",
        "    column_info = [['table','column','dtype']]\n",
        "    print(f'Table Name: {col_name}\\n')\n",
        "\n",
        "    for col in col_list:\n",
        "        column_info.append([str(col_name),col['name'], col['type']])\n",
        "        \n",
        "    df = list2df(column_info)\n",
        "    return column_info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJuN9iHiIEEW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def get_full_table_info"
      ]
    },
    {
      "metadata": {
        "id": "2Y4jWc70GDTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def  get_full_table_info(engine):\n",
        "    \"\"\"Gets the table names, their column namesand data types engine.\n",
        "    Returns column_info dataframe of table details.\n",
        "    \"\"\"\n",
        "    column_info = [['table','column','dtype']]\n",
        "    \n",
        "    list_tables= engine.table_names()\n",
        "    \n",
        "    for table in list_tables:\n",
        "        \n",
        "        col_list = inspector.get_columns(table)\n",
        "        \n",
        "        for col in col_list:\n",
        "            \n",
        "            column_info.append([str(table),col['name'], col['type'],col['']])\n",
        "            inspector.get_foreign_keys()\n",
        "    \n",
        "    df = list2df(column_info)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRRMN3JmIHxp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### How to: use sqlalchemy on Google Colab"
      ]
    },
    {
      "metadata": {
        "id": "dNuYzYIvZ2kW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Using sqlalchemy to import sql tables in google drive\n",
        "import sqlalchemy\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import Session, sessionmaker\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "filepath = '/content/drive/My Drive/Colab Notebooks/datasets/Northwind_small.sqlite'\n",
        "engine = create_engine('sqlite:///'+filepath,echo=True)\n",
        "inspector = inspect(engine);\n",
        "\n",
        "# df_employee = pd.read_sql_query(\"SELECT Id, Title, LastName, HireDate , BirthDate  FROM [EMPLOYEE]\", engine )\n",
        "# df_cust_ord = pd.read_sql_query(\"SELECT *FROM [Order] JOIN [Customer] ON [Customer].Id = [Order].CustomerId\", engine)\n",
        "print(inspector.get_table_names())\n",
        "\n",
        "\n",
        "\n",
        "#IMPORTING TABLES\n",
        "DB_Order = pd.read_sql_table('Order',engine);\n",
        "DB_OrderDetail = pd.read_sql_table('OrderDetail',engine);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCW4NaPfJf9C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Mod 2 Data Processing / Production"
      ]
    },
    {
      "metadata": {
        "id": "f71LKB4MJkYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### making month_dict for month # to name mapping"
      ]
    },
    {
      "metadata": {
        "id": "Hqjw-ph1JkHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#make list of month names (strings) \n",
        "months = ['jan','feb', 'mar', 'apr', 'may' , 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']#creating label names\n",
        "# month_code =\n",
        "month_dict = dict(zip( list(range(1,len(months)+1)),months)) # zip the two into a dictionary\n",
        "\n",
        "# MAP THE MONTH_DICT ONTO NEW COLUMN month_name\n",
        "df_price_geo['month_name'] = df_price_geo['month'].map(month_dict)\n",
        "df_price_geo['month_name'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dxk1nTXUIN3g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Separatig df into new vars based on discounts [Mike]"
      ]
    },
    {
      "metadata": {
        "id": "_dN5nGi46FlY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From mike, separateing into discounts by percetnage\n",
        "# dict and target for running through calc_effect_sizes\n",
        "disc_5 = np.array(df['Quantity'].loc[(df['Discount'] > 0) & (df['Discount'] <= 0.05)])\n",
        "disc_10 = np.array(df['Quantity'].loc[(df['Discount'] > 0.05) &(df['Discount'] <= 0.10)])\n",
        "disc_15 = np.array(df['Quantity'].loc[(df['Discount'] > 0.10) &(df['Discount'] <= 0.15)])\n",
        "disc_20 = np.array(df['Quantity'].loc[(df['Discount'] > 0.15) &(df['Discount'] <= 0.20)])\n",
        "disc_25 = np.array(df['Quantity'].loc[(df['Discount'] > 0.20) &(df['Discount'] <= 0.25)])\n",
        "samples_dict = {'disc_5':disc_5, 'disc_10':disc_10, 'disc_15':disc_15, 'disc_20':disc_20, 'disc_25':disc_25}\n",
        "full_array = np.array(df['Quantity'].loc[df['Discount'] == 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrQvku0YFDei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###def calc_product_price & def_ calc_order_total "
      ]
    },
    {
      "metadata": {
        "id": "Hke_SzR7pr9I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# James: 04/02/19 \n",
        "# Source of df = pd.read_sql_query(\"SELECT * FROM OrderDetail\",  engine)\n",
        "\n",
        "# Define calc_product_review to add product price column\n",
        "def calc_product_price(row):\n",
        "    price = row['UnitPrice']*(1-row['Discount'])*row['Quantity']\n",
        "    row['price'] = price\n",
        "    if row['Discount']>0:\n",
        "        row['OnSale'] = True\n",
        "    else:\n",
        "        row['OnSale'] = False\n",
        "    return row    \n",
        "\n",
        "# Use calc_order_total to fill in order_total column\n",
        "def calc_order_total(row,df):\n",
        "    order = row['OrderId']\n",
        "    df_temp = df.groupby('OrderId').get_group(order)\n",
        "\n",
        "    \n",
        "    if any(df_temp['OnSale']):\n",
        "        row['discounted_order'] = True\n",
        "    else:\n",
        "        row['discounted_order'] = False\n",
        "    \n",
        "    order_total = df_temp['price'].sum()\n",
        "    row['order_total'] = order_total\n",
        "    \n",
        "    return row\n",
        "# Apply calc_product_price to every row \n",
        "df_price = df.apply(lambda x: calc_product_price(x),axis=1)\n",
        "# df_price['order_total'] = None\n",
        "\n",
        "\n",
        "# Apply_calc_order_total to every row\n",
        "df_price = df_price.apply(lambda x: calc_order_total(x,df_price), axis=1)  \n",
        "df_price.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQiob34IJvNp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Saving hypothesis 3 dataframes to csv for Tableau"
      ]
    },
    {
      "metadata": {
        "id": "-J6oQ3jvJzjU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Ssave df_price_Geo \n",
        "save = input(prompt='Would you like to export the dataframe above? (y/n)\\n')\n",
        "if save.lower()=='y':\n",
        "    filename ='df_H3_price_w_dates_products.csv'\n",
        "    df_H3_price_w_dates_products = df_price_geo.copy()\n",
        "    df_H3_price_w_dates_products.to_csv(filename)\n",
        "    print(f'df_price exported and saved as {filename}...')\n",
        "    print(f'if you are running this on Colab:...\\nOpen File sidebar, click Refresh, right click on {filename} to Download.')\n",
        "    \n",
        "    filename ='df_H3_price_w_dates_orders.csv'\n",
        "    df_H3_price_w_dates_orders = df_H3_price_w_dates_products.drop_duplicates(subset=['OrderId'])\n",
        "    df_H3_price_w_dates_orders.to_csv(filename)\n",
        "    print(f'if you are running this on Colab:...\\nOpen File sidebar, click Refresh, right click on {filename} to Download.')\n",
        "\n",
        "else:\n",
        "    print('No .csv exported.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dk6mURRPuaO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Testing Statistics"
      ]
    },
    {
      "metadata": {
        "id": "Z6Z0vGBeGKb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Cohen's d\n",
        "def Cohen_d(group1, group2):\n",
        "    '''Compute Cohen's d.\n",
        "    # group1: Series or NumPy array\n",
        "    # group2: Series or NumPy array\n",
        "    # returns a floating point number \n",
        "    '''\n",
        "    diff = group1.mean() - group2.mean()\n",
        "\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1 = group1.var()\n",
        "    var2 = group2.var()\n",
        "\n",
        "    # Calculate the pooled threshold as shown earlier\n",
        "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
        "    \n",
        "    # Calculate Cohen's d statistic\n",
        "    d = diff / np.sqrt(pooled_var)\n",
        "    \n",
        "    return d\n",
        "\n",
        "\n",
        "def plot_pdfs(cohen_d=2):\n",
        "    \"\"\"Plot PDFs for distributions that differ by some number of stds.\n",
        "    \n",
        "    cohen_d: number of standard deviations between the means\n",
        "    \"\"\"\n",
        "    group1 = scipy.stats.norm(0, 1)\n",
        "    group2 = scipy.stats.norm(cohen_d, 1)\n",
        "    xs, ys = evaluate_PDF(group1)\n",
        "    pyplot.fill_between(xs, ys, label='Group1', color='#ff2289', alpha=0.7)\n",
        "\n",
        "    xs, ys = evaluate_PDF(group2)\n",
        "    pyplot.fill_between(xs, ys, label='Group2', color='#376cb0', alpha=0.7)\n",
        "    \n",
        "    o, s = overlap_superiority(group1, group2)\n",
        "    print('overlap', o)\n",
        "    print('superiority', s)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_skDidJFQTbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# DEFINING FUNCTION \n",
        "#data_in={'name':data}\n",
        "def normtest_results(dict_data):\n",
        "\n",
        "    results_normtest_shap = [['DataIn','Test','stat','p']]\n",
        "    results_normtest_dagp = [['DataIn','Test','stat','p']]\n",
        "\n",
        "    for key,val in dict_data.items():\n",
        "\n",
        "        data_in = val\n",
        "        name = key\n",
        "        test = 'Shapiro'\n",
        "        stat, p = shapiro(data_in)\n",
        "        results_normtest_shap.append([name , test, stat , p ])\n",
        "        test = 'D’Agostino’s'\n",
        "        stat, p = normaltest(data_in)\n",
        "        results_normtest_dagp.append([name,test,stat, p])\n",
        "\n",
        "    results_normtest = pd.concat([list2df(results_normtest_shap), list2df(results_normtest_dagp)]) \n",
        "    \n",
        "    return results_normtest, list2df(results_normtest_shap),list2df(results_normtest_dagp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-MkYBhKolY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from Mike: 04/02/19\n",
        "def overlap_superiority(group1, group2, prints=False):\n",
        "  \"\"\"Calculates the overlap and superiority of two samples,\n",
        "    tailored for small populatioin sizes\n",
        "    group1 and group2 are np.arrays of 1 dimension\n",
        "  \"\"\"\n",
        "  #make sure both samples are of the same size so they can be zipped\n",
        "  if len(group1) < len(group2):\n",
        "    group2 = np.random.choice(group2, len(group1))\n",
        "  \n",
        "  elif len(group1) > len(group2):\n",
        "    group1 = np.random.choice(group1, len(group2))\n",
        "\n",
        "  # Identify the threshold between samples\n",
        "  thresh = (group1.mean() + group2.mean()) / 2\n",
        "  if prints == True: \n",
        "    print('Threshold:',thresh)\n",
        "  \n",
        "  # Calculate no. of values above and below for group 1 and group 2 respectively\n",
        "  above = sum(group1 < thresh)\n",
        "  below = sum(group2> thresh)\n",
        "  \n",
        "  # Calculate the overlap\n",
        "  overlap = (above + below) / len(group1)\n",
        "  \n",
        "  # Calculate probability of superiority\n",
        "  superiority = sum(x > y for x, y in zip(group1, group2)) / len(group1)\n",
        "  if prints == True:\n",
        "    print('Overlap:',overlap,'\\n''Superiority:', superiority)\n",
        "  \n",
        "  return overlap, superiority"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "opCXK5sg5IE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_effect_sizes(target, samples, prints=False):\n",
        "  \"\"\"target is the sample to be compared against, an np. array\n",
        "     samples is a dict. of np.arrays to compare against target\n",
        "     if prints = True, prints out results, otherwise just returns dict\n",
        "     of values.\n",
        "  \"\"\"\n",
        "  effect_dict = {}\n",
        "  for k, v in samples.items():\n",
        "    \n",
        "    if prints == True:\n",
        "      print(f'Effect of sample size for {k}, target:')\n",
        "      effect = overlap_superiority(v, target, prints=True)\n",
        "      print('\\n')\n",
        "      \n",
        "    else:\n",
        "      effect = overlap_superiority(v, target)\n",
        "    \n",
        "    effect_dict[k] = {'overlap':effect[0], 'superiority':effect[1]}\n",
        "    \n",
        "  return effect_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UC3jQLf5Fn0l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cE9MMup_Fno-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ZBLJMLCvECaL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### How to Run Tukey's tests and turn results into a dataframe"
      ]
    },
    {
      "metadata": {
        "id": "ASTzobihD_Ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing tukey's test\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukey\n",
        "\n",
        "# Defome the dataframe containing column of interest and group labels. \n",
        "df_test_hypothesis = df_year_orders[['order_total','month_name','week_day']]\n",
        "grp_labels = df_test_hypothesis['month_name']\n",
        "\n",
        "\n",
        "# Run tukey's test\n",
        "tukey_results =tukey(df_test_hypothesis['order_total'], grp_labels, 0.05)\n",
        "\n",
        "\n",
        "# Save the results into a dataframe\n",
        "dfH_tukey = pd.DataFrame(data=tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0])\n",
        "dfH_tukey\n",
        "# dfH_tukey.loc[dfH_tukey['reject']==True] # To show just significant results."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBzlzWjALWPH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SHORT PIPELINE FOR HYPOTHESIS TESTING"
      ]
    },
    {
      "metadata": {
        "id": "hwvBZywE0V0B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Aim 2.1: Test for Normality"
      ]
    },
    {
      "metadata": {
        "id": "gqiBjl0W4SP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "H3_tests = [['Group:','TestName','Test Purpose','stat','p','sig?']  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34ds8zvRz-X7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import normaltest\n",
        "\n",
        "for month,  df  in dict_to_test.items(): #month = key, df = values\n",
        "\n",
        "    arrA = dict_to_test[month]['order_total']\n",
        "\n",
        "    #1. Test for normality\n",
        "    test_purpose = 'Normality'\n",
        "    test_to_run = 'normaltest'\n",
        "\n",
        "    arrA = np.array(arrA)\n",
        "    statA, pA = eval(test_to_run)(arrA)\n",
        "\n",
        "    H3_tests.append([month, test_to_run, test_purpose ,statA, pA, pA<0.05])\n",
        "    \n",
        "arrB = np.array(df_year_orders['order_total'])\n",
        "stat, p = eval(test_to_run)(arrB)\n",
        "H3_tests.append(['Total Pop', test_to_run, test_purpose,stat, p,p<0.05])\n",
        "\n",
        "\n",
        "H3_results_norm = list2df(H3_tests)\n",
        "H3_results_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNlFwil16GUb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Aim 2.2: Test for Homogneity of Variance\n",
        "- Levenes Test"
      ]
    },
    {
      "metadata": {
        "id": "WYGU5I1f6K2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene\n",
        "\n",
        "for month,  df  in dict_to_test.items(): #month = key, df = values\n",
        "\n",
        "    arrA = dict_to_test[month]['order_total']\n",
        "    arrB = df_year_orders[df_year_orders['month_name']!= month]['order_total']\n",
        "    #1. Test for normality\n",
        "    test_to_run = 'levene'\n",
        "    test_purpose = 'Equal Variance'\n",
        "\n",
        "    arrA = np.array(arrA)\n",
        "    arrB = np.array(arrB)\n",
        "\n",
        "    stat, p = eval(test_to_run)(arrA,arrB,center='median')\n",
        "    \n",
        "    H3_tests.append([f'{month} vs. Other Months', test_to_run, test_purpose ,stat, p, p<0.05])\n",
        "\n",
        "\n",
        "list2df(H3_tests)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "azg_e4Sjylcg"
      },
      "cell_type": "markdown",
      "source": [
        "#### Use Tukey's Pairwise Multiple Comparison test.\n",
        "```statsmodels.stats.multicomp.pairwise_tukeyhsd```"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3ef2272d-5a31-48b9-e449-bbb6135adc86",
        "id": "l-icO2sgylch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1866
        }
      },
      "cell_type": "code",
      "source": [
        "# Importing tukey's test\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukey\n",
        "\n",
        "# Defome the dataframe containing column of interest and group labels. \n",
        "df_test_hypothesis = df_year_orders[['order_total','month_name','week_day']]\n",
        "grp_labels = df_test_hypothesis['month_name']\n",
        "\n",
        "\n",
        "# Run tukey's test\n",
        "tukey_results =tukey(df_test_hypothesis['order_total'], grp_labels, 0.05)\n",
        "\n",
        "\n",
        "# Save the results into a dataframe\n",
        "dfH_tukey = pd.DataFrame(data=tukey_results._results_table.data[1:], columns=tukey_results._results_table.data[0])\n",
        "dfH_tukey\n",
        "# dfH_tukey.loc[dfH_tukey['reject']==True] # To show just significant results."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group1</th>\n",
              "      <th>group2</th>\n",
              "      <th>meandiff</th>\n",
              "      <th>lower</th>\n",
              "      <th>upper</th>\n",
              "      <th>reject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apr</td>\n",
              "      <td>aug</td>\n",
              "      <td>-429.4049</td>\n",
              "      <td>-1421.7047</td>\n",
              "      <td>562.8950</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apr</td>\n",
              "      <td>dec</td>\n",
              "      <td>-207.6797</td>\n",
              "      <td>-1111.0347</td>\n",
              "      <td>695.6754</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apr</td>\n",
              "      <td>feb</td>\n",
              "      <td>-22.6780</td>\n",
              "      <td>-913.5247</td>\n",
              "      <td>868.1687</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apr</td>\n",
              "      <td>jan</td>\n",
              "      <td>82.7094</td>\n",
              "      <td>-793.8885</td>\n",
              "      <td>959.3073</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apr</td>\n",
              "      <td>jul</td>\n",
              "      <td>-249.8789</td>\n",
              "      <td>-1259.4613</td>\n",
              "      <td>759.7034</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>apr</td>\n",
              "      <td>jun</td>\n",
              "      <td>-472.0174</td>\n",
              "      <td>-1727.6696</td>\n",
              "      <td>783.6348</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>apr</td>\n",
              "      <td>mar</td>\n",
              "      <td>-291.8645</td>\n",
              "      <td>-1133.0197</td>\n",
              "      <td>549.2908</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>apr</td>\n",
              "      <td>may</td>\n",
              "      <td>-116.3951</td>\n",
              "      <td>-1188.8343</td>\n",
              "      <td>956.0440</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>apr</td>\n",
              "      <td>nov</td>\n",
              "      <td>-173.3675</td>\n",
              "      <td>-1160.2354</td>\n",
              "      <td>813.5004</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>apr</td>\n",
              "      <td>oct</td>\n",
              "      <td>-54.9710</td>\n",
              "      <td>-1016.8412</td>\n",
              "      <td>906.8993</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>apr</td>\n",
              "      <td>sep</td>\n",
              "      <td>-317.2668</td>\n",
              "      <td>-1298.8553</td>\n",
              "      <td>664.3217</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>aug</td>\n",
              "      <td>dec</td>\n",
              "      <td>221.7252</td>\n",
              "      <td>-827.0696</td>\n",
              "      <td>1270.5199</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>aug</td>\n",
              "      <td>feb</td>\n",
              "      <td>406.7269</td>\n",
              "      <td>-631.3136</td>\n",
              "      <td>1444.7673</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>aug</td>\n",
              "      <td>jan</td>\n",
              "      <td>512.1143</td>\n",
              "      <td>-513.7239</td>\n",
              "      <td>1537.9525</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>aug</td>\n",
              "      <td>jul</td>\n",
              "      <td>179.5259</td>\n",
              "      <td>-962.0417</td>\n",
              "      <td>1321.0935</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>aug</td>\n",
              "      <td>jun</td>\n",
              "      <td>-42.6125</td>\n",
              "      <td>-1406.6443</td>\n",
              "      <td>1321.4192</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>aug</td>\n",
              "      <td>mar</td>\n",
              "      <td>137.5404</td>\n",
              "      <td>-858.1816</td>\n",
              "      <td>1133.2624</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>aug</td>\n",
              "      <td>may</td>\n",
              "      <td>313.0097</td>\n",
              "      <td>-884.5068</td>\n",
              "      <td>1510.5262</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>aug</td>\n",
              "      <td>nov</td>\n",
              "      <td>256.0373</td>\n",
              "      <td>-865.4921</td>\n",
              "      <td>1377.5668</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>aug</td>\n",
              "      <td>oct</td>\n",
              "      <td>374.4339</td>\n",
              "      <td>-725.1635</td>\n",
              "      <td>1474.0313</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>aug</td>\n",
              "      <td>sep</td>\n",
              "      <td>112.1381</td>\n",
              "      <td>-1004.7487</td>\n",
              "      <td>1229.0249</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>dec</td>\n",
              "      <td>feb</td>\n",
              "      <td>185.0017</td>\n",
              "      <td>-768.3709</td>\n",
              "      <td>1138.3743</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>dec</td>\n",
              "      <td>jan</td>\n",
              "      <td>290.3891</td>\n",
              "      <td>-649.6829</td>\n",
              "      <td>1230.4611</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>dec</td>\n",
              "      <td>jul</td>\n",
              "      <td>-42.1993</td>\n",
              "      <td>-1107.3603</td>\n",
              "      <td>1022.9618</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>dec</td>\n",
              "      <td>jun</td>\n",
              "      <td>-264.3377</td>\n",
              "      <td>-1565.0967</td>\n",
              "      <td>1036.4213</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>dec</td>\n",
              "      <td>mar</td>\n",
              "      <td>-84.1848</td>\n",
              "      <td>-991.2976</td>\n",
              "      <td>822.9280</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>dec</td>\n",
              "      <td>may</td>\n",
              "      <td>91.2845</td>\n",
              "      <td>-1033.6320</td>\n",
              "      <td>1216.2011</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>dec</td>\n",
              "      <td>nov</td>\n",
              "      <td>34.3122</td>\n",
              "      <td>-1009.3447</td>\n",
              "      <td>1077.9691</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>dec</td>\n",
              "      <td>oct</td>\n",
              "      <td>152.7087</td>\n",
              "      <td>-867.3431</td>\n",
              "      <td>1172.7606</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>dec</td>\n",
              "      <td>sep</td>\n",
              "      <td>-109.5871</td>\n",
              "      <td>-1148.2533</td>\n",
              "      <td>929.0791</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>feb</td>\n",
              "      <td>oct</td>\n",
              "      <td>-32.2929</td>\n",
              "      <td>-1041.2842</td>\n",
              "      <td>976.6983</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>feb</td>\n",
              "      <td>sep</td>\n",
              "      <td>-294.5888</td>\n",
              "      <td>-1322.3947</td>\n",
              "      <td>733.2171</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>jan</td>\n",
              "      <td>jul</td>\n",
              "      <td>-332.5884</td>\n",
              "      <td>-1375.1533</td>\n",
              "      <td>709.9765</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>jan</td>\n",
              "      <td>jun</td>\n",
              "      <td>-554.7268</td>\n",
              "      <td>-1837.0480</td>\n",
              "      <td>727.5943</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>jan</td>\n",
              "      <td>mar</td>\n",
              "      <td>-374.5739</td>\n",
              "      <td>-1255.0437</td>\n",
              "      <td>505.8960</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>jan</td>\n",
              "      <td>may</td>\n",
              "      <td>-199.1046</td>\n",
              "      <td>-1302.6492</td>\n",
              "      <td>904.4401</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>jan</td>\n",
              "      <td>nov</td>\n",
              "      <td>-256.0769</td>\n",
              "      <td>-1276.6617</td>\n",
              "      <td>764.5078</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>jan</td>\n",
              "      <td>oct</td>\n",
              "      <td>-137.6804</td>\n",
              "      <td>-1134.1137</td>\n",
              "      <td>858.7529</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>jan</td>\n",
              "      <td>sep</td>\n",
              "      <td>-399.9762</td>\n",
              "      <td>-1415.4569</td>\n",
              "      <td>615.5045</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>jul</td>\n",
              "      <td>jun</td>\n",
              "      <td>-222.1384</td>\n",
              "      <td>-1598.7939</td>\n",
              "      <td>1154.5170</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>jul</td>\n",
              "      <td>mar</td>\n",
              "      <td>-41.9855</td>\n",
              "      <td>-1054.9316</td>\n",
              "      <td>970.9606</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>jul</td>\n",
              "      <td>may</td>\n",
              "      <td>133.4838</td>\n",
              "      <td>-1078.3922</td>\n",
              "      <td>1345.3598</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>jul</td>\n",
              "      <td>nov</td>\n",
              "      <td>76.5114</td>\n",
              "      <td>-1060.3377</td>\n",
              "      <td>1213.3606</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>jul</td>\n",
              "      <td>oct</td>\n",
              "      <td>194.9080</td>\n",
              "      <td>-920.3104</td>\n",
              "      <td>1310.1264</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>jul</td>\n",
              "      <td>sep</td>\n",
              "      <td>-67.3878</td>\n",
              "      <td>-1199.6571</td>\n",
              "      <td>1064.8814</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>jun</td>\n",
              "      <td>mar</td>\n",
              "      <td>180.1529</td>\n",
              "      <td>-1078.2054</td>\n",
              "      <td>1438.5113</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>jun</td>\n",
              "      <td>may</td>\n",
              "      <td>355.6222</td>\n",
              "      <td>-1067.7714</td>\n",
              "      <td>1779.0159</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>jun</td>\n",
              "      <td>nov</td>\n",
              "      <td>298.6499</td>\n",
              "      <td>-1061.4354</td>\n",
              "      <td>1658.7351</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>jun</td>\n",
              "      <td>oct</td>\n",
              "      <td>417.0464</td>\n",
              "      <td>-925.0109</td>\n",
              "      <td>1759.1038</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>jun</td>\n",
              "      <td>sep</td>\n",
              "      <td>154.7506</td>\n",
              "      <td>-1201.5088</td>\n",
              "      <td>1511.0100</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>mar</td>\n",
              "      <td>may</td>\n",
              "      <td>175.4693</td>\n",
              "      <td>-900.1371</td>\n",
              "      <td>1251.0757</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>mar</td>\n",
              "      <td>nov</td>\n",
              "      <td>118.4969</td>\n",
              "      <td>-871.8119</td>\n",
              "      <td>1108.8058</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>mar</td>\n",
              "      <td>oct</td>\n",
              "      <td>236.8935</td>\n",
              "      <td>-728.5067</td>\n",
              "      <td>1202.2937</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>mar</td>\n",
              "      <td>sep</td>\n",
              "      <td>-25.4023</td>\n",
              "      <td>-1010.4502</td>\n",
              "      <td>959.6455</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>may</td>\n",
              "      <td>nov</td>\n",
              "      <td>-56.9724</td>\n",
              "      <td>-1249.9917</td>\n",
              "      <td>1136.0470</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>may</td>\n",
              "      <td>oct</td>\n",
              "      <td>61.4242</td>\n",
              "      <td>-1111.0012</td>\n",
              "      <td>1233.8495</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>may</td>\n",
              "      <td>sep</td>\n",
              "      <td>-200.8716</td>\n",
              "      <td>-1389.5275</td>\n",
              "      <td>987.7843</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>nov</td>\n",
              "      <td>oct</td>\n",
              "      <td>118.3966</td>\n",
              "      <td>-976.3014</td>\n",
              "      <td>1213.0946</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>nov</td>\n",
              "      <td>sep</td>\n",
              "      <td>-143.8992</td>\n",
              "      <td>-1255.9628</td>\n",
              "      <td>968.1643</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>oct</td>\n",
              "      <td>sep</td>\n",
              "      <td>-262.2958</td>\n",
              "      <td>-1352.2368</td>\n",
              "      <td>827.6452</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   group1 group2  meandiff      lower      upper  reject\n",
              "0     apr    aug -429.4049 -1421.7047   562.8950   False\n",
              "1     apr    dec -207.6797 -1111.0347   695.6754   False\n",
              "2     apr    feb  -22.6780  -913.5247   868.1687   False\n",
              "3     apr    jan   82.7094  -793.8885   959.3073   False\n",
              "4     apr    jul -249.8789 -1259.4613   759.7034   False\n",
              "5     apr    jun -472.0174 -1727.6696   783.6348   False\n",
              "6     apr    mar -291.8645 -1133.0197   549.2908   False\n",
              "7     apr    may -116.3951 -1188.8343   956.0440   False\n",
              "8     apr    nov -173.3675 -1160.2354   813.5004   False\n",
              "9     apr    oct  -54.9710 -1016.8412   906.8993   False\n",
              "10    apr    sep -317.2668 -1298.8553   664.3217   False\n",
              "11    aug    dec  221.7252  -827.0696  1270.5199   False\n",
              "12    aug    feb  406.7269  -631.3136  1444.7673   False\n",
              "13    aug    jan  512.1143  -513.7239  1537.9525   False\n",
              "14    aug    jul  179.5259  -962.0417  1321.0935   False\n",
              "15    aug    jun  -42.6125 -1406.6443  1321.4192   False\n",
              "16    aug    mar  137.5404  -858.1816  1133.2624   False\n",
              "17    aug    may  313.0097  -884.5068  1510.5262   False\n",
              "18    aug    nov  256.0373  -865.4921  1377.5668   False\n",
              "19    aug    oct  374.4339  -725.1635  1474.0313   False\n",
              "20    aug    sep  112.1381 -1004.7487  1229.0249   False\n",
              "21    dec    feb  185.0017  -768.3709  1138.3743   False\n",
              "22    dec    jan  290.3891  -649.6829  1230.4611   False\n",
              "23    dec    jul  -42.1993 -1107.3603  1022.9618   False\n",
              "24    dec    jun -264.3377 -1565.0967  1036.4213   False\n",
              "25    dec    mar  -84.1848  -991.2976   822.9280   False\n",
              "26    dec    may   91.2845 -1033.6320  1216.2011   False\n",
              "27    dec    nov   34.3122 -1009.3447  1077.9691   False\n",
              "28    dec    oct  152.7087  -867.3431  1172.7606   False\n",
              "29    dec    sep -109.5871 -1148.2533   929.0791   False\n",
              "..    ...    ...       ...        ...        ...     ...\n",
              "36    feb    oct  -32.2929 -1041.2842   976.6983   False\n",
              "37    feb    sep -294.5888 -1322.3947   733.2171   False\n",
              "38    jan    jul -332.5884 -1375.1533   709.9765   False\n",
              "39    jan    jun -554.7268 -1837.0480   727.5943   False\n",
              "40    jan    mar -374.5739 -1255.0437   505.8960   False\n",
              "41    jan    may -199.1046 -1302.6492   904.4401   False\n",
              "42    jan    nov -256.0769 -1276.6617   764.5078   False\n",
              "43    jan    oct -137.6804 -1134.1137   858.7529   False\n",
              "44    jan    sep -399.9762 -1415.4569   615.5045   False\n",
              "45    jul    jun -222.1384 -1598.7939  1154.5170   False\n",
              "46    jul    mar  -41.9855 -1054.9316   970.9606   False\n",
              "47    jul    may  133.4838 -1078.3922  1345.3598   False\n",
              "48    jul    nov   76.5114 -1060.3377  1213.3606   False\n",
              "49    jul    oct  194.9080  -920.3104  1310.1264   False\n",
              "50    jul    sep  -67.3878 -1199.6571  1064.8814   False\n",
              "51    jun    mar  180.1529 -1078.2054  1438.5113   False\n",
              "52    jun    may  355.6222 -1067.7714  1779.0159   False\n",
              "53    jun    nov  298.6499 -1061.4354  1658.7351   False\n",
              "54    jun    oct  417.0464  -925.0109  1759.1038   False\n",
              "55    jun    sep  154.7506 -1201.5088  1511.0100   False\n",
              "56    mar    may  175.4693  -900.1371  1251.0757   False\n",
              "57    mar    nov  118.4969  -871.8119  1108.8058   False\n",
              "58    mar    oct  236.8935  -728.5067  1202.2937   False\n",
              "59    mar    sep  -25.4023 -1010.4502   959.6455   False\n",
              "60    may    nov  -56.9724 -1249.9917  1136.0470   False\n",
              "61    may    oct   61.4242 -1111.0012  1233.8495   False\n",
              "62    may    sep -200.8716 -1389.5275   987.7843   False\n",
              "63    nov    oct  118.3966  -976.3014  1213.0946   False\n",
              "64    nov    sep -143.8992 -1255.9628   968.1643   False\n",
              "65    oct    sep -262.2958 -1352.2368   827.6452   False\n",
              "\n",
              "[66 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 403
        }
      ]
    },
    {
      "metadata": {
        "id": "VBR-bpiVZzdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "najcmrG6LVtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FvzMmNNgZpe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pandas Tricks /  Data Filtering and Selection"
      ]
    },
    {
      "metadata": {
        "id": "K2DiYJNrJJib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def list2df [USE ME!!!]"
      ]
    },
    {
      "metadata": {
        "id": "szjRetJuF5wM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def list2df(list):#, sort_values='index'):\n",
        "    \"\"\" Take in a list where row[0] = column_names and outputs a dataframe.\n",
        "    \n",
        "    Keyword arguments:\n",
        "    set_index -- df.set_index(set_index)\n",
        "    sortby -- df.sorted()\n",
        "    \"\"\"    \n",
        "    \n",
        "    df_list = pd.DataFrame(list[1:],columns=list[0])\n",
        "#     df_list = df_list[1:]\n",
        "\n",
        "    return df_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EBzBLq3TF5Le",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def df_drop_regex"
      ]
    },
    {
      "metadata": {
        "id": "NujuTGyqZsXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def df_drop_regex(DF, regex_list):\n",
        "    '''Use a list of regex to remove columns names. Returns new df.\n",
        "    \n",
        "    Parameters:\n",
        "        DF -- input dataframe to remove columns from.\n",
        "        regex_list -- list of string patterns or regexp to remove.\n",
        "    \n",
        "    Returns:\n",
        "        df_cut -- input df without the dropped columns. \n",
        "        '''\n",
        "    df_cut = DF.copy()\n",
        "    \n",
        "    for r in regex_list:\n",
        "        \n",
        "        df_cut = df_cut[df_cut.columns.drop(list(df_cut.filter(regex=r)))]\n",
        "        print(f'Removed {r}\\n')\n",
        "        \n",
        "    return df_cut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_7H2Zbg9o1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Plotting in Pandas"
      ]
    },
    {
      "metadata": {
        "id": "ZtNgmdxi9sGZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting bar graph with mean + standard error of the mean\n"
      ]
    },
    {
      "metadata": {
        "id": "nitBU-AT9qL-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Plotting bar graph with mean + standard error of the mean -Cell 1 of 2\n",
        "\n",
        "# WANT TO CALCULATE MEAN AND SEM FOR BAR PLOT FOR DF\n",
        "# Calc Standard Error of the Mean for PLotting.\n",
        "from scipy.stats import sem\n",
        "\n",
        "d_plot={}\n",
        "d_plot['mean'] = df_year_orders.groupby(['month'])['order_total'].mean()\n",
        "d_plot['sem'] =df_year_orders.groupby(['month'])['order_total'].sem()\n",
        "df_plot = pd.DataFrame.from_dict(d_plot)\n",
        "\n",
        "# Convert month index to month_num column\n",
        "df_plot['month_num'] = df_plot.index\n",
        "\n",
        "# Use month_dict to get months labeled with names\n",
        "df_plot['month_name']=df_plot['month_num'].map(month_dict)\n",
        "df_plot.set_index('month_name',drop=False,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lgjSL5w9yAR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Plotting bar graph with mean + standard error of the mean -Cell 2 of 2\n",
        "# Specify keywords to feed into df_plot\n",
        "plt.style.use('default')\n",
        "bar_kws = {'figsize':[6,4],\n",
        "          'title': 'Order Totals By Month',\n",
        "          'grid':False,\n",
        "          'legend':False,\n",
        "          'rot':45,\n",
        "           'yerr':'sem',\n",
        "          'ylim': [0,2500]}\n",
        "\n",
        "fig = df_plot.plot(kind='bar',x=df_plot.index.str.title(),y='mean',**bar_kws)#,table=True)\n",
        "fig.set(**{'xlabel':'Month','ylabel':'Order Total($)'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdfO9bHdZwen",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mod 2 Project Plotting - For Presentation or to Make into Functions"
      ]
    },
    {
      "metadata": {
        "id": "tbFPk1EPKSo6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mike's Figure Functions\n"
      ]
    },
    {
      "metadata": {
        "id": "rFcwU8DgEVvj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def make_violinplot"
      ]
    },
    {
      "metadata": {
        "id": "EOGyGQKK5fQh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plotting order totals per month in violin plots\n",
        "\n",
        "def make_violinplot(x,y, title=None, hue=None, ticklabels=None):\n",
        "  \n",
        "  '''Plots a violin plot with horizontal mean line, inner stick lines'''\n",
        "  \n",
        "  plt.style.use('dark_background')\n",
        "  fig,ax =plt.subplots(figsize=(12,10))\n",
        "\n",
        "\n",
        "  sns.violinplot(x, y,cut=2,split=True, scale='count', scale_hue=True,\n",
        "                 saturation=.5, alpha=.9,bw=.25, palette='Dark2',inner='stick', hue=hue).set_title(title)\n",
        "\n",
        "  ax.axhline(y.mean(),label='total mean', ls=':', alpha=.5, color='xkcd:yellow')\n",
        "  ax.set_xticklabels(ticklabels)\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  x= df_year_orders['month']\n",
        "  y= df_year_orders['order_total']\n",
        "  title = 'Order totals per month with or without discounts'\n",
        "  hue=df_year_orders['Discount']>0\n",
        "    \n",
        "    \n",
        "### Example usage\n",
        "# #First, declare variables to be plotted\n",
        "# x = df_year_orders['month']\n",
        "# y = df_year_orders['order_total']\n",
        "# ticks = [v for v in month_dict.values()] \n",
        "# title = 'Order totals per month with or without discounts'\n",
        "# hue = df_year_orders['Discount']>0\n",
        "\n",
        "### Then call function\n",
        "# make_violinplot(x,y,title,hue, ticks), "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbWOaMzpKaKf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def make_stripplot"
      ]
    },
    {
      "metadata": {
        "id": "JJwBisCEswMi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_stripplot(x, y, title=None, hue=None, ticklabels=None):\n",
        "\n",
        "  plt.style.use('dark_background')\n",
        "  fig,ax =plt.subplots(figsize=(8,6))\n",
        "\n",
        "\n",
        "  sns.stripplot(x, y, jitter=True, size=12,edgecolor='gray',linewidth=1.5, alpha=.5, palette='Dark2',marker='d', hue=hue).set_title(title)\n",
        "\n",
        "  ax.axhline(y.mean(),label='total mean', ls=':', alpha=.5, color='xkcd:yellow')\n",
        "  ax.set_xticklabels(ticklabels)\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOAYjtQFKdRm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### def draw_histograms"
      ]
    },
    {
      "metadata": {
        "id": "5blWSt91EY1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "def draw_histograms(df, variable, sample_dict, n_rows, n_cols):\n",
        "\n",
        "  '''Takes dataframe, variable is column name , plots histograms '''\n",
        "  \n",
        "  with plt.style.context('seaborn-paper'):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "    for k,v in sample_dict.items():\n",
        "\n",
        "      month = df[df[variable] == k]['order_total']\n",
        "      month_mean = round(np.mean(month),2)\n",
        "\n",
        "      year =  df[df['month'] != k]['order_total']\n",
        "      year_mean = round(np.mean(year),2)\n",
        "\n",
        "      ax = fig.add_subplot(n_rows,n_cols,k)\n",
        "      ax.tick_params(labelsize=8)\n",
        "\n",
        "      plt.hist(year, bins=90,alpha=.7, label='Rest of Year')\n",
        "      plt.hist(month, alpha=.6,label= v.title())\n",
        "\n",
        "      ax.set_title(v.title(),fontsize=14)\n",
        "\n",
        "      plt.axvline(month_mean, color='xkcd:fuchsia',linestyle='--',\n",
        "                  label='Sample Mean \\n'+str(month_mean))\n",
        "\n",
        "      plt.axvline(year_mean,color='xkcd:green',linestyle='-',\n",
        "                  label='Pop. Mean \\n'+str(year_mean))\n",
        "\n",
        "      plt.legend(fontsize=6, frameon=False, ncol = 2 )\n",
        "\n",
        "    fig.tight_layout()    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9YjykJuwK30L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### draw_histograms_from_sample"
      ]
    },
    {
      "metadata": {
        "id": "30cw7laZEaU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_histograms_from_sample(population,sample, sample_dict, n_rows, n_cols):\n",
        "\n",
        "  fig = plt.figure(figsize=(8.5,7.5))\n",
        "  count = 0\n",
        "  \n",
        "  for k,v in sample_dict.items():\n",
        "    \n",
        "    count += 1                        \n",
        "\n",
        "    month = sample_dict[k] #pop_samp_month_dict[k]\n",
        "    month_mean = round(np.mean(v),2)\n",
        "    \n",
        "    year = population\n",
        "    year_mean = round(np.mean(population),2)\n",
        "\n",
        "    ax = fig.add_subplot(n_rows,n_cols, count)\n",
        "    ax.tick_params(labelsize=8)\n",
        "\n",
        "    plt.hist(year, alpha=.8, label='All Months')\n",
        "    plt.hist(month, alpha=.6, label = v.title())\n",
        "\n",
        "    ax.set_title(k.title(),fontsize=14)\n",
        "\n",
        "    plt.axvline(month_mean, color='xkcd:fuchsia',linestyle='--',\n",
        "                label='Sample Mean \\n'+str(month_mean))\n",
        "    plt.axvline(year_mean,color='xkcd:green',linestyle='-',\n",
        "                label='Pop. Mean \\n'+str(year_mean))\n",
        "    \n",
        "    plt.legend(fontsize=6, frameon=False)\n",
        "    \n",
        "  fig.tight_layout()    \n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_iluxStKSZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvMGqL4bHsdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BOOKMARK <img src=\"https://www.dropbox.com/s/6xqzendi1iyzls8/bookmark.png?raw=1\" width=25> \n"
      ]
    },
    {
      "metadata": {
        "id": "DUruMce5J8oV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using gridspec to plot KDE and bar plots Hypothesis 1"
      ]
    },
    {
      "metadata": {
        "id": "S89W0FQBGoGv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plotting Histogram/kde for most of width of figure, then bar graph on right. \n",
        "## ADDING add_gridspec usage\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import sem\n",
        "\n",
        "\n",
        "from matplotlib import rcParams\n",
        "from matplotlib import rc\n",
        "rcParams['font.family'] = 'serif'\n",
        "rcParams['font.sans-serif'] = ['Tahoma']\n",
        "# rcParams[]\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Plot distributions of discounted vs full price groups\n",
        "plt.style.use('default')\n",
        "# with plt.style.context(('tableau-colorblind10')):\n",
        "with plt.style.context(('seaborn-notebook')):\n",
        "    \n",
        "    ## ----------- DEFINE AESTHETIC CUSTOMIZATIONS ----------- ##\n",
        "   # Axis Label fonts\n",
        "    fontSuptitle ={'fontsize': 24,\n",
        "               'fontweight': 'bold',\n",
        "                'fontfamily':'serif'}\n",
        "    \n",
        "    fontTitle = {'fontsize': 12,\n",
        "               'fontweight': 'medium',\n",
        "                'fontfamily':'serif'}\n",
        "\n",
        "    fontAxis = {'fontsize': 12,\n",
        "               'fontweight': 'medium',\n",
        "                'fontfamily':'serif'}\n",
        "\n",
        "    fontTicks = {'fontsize': 10,\n",
        "               'fontweight':'medium', \n",
        "                'fontfamily':'sans-serif'}\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "    fig = plt.figure(constrained_layout=True, figsize=(10,4))\n",
        "    gs = fig.add_gridspec(nrows=1,ncols=10)\n",
        "    \n",
        "    ax0 = fig.add_subplot(gs[0, 0:-3])\n",
        "    ax1 = fig.add_subplot(gs[7:9])\n",
        "    \n",
        "    ax = [ax0,ax1]\n",
        "    \n",
        "    plt.suptitle('Quantity of Units Sold', fontdict=fontSuptitle)\n",
        "    \n",
        "\n",
        "     ## ----------- DEFINE SUBPLOT GROUPS DATA, LABELS, AND STYLE ----------- ##\n",
        "\n",
        "    # Group 1: data, label, hist_kws and kde_kws\n",
        "    \n",
        "    plot_me1 = {'data': df_fullprice['Quantity'], \n",
        "                'label': 'full price'.title(),\n",
        "                \n",
        "               'hist_kws' :\n",
        "                {'edgecolor': 'black','color':'darkgray','alpha': 0.8, 'lw':0.5},\n",
        "                \n",
        "               'kde_kws':\n",
        "                {'color':'gray','linestyle': '--', 'linewidth':2,'label':'kde'}}\n",
        "\n",
        "    \n",
        "    sns.distplot(plot_me1['data'], label=plot_me1['label'],\n",
        "                 hist_kws = plot_me1['hist_kws'],\n",
        "                 kde_kws = plot_me1['kde_kws'], ax=ax[0])   \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # Group 2: data, label, hist_kws and kde_kws\n",
        "    \n",
        "    plot_me2 = {'data': df_discounted['Quantity'],\n",
        "                'label': 'discounted'.title(), \n",
        "                \n",
        "                'hist_kws' :\n",
        "                {'edgecolor': 'black','color':'green','alpha':0.8 ,'lw':0.5},\n",
        "                \n",
        "\n",
        "                'kde_kws':\n",
        "                {'color':'darkgreen','linestyle':':','linewidth':3,'label':'kde'}}\n",
        "    \n",
        "    \n",
        "    sns.distplot(plot_me2['data'], label=plot_me2['label'],\n",
        "                 hist_kws=plot_me2['hist_kws'],\n",
        "                 kde_kws = plot_me2['kde_kws'],ax=ax[0])\n",
        "    \n",
        "    \n",
        "    ax[0].set_title('Histogram + KDE',fontdict=fontTitle)\n",
        "    #ax[0].set_xlabel(fontAxis)\n",
        "    ax[0].set_ylabel('Kernel Density Estimation',fontdict=fontAxis)\n",
        "                      \n",
        "    ax[0].tick_params(axis='both',labelsize=fontTicks['fontsize'])   \n",
        "    ax[0].legend()\n",
        "\n",
        "\n",
        "    # SUBPLOT 2 \n",
        "    # Import scipy for error bars\n",
        "    from scipy import stats\n",
        "\n",
        "    x = [plot_me1 ['label'], plot_me2['label']]\n",
        "    y = [np.mean(plot_me1['data']),np.mean(plot_me2['data'])]\n",
        "\n",
        "    yerr = [stats.sem(plot_me1['data']),  stats.sem(plot_me2['data'])]\n",
        "    err_kws = {'ecolor':'black','capsize':10,'capthick':1,'elinewidth':1,'barsabove':False}\n",
        "\n",
        "    ax[1].bar(x,y,align='center', edgecolor='black', yerr=yerr,error_kw=err_kws)\n",
        "\n",
        "    # Customize subplot 2\n",
        "    ax[1].set_title('Average Quantities Sold',fontdict=fontTitle)\n",
        "    ax[1].set_xlabel('Sales Price', fontdict=fontAxis)\n",
        "    ax[1].set_ylabel('Mean +/- SEM ',fontdict=fontAxis)\n",
        "    ax[1].tick_params(axis='both',labelsize=fontTicks['fontsize'])\n",
        "    fig.savefig('H1_EDA_using_gridspec.png')\n",
        "#     plt.tight_layout()\n",
        "#     print(f')\n",
        "\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TlqO6JSSIlsC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Summary distribution with annotated mean\n"
      ]
    },
    {
      "metadata": {
        "id": "DAzkiuskI2bG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Hypothesis 2 summary distribtuions with annotations\n",
        "with plt.style.context(('tableau-colorblind10')):\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    plt.title('Order Total  of Orders with Discounted Items vs Full Price')\n",
        "    \n",
        "    plt.hist(arrA,alpha = 0.5, bins=30,label='Discounted')\n",
        "    plt.hist(arrB,color='black', alpha = 0.5, bins=30,label='Full Price')\n",
        "\n",
        "    # Adding annotations\n",
        "    meanD = round(np.mean(arrA),3)\n",
        "    meanS = round(np.mean(arrB),3)\n",
        "    \n",
        "    plt.axvline(meanD, linestyle='--',label='Discounted Mean')\n",
        "    plt.text(meanD-1000,165,f'Mean:{meanD}',rotation=90)\n",
        "    \n",
        "    plt.axvline(meanS,color='k',linestyle='--',label='Full Price Mean')\n",
        "    plt.text(meanS+500,165,f'Mean:{meanS}',rotation=90)\n",
        "\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Run normality testing\n",
        "stat,p = normaltest(pop_samp_full)\n",
        "print(f'Normality: stat ={stat}, p = {p}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Br18qUGAIhdP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Resampled data distributions with annotated mean [as example for annotating?]"
      ]
    },
    {
      "metadata": {
        "id": "E0r5ZQAtGysg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot the re-sampled data\n",
        "\n",
        "# # IF want to take smaller sample from population:\n",
        "\n",
        "# pop_samp_disc = np.random.choice(pop_samp_disc,1000)\n",
        "# pop_samp_full = np.random.choice(pop_samp_full, 1000)\n",
        "with plt.style.context(('dark_background')):\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    plt.title('Distribution of Quanitities for Discounted vs Full Price ')\n",
        "\n",
        "    disc = df_discounted['Quantity']\n",
        "    full = df_fullprice['Quantity']\n",
        "    \n",
        "    \n",
        "    plt.hist(full,color='red', alpha = 0.5, bins=30,label='Full Price')\n",
        "    plt.hist(disc, alpha = 0.8, bins=30,label='Discounted')\n",
        "\n",
        "    # Adding annotations\n",
        "    meanD = round(np.mean(disc),3)\n",
        "    meanF = round(np.mean(full),3)\n",
        "    \n",
        "    plt.axvline(meanD, color='green',linestyle='--',label='Discounted Mean')\n",
        "    plt.text(meanD,190,f'Mean:{meanD}',rotation=270,fontweight='medium')\n",
        "    \n",
        "    plt.axvline(meanF,color='white',linestyle='-',label='Full Price Mean')\n",
        "    plt.text(meanF, 190, f'Mean:{meanF}',rotation=270,fontweight='medium')\n",
        "\n",
        "    plt.xlabel('Quantity')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aPsOd-vNHZsX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Making a population overlapping histrogram +mean annotaitons"
      ]
    },
    {
      "metadata": {
        "id": "n_jV1mVYHeMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Resample our data  i # of samples with n =50/sample \n",
        "# Dat source\n",
        "data_discounted = df['Quantity'].loc[df['Discount']>0].copy()\n",
        "data_fullprice = df['Quantity'].loc[df['Discount']==0].copy()\n",
        "\n",
        "\n",
        "n = 50 \n",
        "i = 10000\n",
        "pop_samp_disc = []\n",
        "pop_samp_full = []\n",
        "for i in range(0,i):\n",
        "    \n",
        "    pop_samp_disc.append(data_discounted.sample(n).mean())\n",
        "    pop_samp_full.append(data_fullprice.sample(n).mean())\n",
        "    #   test_results.append(normaltest())\n",
        "    # plt.hist([pop_samp_disc,pop_samp_full])\n",
        "    \n",
        "    \n",
        "# Plot the re-sampled data\n",
        "\n",
        "# pop_samp_disc = np.random.choice(pop_samp_disc,1000)\n",
        "# pop_samp_full = np.random.choice(pop_samp_full, 1000)\n",
        "with plt.style.context(('tableau-colorblind10')):\n",
        "    fig = plt.figure()\n",
        "    \n",
        "    plt.title('Quantity of Discounted vs Full Price Products Purchased ')\n",
        "    \n",
        "    plt.hist(pop_samp_disc,alpha = 0.5, bins=30,label='Discounted')\n",
        "    plt.hist(pop_samp_full,color='black', alpha = 0.5, bins=30,label='Full Price')\n",
        "\n",
        "    # Adding annotations\n",
        "    meanD = round(np.mean(pop_samp_disc),3)\n",
        "    meanS = round(np.mean(pop_samp_full),3)\n",
        "    \n",
        "    plt.axvline(meanD, linestyle='--',label='Discounted Mean')\n",
        "    plt.text(meanD-1,700,f'Mean:{meanD}',rotation=90)\n",
        "    \n",
        "    plt.axvline(meanS,color='k',linestyle='--',label='Full Price Mean')\n",
        "    plt.text(meanS-1,700,f'Mean:{meanS}',rotation=90)\n",
        "\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Run normality testing\n",
        "stat,p = normaltest(pop_samp_full)\n",
        "print(f'Normality: stat ={stat}, p = {p}')\n",
        "\n",
        "# Run ttest\n",
        "tstat,tp = stats.ttest_ind(pop_samp_disc, pop_samp_full)\n",
        "# print(f'T-test: stat ={tstat}, p = {tp}')#tstat,tp\n",
        "# ax.text("
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}