{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>My Flatiron Data Science Bootcamp Cheatsheet &amp; Example Code<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CODE-SNIPPET-LIBRARY\" data-toc-modified-id=\"CODE-SNIPPET-LIBRARY-1\">CODE SNIPPET LIBRARY</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Dataframes-and-filtering-/-indexing-data\" data-toc-modified-id=\"Dataframes-and-filtering-/-indexing-data-1.0.1\">Dataframes and filtering / indexing data</a></span></li></ul></li></ul></li><li><span><a href=\"#FLATIRON-BOOTCAMP-NOTES\" data-toc-modified-id=\"FLATIRON-BOOTCAMP-NOTES-2\">FLATIRON BOOTCAMP NOTES</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-started\" data-toc-modified-id=\"Getting-started-2.1\">Getting started</a></span><ul class=\"toc-item\"><li><span><a href=\"#Git-Bash-Terminal\" data-toc-modified-id=\"Git-Bash-Terminal-2.1.1\">Git Bash Terminal</a></span></li><li><span><a href=\"#Jupyter-Notebook-Hotkeys-&amp;-Mouse-Tricks\" data-toc-modified-id=\"Jupyter-Notebook-Hotkeys-&amp;-Mouse-Tricks-2.1.2\">Jupyter Notebook Hotkeys &amp; Mouse Tricks</a></span></li></ul></li><li><span><a href=\"#BASIC-PYTHON-FUNCTIONS/METHODS/INDEXING\" data-toc-modified-id=\"BASIC-PYTHON-FUNCTIONS/METHODS/INDEXING-2.2\">BASIC PYTHON FUNCTIONS/METHODS/INDEXING</a></span><ul class=\"toc-item\"><li><span><a href=\"#List-Indexing:\" data-toc-modified-id=\"List-Indexing:-2.2.1\">List Indexing:</a></span></li><li><span><a href=\"#List-Methods\" data-toc-modified-id=\"List-Methods-2.2.2\">List Methods</a></span></li><li><span><a href=\"#String-methods\" data-toc-modified-id=\"String-methods-2.2.3\">String methods</a></span></li><li><span><a href=\"#Dictionary-Indexing:\" data-toc-modified-id=\"Dictionary-Indexing:-2.2.4\">Dictionary Indexing:</a></span></li><li><span><a href=\"#Flow-control-(conditionals-and-loops)\" data-toc-modified-id=\"Flow-control-(conditionals-and-loops)-2.2.5\">Flow control (conditionals and loops)</a></span></li><li><span><a href=\"#Defining-functions\" data-toc-modified-id=\"Defining-functions-2.2.6\">Defining functions</a></span></li><li><span><a href=\"#Lambda-functions\" data-toc-modified-id=\"Lambda-functions-2.2.7\">Lambda functions</a></span></li><li><span><a href=\"#List-Comprehensions\" data-toc-modified-id=\"List-Comprehensions-2.2.8\">List Comprehensions</a></span></li></ul></li><li><span><a href=\"#GRAPHING-WITH-MATPLOTLIB\" data-toc-modified-id=\"GRAPHING-WITH-MATPLOTLIB-2.3\">GRAPHING WITH MATPLOTLIB</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stem-&amp;-leaf-plots\" data-toc-modified-id=\"Stem-&amp;-leaf-plots-2.3.1\">Stem &amp; leaf plots</a></span></li><li><span><a href=\"#My-Histograms-from-PDF-lab\" data-toc-modified-id=\"My-Histograms-from-PDF-lab-2.3.2\">My Histograms from PDF lab</a></span></li></ul></li><li><span><a href=\"#PANDAS-AND-DATAFRAMES\" data-toc-modified-id=\"PANDAS-AND-DATAFRAMES-2.4\">PANDAS AND DATAFRAMES</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pandas-methods-and-functions\" data-toc-modified-id=\"Pandas-methods-and-functions-2.4.1\">Pandas methods and functions</a></span></li><li><span><a href=\"#Useful-pandas-series-methods:\" data-toc-modified-id=\"Useful-pandas-series-methods:-2.4.2\">Useful pandas series methods:</a></span></li><li><span><a href=\"#Using-Map/apply-to-operate-on-data-frames\" data-toc-modified-id=\"Using-Map/apply-to-operate-on-data-frames-2.4.3\">Using Map/apply to operate on data frames</a></span></li></ul></li><li><span><a href=\"#HOW-TO:-cleaning-a-dataset-and-checking-for-missing-values\" data-toc-modified-id=\"HOW-TO:-cleaning-a-dataset-and-checking-for-missing-values-2.5\">HOW TO: cleaning a dataset and checking for missing values</a></span></li><li><span><a href=\"#SQL-(sect-05)\" data-toc-modified-id=\"SQL-(sect-05)-2.6\">SQL (sect 05)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-sqlite3-with-SQL-databases\" data-toc-modified-id=\"Using-sqlite3-with-SQL-databases-2.6.1\">Using sqlite3 with SQL databases</a></span></li></ul></li><li><span><a href=\"#Object-Oriented-Programming-(Sect-06-07)\" data-toc-modified-id=\"Object-Oriented-Programming-(Sect-06-07)-2.7\">Object-Oriented Programming (Sect 06-07)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Defining-classes\" data-toc-modified-id=\"Defining-classes-2.7.1\">Defining classes</a></span></li><li><span><a href=\"#Class-Attributes-&amp;-Methods\" data-toc-modified-id=\"Class-Attributes-&amp;-Methods-2.7.2\">Class Attributes &amp; Methods</a></span></li><li><span><a href=\"#Instance-Variables-&amp;-Setters-and-Getters\" data-toc-modified-id=\"Instance-Variables-&amp;-Setters-and-Getters-2.7.3\">Instance Variables &amp; Setters and Getters</a></span></li></ul></li><li><span><a href=\"#Using-NumPy-&amp;-Arrays-(section-08)\" data-toc-modified-id=\"Using-NumPy-&amp;-Arrays-(section-08)-2.8\">Using NumPy &amp; Arrays (section 08)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numpy-&amp;-element-wise-math-operations\" data-toc-modified-id=\"Numpy-&amp;-element-wise-math-operations-2.8.1\">Numpy &amp; element-wise math operations</a></span></li><li><span><a href=\"#Scalar-Math\" data-toc-modified-id=\"Scalar-Math-2.8.2\">Scalar Math</a></span></li><li><span><a href=\"#Vector-Math\" data-toc-modified-id=\"Vector-Math-2.8.3\">Vector Math</a></span></li><li><span><a href=\"#Appending-/-adding-elements\" data-toc-modified-id=\"Appending-/-adding-elements-2.8.4\">Appending / adding elements</a></span></li><li><span><a href=\"#Multi-dimensional-Arrays-with-Numpy\" data-toc-modified-id=\"Multi-dimensional-Arrays-with-Numpy-2.8.5\">Multi-dimensional Arrays with Numpy</a></span></li><li><span><a href=\"#Numpy-Functions-for-Creating-Arrays\" data-toc-modified-id=\"Numpy-Functions-for-Creating-Arrays-2.8.6\">Numpy Functions for Creating Arrays</a></span></li><li><span><a href=\"#NP-Array-Indexing-/-Subsetting\" data-toc-modified-id=\"NP-Array-Indexing-/-Subsetting-2.8.7\">NP Array Indexing / Subsetting</a></span></li><li><span><a href=\"#Get-unique-vanlues-and-counts-from-a-np-array\" data-toc-modified-id=\"Get-unique-vanlues-and-counts-from-a-np-array-2.8.8\">Get unique vanlues and counts from a np array</a></span></li></ul></li><li><span><a href=\"#STATISTICS-AND-PROBABILITY-(Section-08)\" data-toc-modified-id=\"STATISTICS-AND-PROBABILITY-(Section-08)-2.9\">STATISTICS AND PROBABILITY (Section 08)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-definions\" data-toc-modified-id=\"Set-definions-2.9.1\">Set definions</a></span></li><li><span><a href=\"#Set-operations:\" data-toc-modified-id=\"Set-operations:-2.9.2\">Set operations:</a></span></li><li><span><a href=\"#Empty\" data-toc-modified-id=\"Empty-2.9.3\">Empty</a></span></li><li><span><a href=\"#Sample-Space-&amp;-Event-Space\" data-toc-modified-id=\"Sample-Space-&amp;-Event-Space-2.9.4\">Sample Space &amp; Event Space</a></span></li><li><span><a href=\"#Law-of-relative-frequency\" data-toc-modified-id=\"Law-of-relative-frequency-2.9.5\">Law of relative frequency</a></span></li><li><span><a href=\"#Addition-law-of-probability\" data-toc-modified-id=\"Addition-law-of-probability-2.9.6\">Addition law of probability</a></span></li><li><span><a href=\"#HOW-TO:-test-probability-of-an-event:\" data-toc-modified-id=\"HOW-TO:-test-probability-of-an-event:-2.9.7\">HOW TO: test probability of an event:</a></span></li></ul></li><li><span><a href=\"#Permutations-and-Factorials:\" data-toc-modified-id=\"Permutations-and-Factorials:-2.10\">Permutations and Factorials:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Permutations-of-a-subset\" data-toc-modified-id=\"Permutations-of-a-subset-2.10.1\">Permutations of a subset</a></span></li><li><span><a href=\"#Permutations-with-replacement\" data-toc-modified-id=\"Permutations-with-replacement-2.10.2\">Permutations with replacement</a></span></li><li><span><a href=\"#Permutations-with-repetition\" data-toc-modified-id=\"Permutations-with-repetition-2.10.3\">Permutations with repetition</a></span></li><li><span><a href=\"#Statistical-Distribtuions-+-Linear-Regression\" data-toc-modified-id=\"Statistical-Distribtuions-+-Linear-Regression-2.10.4\">Statistical Distribtuions + Linear Regression</a></span></li><li><span><a href=\"#Distributions:-Discrete-vs-Continuous\" data-toc-modified-id=\"Distributions:-Discrete-vs-Continuous-2.10.5\">Distributions: Discrete vs Continuous</a></span></li><li><span><a href=\"#[-]-Probability-Mass-Function-(PMF)\" data-toc-modified-id=\"[-]-Probability-Mass-Function-(PMF)-2.10.6\">[ ] Probability Mass Function (PMF)</a></span></li><li><span><a href=\"#[-]-CUMULATIVE-DENSITY-FUNCTION\" data-toc-modified-id=\"[-]-CUMULATIVE-DENSITY-FUNCTION-2.10.7\">[ ] CUMULATIVE DENSITY FUNCTION</a></span></li><li><span><a href=\"#[-]-PROBABILITY-DENSITY-FUNCTION\" data-toc-modified-id=\"[-]-PROBABILITY-DENSITY-FUNCTION-2.10.8\">[ ] PROBABILITY DENSITY FUNCTION</a></span></li></ul></li><li><span><a href=\"#Simple-Linear-Regression\" data-toc-modified-id=\"Simple-Linear-Regression-2.11\">Simple Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-statsmodels-to-run-Ordinary-Least-Squares-Regressions*\" data-toc-modified-id=\"Using-statsmodels-to-run-Ordinary-Least-Squares-Regressions*-2.11.1\">Using statsmodels to run Ordinary Least Squares Regressions*</a></span></li><li><span><a href=\"#Regression-Diagnostics-in-Statsmodels\" data-toc-modified-id=\"Regression-Diagnostics-in-Statsmodels-2.11.2\">Regression Diagnostics in Statsmodels</a></span></li><li><span><a href=\"#Q-Q-Plots-to-check-normality-(also-called-normal-density-plots-when-used-with-standard-normal-quantiles)\" data-toc-modified-id=\"Q-Q-Plots-to-check-normality-(also-called-normal-density-plots-when-used-with-standard-normal-quantiles)-2.11.3\">Q-Q Plots to check normality (also called normal density plots when used with standard normal quantiles)</a></span></li></ul></li><li><span><a href=\"#Multiple-Linear-Regression*\" data-toc-modified-id=\"Multiple-Linear-Regression*-2.12\">Multiple Linear Regression*</a></span><ul class=\"toc-item\"><li><span><a href=\"#HOW-TO:-BLOG-POST-ON-LINEAR-REGRESSION-IN-PYTHON:\" data-toc-modified-id=\"HOW-TO:-BLOG-POST-ON-LINEAR-REGRESSION-IN-PYTHON:-2.12.1\">HOW TO: BLOG POST ON LINEAR REGRESSION IN PYTHON:</a></span></li><li><span><a href=\"#Code-from:-FEATURE-SCALING-AND-NORMALIZATION-LAB:\" data-toc-modified-id=\"Code-from:-FEATURE-SCALING-AND-NORMALIZATION-LAB:-2.12.2\">Code from: FEATURE SCALING AND NORMALIZATION LAB:</a></span></li><li><span><a href=\"#Code-from:-Regression-modeling-with-Boston-Housing-Dataset\" data-toc-modified-id=\"Code-from:-Regression-modeling-with-Boston-Housing-Dataset-2.12.3\">Code from: Regression modeling with Boston Housing Dataset</a></span></li><li><span><a href=\"#Code-from:-Dealing-with-categorical-variables-lab\" data-toc-modified-id=\"Code-from:-Dealing-with-categorical-variables-lab-2.12.4\">Code from: Dealing with categorical variables lab</a></span></li><li><span><a href=\"#REGRESSION-MODEL-VALIDATION\" data-toc-modified-id=\"REGRESSION-MODEL-VALIDATION-2.12.5\">REGRESSION MODEL VALIDATION</a></span></li></ul></li><li><span><a href=\"#OUR-FIRST-EXAMPLE-COMPLETE-PROJECT-(Section-12)\" data-toc-modified-id=\"OUR-FIRST-EXAMPLE-COMPLETE-PROJECT-(Section-12)-2.13\">OUR FIRST EXAMPLE COMPLETE PROJECT (Section 12)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modeling-Our-Data-Lab/Lesson:\" data-toc-modified-id=\"Modeling-Our-Data-Lab/Lesson:-2.13.1\">Modeling Our Data Lab/Lesson:</a></span></li></ul></li><li><span><a href=\"#MOD-1-FINAL-PROJECT-Workflow-Notes-(section12)\" data-toc-modified-id=\"MOD-1-FINAL-PROJECT-Workflow-Notes-(section12)-2.14\">MOD 1 FINAL PROJECT Workflow Notes (section12)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Order-of-Processing-(using-OSEMN-model)\" data-toc-modified-id=\"Order-of-Processing-(using-OSEMN-model)-2.14.1\">Order of Processing (using OSEMN model)</a></span></li></ul></li><li><span><a href=\"#Regular-Expression-in-Beautiful-Soup\" data-toc-modified-id=\"Regular-Expression-in-Beautiful-Soup-2.15\">Regular Expression in Beautiful Soup</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My Flatiron Data Science Bootcamp Cheatsheet & Example Code**\n",
    "- This document will contain both a short-hand collection of code to re-use + a more complete notes collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SNIPPET LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes and filtering / indexing data\n",
    "\n",
    "#### Code to select pandas columns that don’t include string\n",
    "```python\n",
    "df_test =df_run.loc[:,\\~(df_run.columns.str.startswith('logZ'))]\n",
    "```\n",
    "#### code to turn a results list (starts as list with first row as column names)\n",
    "```python\n",
    "results = [['set\\#','R_square_train','MSE_train','R_square_test','MSE_test']]\n",
    "# …\n",
    "results.append([i,R_sqare_train,train_mse,R_square_test,test_mse])\n",
    "df_res=pd.DataFrame(results)\n",
    "df_res.columns=df_res.iloc[0,:]\n",
    "df_res = df_res[1:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLATIRON BOOTCAMP NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started \n",
    "\n",
    "### Git Bash Terminal\n",
    "* Launch Git Bash on Windows\n",
    "    * Can right click inside a folder in Windows and select GitBash to start in current folder\n",
    "```python      \n",
    "      source activate learn-env # Make sure to use learn-env \n",
    "```\n",
    "* [!] New Conda Warning / Updating Your Learn-Env Packages\n",
    "   * If you see a message that states “WARNING: A newer version of conda exists” run :\n",
    "```python\n",
    "    conda update -n base conda # and then try again to create the environment using:\n",
    "    conda env create -f environment.yml.\n",
    "```\n",
    "#### [!] if Jupyter Notebook doesn’t have the Learn-env kernel as an option:\n",
    "```bash\n",
    " python -m ipykernel install --user --name=learn-env\n",
    "```\n",
    "#### General terminal commands\n",
    "\n",
    "cd d: # change to d drive before calling folders\n",
    "cd('D:/Users/My Name/My Flatiron Files') # in quote\n",
    "cd .. # move up one level \n",
    "\n",
    "ls # list folders in current directory\n",
    "pwd # print working directory\n",
    "mkdir #new folder\t\t\n",
    "\n",
    "Ctrl + C # to interrupt kernel\n",
    "Ctrl + Shift + Insert # to paste\n",
    "\n",
    "Up Arrow / Down Arrow # cycles through previous commands \n",
    "        \n",
    "#### Cloning Git, Loading Jupyter Notebook\n",
    "```bash\n",
    "source activate learn-env #gitbash\n",
    "git clone <URL> # control+shift+insert to paste\n",
    "cd(''D:/Users/My Name/My Flatiron Files'/new-cloned-git-learn-lesson/) \n",
    "\n",
    "jupyter notebook #launches notebook in current dir         \n",
    "```\n",
    "- Click on index.ipnb # Lessons are containeed in index.ipnb*\n",
    "- Click Kernel > Change Kernel > learn-env\n",
    "    \n",
    "#### Pushing notebooks back to git\n",
    "git add .\n",
    "git commit -m \"Comments go here\"\n",
    "git push       \n",
    "\n",
    "### Jupyter Notebook Hotkeys & Mouse Tricks\n",
    "\n",
    "* Shift + Tab # inside method/function () for help\n",
    "\n",
    "* % matplotlib inline #for graphs in notebook\n",
    "\n",
    "* ctrl+/  # comment / uncomment selection\n",
    "* shift + enter  #run cell, select below.\n",
    "* ctrl + enter # run cell.\n",
    "* alt + enter #run cell, insert below.\n",
    "  \n",
    "* A # insert cell above.\n",
    "* B # insert cell below.\n",
    "\n",
    "* C # copy cell.\n",
    "* V # paste cell.\n",
    "\n",
    "* X # delete selected cell.\n",
    "* Y # change cell to code\n",
    "* M # change cell to markdown\n",
    "\n",
    "* Ctrl +Click # create multiple cursors at once (edit simultaneously)\n",
    "\n",
    "#### [!] if Jupyter Notebook doesn't have the Learn-env kernel as an option:\n",
    "```python\n",
    "         *python -m ipykernel install --user --name=learn-env*\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC PYTHON FUNCTIONS/METHODS/INDEXING\n",
    "```python\n",
    "\tlen(), type()\n",
    "    var+=1 # can add / sub \n",
    "\tset(list) # returns unique values\n",
    "\tlist(range(0,len(variable))) # create numerical index for variable length\n",
    "\tround(result,num_decimals) # Display only 2 decimal places\n",
    "```\n",
    "### List Indexing:\n",
    "```python\n",
    "\t\tlist=['str','str']\n",
    "\t\tdata[0:5] # select data elements 1-4\n",
    "\t\tdata[5:] # select 5 to the end\n",
    "\t\tdata[0:end:2] #Select every other ek\n",
    "\t\tdata[-1] #last element\n",
    "```\n",
    "### List Methods \n",
    "```python\n",
    "    list.append()\n",
    "    list.pop()\n",
    "    list.extend() #joins 2 list\n",
    "    list.insert()\n",
    "    list.remove()\n",
    "    list.count()\n",
    "    \n",
    "    list.reverse()\n",
    "    list.sort() # doesn't return a value \n",
    "    s=sorted(list,key_func,reverse=True)\n",
    "    \n",
    "    filtered_list = filter(func_that_filters, orignal_long_list )\n",
    "```\n",
    "\n",
    "### String methods\n",
    "```python\n",
    "\n",
    "    str.upper()\n",
    "\tstr.lower()\n",
    "\tstr.capitalize() \n",
    "\tstr.title() \n",
    "\n",
    "\tstr.strip()\n",
    "\tstr.endswith(txt)\n",
    "\tstr.startswith(txt)\n",
    "\tstr.split('_')\n",
    "\tstr=f'This string references my {variable} named variable.'\n",
    "    \n",
    "     # Print vars inside of strings with f-string formatting\n",
    "    print(f'My str will have {variable_names} inserted into it.')\n",
    "```\n",
    "\n",
    "### Dictionary Indexing:\n",
    "```python\n",
    "    new_dict=dict()\n",
    "    ex_dict  = {'key1' : value1 , 'key2' : value2}\n",
    "    \n",
    "\tex_dict['key1'] [element_index]# returns element from value1\n",
    "    \n",
    "    key_to_add='Name'\n",
    "    ex_dict[key_to_add]= 2 \n",
    "    \n",
    "    ex_dict.keys() # returns all keys\n",
    "\tex_dict.values() # returns all values\n",
    "\tex_dict.items() # returns all items\n",
    "\n",
    "\tex_dict.get(var, value_if_DNE) #DNE=does not exist \n",
    "    \n",
    "```\n",
    "#### Ex: Updating a dictionary value (if it exists) by  looping through an iterable\n",
    "```python\n",
    "\t\twords=txt.split() # A long list of strings\n",
    "\t\tword_counts={} # Empty dictionary\n",
    "    \n",
    "        #Loop through words list \n",
    "\t\tfor word in words:\n",
    "\t\t\tword_counts[word] = word_counts.get(word, 0_ ) #dict.get(key, default_value)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow control (conditionals and loops)\n",
    "#### If, elif, else\n",
    "```python\n",
    "if <condition>:\n",
    "\t\tcode_to_run\n",
    "\telif other_condition:\n",
    "\t\tother_code_to_run\n",
    "\telse:\n",
    "\t\totherwise_run_code\n",
    "# Ends via indentation\n",
    "```    \n",
    "#### Conditional statement to chceck of variable exists inside of the list/iterable var \n",
    "\n",
    "##### try, except \n",
    "```python\n",
    "try:\n",
    "    df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "```\n",
    "#### For loops \n",
    "```python\n",
    "\tfor element in iterable:\n",
    "\t\t'run this code'\n",
    "\n",
    "\t*for key, value in exampl_dictionary.items()*\n",
    "\t\t'run this code'\n",
    "```\n",
    "#### While loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions\n",
    "```python\n",
    "\tdef function_name(parameters_in=default_value:  #can do (), but variables must already exist\n",
    "\t\tstr='run this code'\n",
    "\t\treturn value_to_send_back\n",
    "```\n",
    "\n",
    "### Lambda functions\n",
    "```python\n",
    "    df['column'] = df.column_to_operate_on.map(lambda x:  'N' in x)\n",
    "```\n",
    "### List Comprehensions\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPHING WITH MATPLOTLIB\n",
    "```python\n",
    "    import matplotlib.pyplot as plt\n",
    "\t%matplotlib inline # onlu jupyter notebooks\n",
    "    \n",
    "\tplt.figure(figsize=(x,y))\n",
    "\n",
    "\tdata_to_graph.plot(kind='barh') # default is line\n",
    "```    \n",
    "   Can call plotting *functions:*  \n",
    "```python\n",
    "    plt.scatter(x,y)\n",
    "    plt.hist(x,bins=num)\n",
    "\n",
    "\tplt.title('Top 5 Lego Themes', fontsize=16) #fontsize is optional\n",
    "\tplt.xlabel('Number of Lego Sets') #you could also pass in fontsize if you wanted here\n",
    "\tplt.ylabel('Theme') #you could also rotate text if you wanted\n",
    "\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "```\n",
    "\n",
    "#### Matplotlib from lesson - two subplots:\n",
    "```python\n",
    "\t# Define a new figure with matplotlib's .plot() function. Set the size of figure space\n",
    "\tnew_figure = plt.figure(figsize=(10,4))\n",
    "\t# Add a subplot to the figure - a new axes\n",
    "\tax = new_figure.add_subplot(121)\n",
    "\t# Add a second subplot to the figure - a new axes\n",
    "\tax2 = new_figure.add_subplot(122)\n",
    "\t# Generate a line plot on first axes\n",
    "\tax.plot([1, 4, 6, 8], [10, 15, 27, 32], color='lightblue', linewidth=3, linestyle = '-.')\n",
    "\t# Draw a scatter plot on 2nd axes\n",
    "\tax2.scatter([0.5, 2.2, 4.2, 6.5], [21, 19, 9, 26], color='red', marker='o')\n",
    "\t# Set the limits of x and y for first axes\n",
    "\tax.set_xlim(0, 9), ax.set_ylim(5,35)\n",
    "\t# Set the limits of x and y for 2nd axes\n",
    "\tax2.set_xlim(0, 9), ax2.set_ylim(5,35)\n",
    "\t# Show the plot\n",
    "\tplt.show()\n",
    "\n",
    "```\n",
    "#### Matplotlib from lesson - inset subplot\n",
    "```python\n",
    "\t# Generate sample data \n",
    "\tx = np.linspace(0, 5, 11)\n",
    "\ty = x ** 3\n",
    "\n",
    "\t# Creates blank canvas\n",
    "\tfigure = plt.figure()\n",
    "\n",
    "\t# Add new axes to the figure with absolute positions\n",
    "\tax1 = figure.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
    "\tax2 = figure.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes\n",
    "\n",
    "\t# Larger Figure Axes 1\n",
    "\tax1.plot(x, y, color = 'blue', linestyle = '-.')\n",
    "\tax1.set_xlabel('X_label on axes1')\n",
    "\tax1.set_ylabel('Y_label on axes1')\n",
    "\tax1.set_title('Axes 1 Title')\n",
    "\n",
    "\t# Insert Figure Axes 2\n",
    "\tax2.plot(y, x, color = 'green', linestyle = '--')\n",
    "\tax2.set_xlabel('X_label on axes2')\n",
    "\tax2.set_ylabel('Y_label on axes2')\n",
    "\tax2.set_title('Axes 2 Title')\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stem & leaf plots\n",
    "\n",
    "The last major digit is convertd to category on x-axis, the ones-digits are then\n",
    "plotted as Y-values (cannot see multiple instances of same value)\n",
    "\n",
    "![](media/2a56e9788cee9b0d83f8b81a87a8ccb7.emf)\n",
    "```python\n",
    "Import matplotlib.pyplot as plt  \n",
    "%matplotlib inline  \n",
    "plt.style.use(‘ggplot’)  \n",
    "\\# Create a stem and leaf plot including the above styling\n",
    "plt.figure(figsize=(12,8))\n",
    "\\# markerline, stemlines, baseline =\n",
    "plt.stem(stems, leafs, '-.', 'o' )\n",
    "plt.title('Stem and Leaf Plot for Student Marks', fontsize = 30 )\n",
    "plt.ylabel('Leafs', fontsize = 20)\n",
    "plt.xlabel('Stems', fontsize = 20)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Histograms from PDF lab\n",
    "\n",
    "```python\n",
    "fig2=plt.figure()\n",
    "male_df['Height'].plot(kind='hist',color='blue',edgecolor='pink',label='Male',density=True,alpha=0.7)\n",
    "\n",
    "female_df['Height'].plot(kind='hist',color='pink',edgecolor='blue',label='Female',density=True,alpha=0.7)\n",
    "\n",
    "plt.xlabel('Height (inches)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "\\# You code here\n",
    "x_male,y_male=density(male_df['Height'])\n",
    "plt.plot(x_male,y_male,':',color='cyan',linewidth=3)\n",
    "x_female,y_female=density(female_df['Height'])\n",
    "plt.plot(x_female,y_female,'--',color='magenta',linewidth=3)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PANDAS AND DATAFRAMES\n",
    "```python\n",
    "\timport pandas as pd\n",
    "\tdataframe= pd.read_csv('filename.csv',header=1, encoding='latin-1',usecols=[1,2,3])\n",
    "\tdf=pd.read_excel('filename.xlsx',sheet_name='sheet name')\n",
    "\t\n",
    "\tworkbook = pd.ExcelFile('filename.xlsx')\n",
    "\tworkbook.sheet_names\n",
    "\tdf = workbook.parse(sheet_name=1)\n",
    "\n",
    "\tdf.to_csv('file.csv',index=False) #create csv file\n",
    "\tdf.to_excel() #excel \n",
    "\tdf.to_dict()\n",
    "```\n",
    "\n",
    "\n",
    "### Pandas methods and functions\n",
    "```python\n",
    "\tdf.head() # display first few rows ; can do df.column.head()\n",
    "\tdf.tail()\n",
    "\tdf.info() #\n",
    "\tdf.shape() # rows and columns-\n",
    "\tdf.describe() # quick statistics for all of dataframe\n",
    "\tdf.dtypes()\n",
    "\tdf.index()\n",
    "\tdf.columns()\n",
    "\tdf.drop() \n",
    "\tdf.set_index('column')\n",
    "\tdf.reset_index()\n",
    "```\n",
    "#### Dataframe Indexing  \n",
    "```python\n",
    "# For series/column\n",
    "    df['col_ name'] # OR:\n",
    "    df.col_Name\n",
    "# For rows ..?\n",
    "    # []TBD!\n",
    "# Index data by position .iloc[ ]\n",
    "\tdf.iloc[row_idx_start : row_idx_exclusive, col_idx_start: col_idx_end] # slice row row_idx\n",
    "# Index data using .loc[]: \n",
    "    # Index based upon their labels (row index and column name)\n",
    "        df.loc[row1:rowEnd,'column_name' ]     \n",
    "    # Index based upon conditional (boolean) statements\n",
    "        df.loc[df['col_to_test'] < condition1 ]\n",
    "        singe_col_filtered = df.loc[df['col_to_test'] < condition1, ['column_name']]\n",
    "    # Index based upon two conditionals\n",
    "        df.loc[(df[\"col_to_test1\"] == condition1) & (df[\"col_to_test2\"]== condition2)]\n",
    "    # Changing values via .loc indexing\n",
    "        df.loc[df[\"color_intensity\"]>10, \"color_intensity\"] = 10\n",
    "    # Changing values if contain string\n",
    "        df.loc[df[\"Home Team Name\"].str.contains('Korea'), \"Home Team Name\" ]        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful pandas series methods:\n",
    "```python\n",
    "    df.col_name.value_counts() #[0:5]\n",
    "    df.col_name.astype()\n",
    "    series.mean() #Changing notation here: series refers to df.col_name (which is a series)!\n",
    "    series.median()\n",
    "    series.min()\n",
    "    series.max()\n",
    "    series.std()\n",
    "    series.unique()\n",
    "    series.nunique()\n",
    "    series.sample()\n",
    "    series.sort_values()\n",
    "    series.hist()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples: using pandas \n",
    "##### Ex from lesson: conditional indexing\n",
    "```python\n",
    "    # Index based upon an  3 variables, var1/cond1 & (var2/cond2 | var3/cond3)} # / just means var+ condition \n",
    "\tUSA_home_and_away = df[(df.Year==2014)  & ((df['Home Team Name'] == 'USA') | (df['Away Team Name']=='USA'))\n",
    "```\n",
    "##### Ex from lesson: operating on dataframes (change names, cols)\n",
    "```python                           \n",
    "    # Drop a column of the df\n",
    "    df = df.drop('C/A', axis=1) #drop the COLUMN(axis=1) 'C/A'\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'DATE' : 'date'})\n",
    "\t\t\n",
    "    # Operate on columns names\n",
    "    new_cols = [col.lower() for col in df.columns]                       \n",
    "    df.columns = [my_function(col) for col in df.columns] \n",
    "```\n",
    "##### Ex from lessons: using datetime type \n",
    "```python\n",
    "    df.DATE = pd.to_datetime(df.DATE, format='%m/%d/%Y') # convert dates to datetime type\n",
    "    df.DATE.dt.day_name() #dt.day_name\n",
    "    df['Dayofweek'] = df.DATE.dt.dayofweek \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby \n",
    "```python \n",
    "grouped = df.groupby('Dayofweek').sum()\n",
    "grouped.plot(kind='barh')\n",
    " # HMmm weird\n",
    "df['Num_Lines'] = df.LINENAME.map(lambda x: len(x))\n",
    "```\n",
    "#### Dataframe statistics methods\n",
    " (.mean(), .std(), .count(), .sum(), .mean(), .median(), .std(), .var() and .quantile())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Map/apply to operate on data frames\n",
    "```python\n",
    "df[‘column’].map(lambda x: len(x.split()).head()\n",
    "#LAMBDA + MAP FUNCTIONS WITH CONDITIONALS\n",
    "df['text'].map(\n",
    "    lambda x: 'Good' if any([word in x.lower() for word in ['awesome', 'love', 'great']]) else 'Bad').head()\n",
    " ```\n",
    " #### Using .applymap()\n",
    "```python\n",
    "string_df=df.applymap(lambda x: str(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## HOW TO: cleaning a dataset and checking for missing values\n",
    "```python\n",
    "\tprint('   HEROES_DF INFORMATION:\\n')\n",
    "\tprint(heroes_df.info())\n",
    "\tprint('\\n')\n",
    "\t# print('heroes_df value counts (check for redundancy):')\n",
    "\t# print(heroes_df['name'].value_counts()[0:10])\n",
    "\t# print('\\n\\n')\n",
    "\n",
    "\tprint(f'NaN values in data? \\n {heroes_df.isna().any().any()}\\n')\n",
    "\n",
    "\t# print('heroes_df names - Number of Redundant:'.upper())\n",
    "\t# print(f'Num unique names: {len(heroes_df.name.unique())}')\n",
    "\t# print(f'Num of repeated names: {len(heroes_df.name)-len(heroes_df.name.unique())}')\n",
    "\t# print('\\n')\n",
    "\n",
    "\tprint('heroes_df -  Missing Publisher values:'.upper())\n",
    "\t#print(f'Num unique: {len(heroes_df.Publisher.unique())}')\n",
    "\tprint(f'Num missing: {heroes_df.Publisher.isna().sum()} out of {len(heroes_df.Publisher)}, ({round((heroes_df.Publisher.isna().sum() /len(heroes_df.Publisher) * 100),2) }%)')\n",
    "\t# print(f'{heroes_df.Publisher.isna().sum()/len(heroes_df.Publisher)*100}%')\n",
    "\tprint('\\n')\n",
    "\n",
    "\tprint('heroes_df - Missing Weight values:'.upper())\n",
    "\t# print(f'Num missing: {heroes_df.Weight.isna().sum()}')\n",
    "\tprint(f'Num missing: {heroes_df.Weight.isna().sum()} out of {len(heroes_df.Weight)}, ({round((heroes_df.Weight.isna().sum() /len(heroes_df.Weight) * 100),2) }%)')\n",
    "\tprint('\\n')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL (sect 05)\n",
    "\n",
    "### Using sqlite3 with SQL databases\n",
    "```python\n",
    "import sqlite3\n",
    "connection = sqlite3.connect('pet_database.db') # Creates pet_database, but empty until create a table    \n",
    "cursor = connection.cursor()\n",
    "\n",
    "# use the corsor to execute sql commands\n",
    "cursor.execute(''' \n",
    "CREATE TABLE cats (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    age INTEGER,\n",
    "    breed TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "# Insert into table\n",
    "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES ('Maru', 3, 'Scottish Fold');''')\n",
    "# Select from table\n",
    "cursor.execute('''SELECT name FROM cats;''').fetchall()\n",
    "\n",
    "# Select only distinct entries\n",
    "cursor.execute('''SELECT DISTINCT name FROM cats;''').fetchall()\n",
    "# Selecting by conditionals using WHERE\n",
    "cursor.execute('''SELECT * FROM [table name] WHERE [column name] = [some value];''').fetchall()\n",
    "\n",
    "# Altering a table \n",
    "cursor.execute('''ALTER TABLE cats ADD COLUMN notes text;''')\n",
    "# Updating data\n",
    "cursor.execute('''UPDATE [table name] SET [column name] = [new value] WHERE [column name] = [value];''')\n",
    "# Deleting data\n",
    "cursor.execute('''DELETE FROM [table name] WHERE [column name] = [value];''')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Notes on Displaying Query Outputs\n",
    "```python \n",
    "    import pandas as pd\n",
    "    #Demonstrating running a query and previewing results as pandas DataFrame\n",
    "    results = cursor.execute(\"\"\"select * from planets;\"\"\").fetchall()  \n",
    "    df = pd.DataFrame(results)\n",
    "    df. columns = [i[0] for i in cursor.description]\n",
    "    df.head()\n",
    "\n",
    "    # CAN MAKE A FUNCTION TO SIMPLIFY\n",
    "    def sql_select_to_df(SQL_COMMAND, cur=cursor):\n",
    "        results = cur.execute(SQL_COMMAND).fetchall()\n",
    "        df = pd.DataFrame(results)\n",
    "        df.columns = [i[0] for i in cur.description]\n",
    "        return df\n",
    "    \n",
    "    # Call function to select data\n",
    "    df = sql_select_to_df(\"\"\"select * from planets;\"\"\")\n",
    "    df.head()\n",
    "    \n",
    "    # Select with function + conditional\n",
    "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE mass > 1;\"\"\")\n",
    "    df.head()\n",
    "    \n",
    "    # Select with AND \n",
    "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE (num_of_moons>1 AND mass < 1);\"\"\")\n",
    "    df.head()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering and Ordering\n",
    "```python\n",
    "# ORDER BY\n",
    "cursor.execute('''SELECT column_name FROM table_name ORDER BY column_name ASC|DESC;''').fetchall()\n",
    "# LIMIT\n",
    "cursor.execute('''SELECT * FROM cats ORDER BY age DESC LIMIT 3;''').fetchall() #Fetch top 3\n",
    "cursor.execute('''SELECT * FROM cats ORDER BY age DESC;''').fetchone() #returns the first \n",
    "# BETWEEN\n",
    "cursor.execute('''SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2;''').fetchall()\n",
    "# NULL - placeholder\n",
    "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES (NULL, NULL, \"Tabby\");''')\n",
    "#SELECT BY NULL\n",
    "SELECT * FROM cats WHERE name IS NULL;\n",
    "# COUNT\n",
    "SELECT COUNT([column name]) FROM [table name] WHERE [column name] = [value];\n",
    "# GROUPBY\n",
    "SELECT breed, COUNT(breed) FROM cats GROUP BY breed;\n",
    "SELECT breed, owner_id, COUNT(breed) FROM cats GROUP BY breed, owner_id;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-Oriented Programming (Sect 06-07)\n",
    "\n",
    "\n",
    "### Defining classes \n",
    "\n",
    "```python\n",
    "# Must define class NameConventionCase\n",
    "class MyNewClass: \n",
    "    pass # If no attributes, must pass\n",
    "# Instantiate an MyNewClass object\n",
    "new_instance = MyNewClass() \n",
    "\n",
    "```\n",
    "### Class Attributes & Methods \n",
    "* Instance methods are like attributes, but are *callable.*\n",
    "* When calling a object **.method()**, the object *implicitly* called\n",
    "    * Must use `self` to tell methods to expect input variable \n",
    "\n",
    "```python \n",
    "# Defining an instance method:\n",
    "class Dog():\n",
    "    def bark(self):\n",
    "        return \"Ruh-roh!\"\n",
    "    def needs_a_walk(self):\n",
    "        self.gotta_go = False \n",
    "        return 'Phew that was close!'\n",
    "    def whose_a_good_dog(self, name):\n",
    "        return f'Whos a good dog???\"\\n {name.title()} is!'  \n",
    "\n",
    "# Calling an instance method\n",
    "new_rex = Dog()\n",
    "new_rex.bark() # Ruh-roh!\n",
    "new_rex.whose_a_good_dog('Fido')\n",
    "\n",
    "```\n",
    "\n",
    "###  Instance Variables & Setters and Getters\n",
    "\n",
    "```python \n",
    "# _instance_ variables are protected from unwanted external edits\n",
    "# They have class.methods() defined to set and get the values.\n",
    "class BankAccount():\n",
    "    \n",
    "    def set_balance(self, amount):\n",
    "        self._balance += amount    \n",
    "    def get_balance(self):\n",
    "        return self._balance\n",
    "        \n",
    "    def make_withdrawal(self, amount_requested):\n",
    "        if (self.check_min_bal(amount_requested)):\n",
    "            return self.check_min_bal(amount_requested)\n",
    "        else: \n",
    "            self.set_balance(-amount_requested)\n",
    "            return print(f'$ {amount_requested}')\n",
    "\n",
    "        # ---- Note: some code cut -----\n",
    "[BOOKMARK TO RETURN TO LATER]                \n",
    "## Using Properties with Setters & Getters\n",
    "\n",
    "# ----------- HERE is where we are using the property() function ----------------------------------- #\n",
    "    balance = property(get_balance, set_balance)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python        \n",
    "# Initializing Instance Objects Using _init_ \n",
    "class Business():\n",
    "    def __init__(name=None, biz_type=None, city=None, customers = {}):\n",
    "        business.name = name\n",
    "        business.biz_type = biz_type\n",
    "        business.city = city\n",
    "        business.customers = customers\n",
    "\n",
    "    # Normal function to instantiate a BankAccount\n",
    "    def make_account():\n",
    "        new_account = BankAccount()\n",
    "        new_account._balance = 0\n",
    "        new_account._minimum_balance = 250\n",
    "        new_account._max_withdrawal = 150 \n",
    "        return new_account\n",
    "```\n",
    "```python\n",
    "class Customer():\n",
    "    def __init__(self, name=None, orders=[], location=None):\n",
    "        self.name=name\n",
    "        self.orders = orders\n",
    "        self.location = location\n",
    "    def add_order(item_name, item_cost, quantity):\n",
    "        self.orders.append({'item_name': item_name, 'item_cost':item_cost, 'quantity':quantity})\n",
    "```\n",
    "\n",
    "```python\n",
    "\n",
    "# Simple / lazy way\n",
    "class Person:\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "    def set_job(self, job):\n",
    "        self.job = job\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NumPy & Arrays (section 08)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy & element-wise math operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Intitialize a np array\n",
    "import numpy as np\n",
    "x=np.array([1,10,20,30]) \n",
    "print(x)\n",
    "\n",
    "#np  Array Math Operations\n",
    "print('x*3 =', x * 3 ) # Array .* (element-wise function)\n",
    "print('[1,2,3] * 3=' ,[1,2,3] * 3)\n",
    "print('x + 2=',x + 2) #Adds two to each element\n",
    "# But can't do element-wise addition\n",
    "[1,2,3] + 2 # Returns an error; different data types\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Math\n",
    "Here arr = np array\n",
    "```python\n",
    "np.add(arr,1) # Add 1 to each array element\n",
    "np.subtract(arr,2) # Subtract 2 from each array element\n",
    "np.multiply(arr,3) # Multiply each array element by 3\n",
    "np.divide(arr,4) # Divide each array element by 4 (returns np.nan for division by zero)\n",
    "np.power(arr,5) # Raise each array element to the 5th power  \n",
    "```\n",
    "### Vector Math\n",
    "Here arr1, arr2 are both np arrays\n",
    "```python\n",
    "np.array_equal(arr1,arr2) # Returns True if the arrays have the same elements and shape\n",
    "\n",
    "np.add(arr1,arr2) # Elementwise add arr2 to arr1\n",
    "np.subtract(arr1,arr2) # Elementwise subtract arr2 from arr1\n",
    "np.multiply(arr1,arr2) # Elementwise multiply arr1 by arr2\n",
    "np.divide(arr1,arr2) # Elementwise divide arr1 by arr2\n",
    "\n",
    "np.power(arr1,arr2) # Elementwise raise arr1 raised to the power of arr2\n",
    "np.sqrt(arr) # Square root of each element in the array\n",
    "np.log(arr) # Natural log of each element in the array\n",
    "\n",
    "np.abs(arr) # Absolute value of each element in the array\n",
    "np.ceil(arr) # Rounds up to the nearest int\n",
    "np.floor(arr) # Rounds down to the nearest int\n",
    "np.round(arr) # Rounds to the nearest int\n",
    "\n",
    "np.sin(arr) # Sine of each element in the array\n",
    "```\n",
    "### Appending / adding elements\n",
    "```python\n",
    "[1,2,3] + [4,5,6] #Adding raw lists is just appending\n",
    "np.array([1,2,3]) + np.array([4,5,6]) #Adds elements\n",
    "\n",
    "#Same as above with built in method\n",
    "x = np.array([1,2,3])\n",
    "y = np.array([4,5,6])\n",
    "np.add(x,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-dimensional Arrays with Numpy\n"
   ]
  },
  {
   "attachments": {
    "ScreenClip.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numpy displays arrays in more user friendly way ( rows above rows)\n",
    "    * <img style=float src=\"attachment:ScreenClip.png\" align=\"left\"/>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* np.shape returns length of each dimensions (row, col, __) \n",
    "\n",
    "```python\n",
    "    y = np.array([[1,2,3],[4,5,6]])\n",
    "    print(y.shape) # (2,3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Functions for Creating Arrays\n",
    "```python\n",
    "# np.zeroes(shape) and np.ones(shape)\n",
    "    np.zeros(5) # #one dimensional; 5 elements, all 0\n",
    "    np.zeros([2,2]) #two dimensional; 2x2 matrix\n",
    "    np.zeros([3,4,5]) #3 dimensional; 3 4x5 matrices\n",
    "    \n",
    "    np.ones(shape) # Returns 1's\n",
    "\n",
    "# np.full(shape,fill) \n",
    "    np.full(shape, fill) # fill array with arbitrary values\n",
    "    np.full(5, 3) #Create a 1d array with 5 elements, all of which are 3\n",
    "    np.full(5, range(5)) #Create  array with 5 elements (0-4) (ONLY WORKS WITH 1-2 DIMENSIONS)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP Array Indexing / Subsetting\n",
    "```python\n",
    "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
    "print(x.shape) #(4,3)\n",
    "#Result displays as:\n",
    "np.array([[1,2,3], \n",
    "          [4,5,6], \n",
    "          [7,8,9], \n",
    "          [10,11,12]])\n",
    "\n",
    "# Slice rows with 1 index:\n",
    "x[0] # array([1,2,3])\n",
    "\n",
    "#Slice rows, columns  \n",
    "# x[slice_dim1, slice_dim2]\n",
    "x[:,0] #All rows, column 0\n",
    "\n",
    "# If array has more than 2 dimensions:   \n",
    "print(\"NOTE: [!] If have multi-dim array (3+ dim), can't use row,col indexing!!\")\n",
    "\n",
    "#To slice along a second dimension with lists - list comprehension\n",
    "[i[0] for i in x] #returns first element from each row \n",
    "\n",
    "#Doing this in multiple dimensions with lists\n",
    "[i[1:3] for i in x[2:4]] #returns rows (second-third), columns (third:fourth) [[8,9],[11,12]]\n",
    "```\n",
    "\n",
    "#### Slicing 3D arrays\n",
    "```python \n",
    "#With an array\n",
    "x = np.array([\n",
    "              [[1,2,3], [4,5,6]],\n",
    "              [[7,8,9], [10,11,12]]\n",
    "             ])\n",
    "x\n",
    "    #returns: \n",
    "    array([[[ 1,  2,  3],\n",
    "            [ 4,  5,  6]],\n",
    "\n",
    "           [[ 7,  8,  9],\n",
    "            [10, 11, 12]]])\n",
    "\n",
    "# Array is 3-D\n",
    "x.shape #(2,2,3)\n",
    "# 3-D indexing\n",
    "x[:,:,-1]\n",
    "#returns last element of ebery row, col:\n",
    "array([[ 3,  6],\n",
    "   [ 9, 12]])\n",
    "```\n",
    "\n",
    "### Get unique vanlues and counts from a np array\n",
    "values, counts = np.unique(np_it, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATISTICS AND PROBABILITY (Section 08)\n",
    "\n",
    "### Set definions\n",
    "#### set :  \n",
    "- a *well-defined colletion of objects*.\n",
    "- _Math notation:_\n",
    "    - define a set by $S$. \n",
    "    - If an element $x$ belongs to a set $S$:\n",
    "        - $x \\in S$.\n",
    "    - If $x$ does not belong to a set $S$:\n",
    "        - $x\\notin S$.\n",
    "        \n",
    "#### subset: \n",
    "- set $T$ is a subset of set $S$ if *every element* in set $T$ is also in set $S$. \n",
    "    - Notation for a subset is $T \\subset S$.   \n",
    "        - $T$ and $S$ can be the SAME\n",
    "    - If $T$ != $S$, but $T \\subset S$, called a '_proper subset_'\n",
    "        - Can use notation:  $T \\subsetneq S$ and $T \\subseteq S$ \n",
    "\n",
    "#### Universal set:\n",
    "- The collection of all possible outcomes in a certain context or universe.\n",
    "    -  often denoted by $\\Omega$.\n",
    "    - Example: all possible outcomes of a 6-sided die:\n",
    "        - $\\Omega = \\{1,2,3,4,5,6\\}$\n",
    "    - Can have infinite # of elements (e.g. the set of all real numbers!)\n",
    "\n",
    "### Set operations:\n",
    "- Data used in examples:\n",
    "\n",
    "Imagine you have two sets of numbers, say the first 4 multiples of 3 in set $S$:\n",
    "\n",
    "$ S = \\{3,6,9,12\\}$\n",
    "\n",
    " and the first 4 multiples of 2 in set $T$:\n",
    " \n",
    "$ T = \\{2,4,6,8\\} $.\n",
    "\n",
    "#### Union (combining elements)\n",
    "- the union of $S$ and $T$ is denoted as $S \\cup T$\n",
    "\n",
    "#### Intersection\n",
    "- contains all elements of $S$ that also belong to $T$. \n",
    "    - denoted as $S \\cap T$.\n",
    "    \n",
    "#### Relative complement / difference\n",
    "-  the relative complement of S contains all the elements of T that are NOT in S.\n",
    "    - relative complement of S (or $ T\\backslash S $) is $\\{2,4,8\\}$.\n",
    "    - relative complement  of T (or $ S\\backslash T $) is $\\{3,9,12\\}$.\n",
    "\n",
    "#### Absolute complement\n",
    "- The absolute complement of $S$, with respect to the Universal set $\\Omega$, is the collection of the objects in $\\Omega$ that don't belong to $S$.\n",
    "    -  absolute complement of $S$ is denoted as $S'$ or $S^c$.\n",
    "\n",
    "- Example: Let's define $\\Omega$ (box around the two venn diagrams) = multiples of both 2 and 3 until 20.\n",
    "\n",
    "    - Elements of $\\Omega$ are $\\{2,3,4,6,8,9,10,12,14,15,16,18,20\\}$. \n",
    "\n",
    "    - The absolute complement of $S$ (so $S'$ or $S^c$) is then given by $\\{2,4,8,10,14,15,16,18,20\\}$.\n",
    "    \n",
    "#### Inclusion Exclusion principle\n",
    "- When combining  2 sets, the method for obtaining the union of two finite sets is given by:\n",
    "\n",
    "    - $\\mid S \\cup T \\mid = \\mid S \\mid + \\mid T \\mid - \\mid S \\cap T \\mid $\n",
    "    \n",
    "        - Horizontal lines denote the *cardinality* of a set, which is the number of elements, considering a finite set. \n",
    "        \n",
    "        \n",
    "- *The formula expresses the fact that the sum of the sizes of the two sets may be too large since some elements may be counted twice. For the double-counted elements, one is substracted again.*\n",
    "\n",
    "### Empty \n",
    " - An **empty** set has no elements\n",
    " - denoted by $\\emptyset$ or simply $\\{\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Space & Event Space\n",
    "#### Sample space:\n",
    "$$S = \\{ 1,2,3,4,5,6\\}$$ \n",
    "being the possible outcomes when throwing a dice.\n",
    "\n",
    "#### Event space:\n",
    "-   The **event space** is a subset of the sample space, $$E \\subseteq S$$\n",
    "-   Example:\n",
    "    -   Throwing an odd number would lead to an event space $$E = \\{ 1,3,5\\}$$.\n",
    "\n",
    "### Law of relative frequency\n",
    "-   Event E, the P(E) (probability of E), n =\\# of experiments, S(n)=successful\n",
    "    experiments\n",
    "\n",
    "![](media/3678f57f44336ac27981e0cd1664b19f.png)\n",
    "\n",
    "#### Probability axioms\n",
    "\n",
    "1.  Positivity : Prob is always 0 \\<= P(E) \\<=1\n",
    "\n",
    "2.  Probability of a certain event: P(S)=1\n",
    "\n",
    "3.  Additivity Union of 2 exclusive sets = sum prob of individual events\n",
    "    happening\n",
    "\n",
    "    ![](media/dad1bc9976ba1aeb37bbb5e1b694e26a.png)\n",
    "\n",
    "### Addition law of probability \n",
    "\n",
    "-   Prob of union of A and B is individual P minus intersection\n",
    "\n",
    "    ![](media/c5796f303440c76665beb09eb299f156.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO: test probability of an event: \n",
    "\n",
    "1.  What is the prob of E happening at least once?\n",
    "\n",
    "    1.  Get Boolean result for E:  \n",
    "        Set_E =sample_population == E\n",
    "\n",
    "    2.  Verify condition:  \n",
    "        true_E=np.any(set_E, axis = 1)\n",
    "\n",
    "    3.  Prob_E=np.sum(true_E)/len(sample_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutations and Factorials:\n",
    "----------------------------\n",
    "\n",
    "### Permutations of a subset\n",
    "\n",
    "How many ways can we select k elements out of a pool of n objects?\n",
    "\n",
    "![](media/93405e47675b1e706fed18dbb001768b.png)\n",
    "\n",
    "### Permutations with replacement \n",
    "\n",
    "\\# of possible options doesn’t change, so n is raised to the power of j, the\n",
    "number of draws from the pop\n",
    "\n",
    "*nj*\n",
    "\n",
    "### Permutations with repetition \n",
    "\n",
    "The \\# of permutations of *n* objects with identical objects of type 1 (*n­1 )*\n",
    "and type 2 ( *n2)*\n",
    "\n",
    "![](media/00ff12464dd108477fd6a5dbeac9868d.png)\n",
    "\n",
    "[./media/image6.png](./media/image6.png)\n",
    "\n",
    "### Statistical Distribtuions + Linear Regression\n",
    "\n",
    "[./media/image7.png](./media/image7.png)\n",
    "\n",
    "### Distributions: Discrete vs Continuous \n",
    "#### Discrete Distributions\n",
    "-   Bernoulli = Repeated trials of binary outcome event. ( x successes in n trials)(flipping a coin)\n",
    "-   Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
    "-   Poisson = The probability of n events in a given time period when overall rate of occurrence is constant (i.e. receiving mail)\n",
    "-   Uniform = all outcomes equally likely\n",
    "\n",
    "#### Continuous Distributions\n",
    "\n",
    "-   Normal / gaussian = single ost important for data analysis, occurs very\n",
    "    frequently in real-world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [ ] Probability Mass Function (PMF)\n",
    "\n",
    "-   Also called a Frequency Function. Converts frequency of events to\n",
    "    probability of a particular outcome of a discrete function, by normalizing\n",
    "    such that sum of all outcomes == 1.\n",
    "\n",
    "-   Gives probability for discrete random variables, if we have x outcomes, we\n",
    "    want to know what is the probability of getting k (our value of interest)\n",
    "    from x\n",
    "\n",
    "### [ ] CUMULATIVE DENSITY FUNCTION\n",
    "\\-[etc[\n",
    "\n",
    "### [ ] PROBABILITY DENSITY FUNCTION\n",
    "-   For continuous data, etc\n",
    "![](media/17f3df4583df554db7f48b9123e39aad.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to convert freq - \\> prob for PMF*  \n",
    "```python\n",
    "import numpy as np  \n",
    "import collections  \n",
    "x = [1,1,1,1,2,2,2,2,3,3,4,5,5]\n",
    "\n",
    "counter = collections.Counter(x)  \n",
    "\\# Convert frequency to probability - divide each frequency value by total\n",
    "number of values\n",
    "\n",
    "pmf = []\n",
    "for key,val in counter.items():\n",
    "    pmf.append(round(val/len(x), 2))\n",
    "    print(counter.keys(), pmf)  \n",
    "  \n",
    "# Proof that is normalized to overall prob of 1 (needed for PMF)  \n",
    "np.array(pmf).sum()\n",
    "\n",
    "# Visualizing PMF – similar to histogram, but normalized to P=1*  \n",
    "import matplotlib.pyplot as plt  \n",
    "plt.style.use(‘ggplot’)  \n",
    "  \n",
    "plt.stem(counter.keys(), pmf)  \n",
    "```\n",
    "![](media/e51d10e06e9b70069c792d9fa8172e5e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "### Using statsmodels to run Ordinary Least Squares Regressions*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# TESTING ASSUMPTIONS AND RUNNING LINEAR REGRESSION\n",
    "\\# For all the variables, check if they hold normality assumption\n",
    "for column in data:\n",
    "    data[column].plot.hist(normed=True, label = column+' histogram')\n",
    "    data[column].plot.kde(label =column+' kde')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "![](media/a0ddfd1b41d9348b678840beeb05cd27.png)\n",
    "\n",
    "# [Test linearity assumption] visualize the relationship between the preditors and the target using scatterplots\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['TV', 'radio', 'newspaper']):\n",
    "    data.plot(kind='scatter', x=channel, y='sales', ax=axs[idx], label=channel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "![](media/f216f3686df0bc39bd30a6cd13f45993.png)\n",
    "\n",
    "# Run a simple regression in **statsmodels**\n",
    "# import libraries\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# build the formula\n",
    "f = 'sales\\~TV'\n",
    "\n",
    "# create a fitted model in one line\n",
    "model = smf.ols(formula=f, data=data).fit()\n",
    "model.summary() \\# Will spit out stastics and coefficients, R2\n",
    "\n",
    "## Draw the prediction line from the model with the scatter plot:  \n",
    "# We can use model.predict() functions to predict start and end point of regression line for min and max values in variable]\n",
    "\n",
    "# create a DataFrame with the minimum and maximum values of TV\n",
    "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
    "print(X_new.head())\n",
    "\n",
    "\\# make predictions for those x values and store them\n",
    "preds = model.predict(X_new)\n",
    "print (preds)\n",
    "\n",
    "\\# first, plot the observed data and the least squares line\n",
    "data.plot(kind='scatter', x='TV', y='sales')\n",
    "plt.plot(X_new, preds, c='red', linewidth=2)\n",
    "plt.show()\n",
    "```\n",
    "![](media/79706ce0909dbf6a29f02a441cc4dd4a.png)\n",
    "\n",
    "```python\n",
    "# Visualize the error term for variance and heteroscedasticity:\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(model, \"TV\", fig=fig)\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](media/8b847a77d81a31166697e6c519f543c6.png)\n",
    "\n",
    "**For the four graphs we see above:**\n",
    "\n",
    "-   The “Y and Fitted vs. X” graph plots the dependent variable against our\n",
    "    predicted values with a confidence interval. The positive relationship shows\n",
    "    that height and weight are correlated correlated, i.e., when one variable\n",
    "    increases the other increases.\n",
    "\n",
    "-   The “Residuals versus height” graph shows our model's errors versus the\n",
    "    specified predictor variable. Each dot is an observed value; the line\n",
    "    represents the mean of those observed values. Since there's no pattern in\n",
    "    the distance between the dots and the mean value, the OLS assumption of\n",
    "    homoskedasticity holds.\n",
    "\n",
    "-   The “Partial regression plot” shows the relationship between height and\n",
    "    weight, taking in to account the impact of adding other independent\n",
    "    variables on our existing height coefficient. We'll see later how this same\n",
    "    graph changes when we add more variables.\n",
    "\n",
    "-   The Component and Component Plus Residual (CCPR) plot is an extension of the\n",
    "    partial regression plot, but shows where our trend line would lie after\n",
    "    adding the impact of adding our other independent variables on the weight.\n",
    "    We shall look at this in more detail in multiple regression.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Diagnostics in Statsmodels\n",
    "- We’ve already used R2 value (from ols model.summary()) and visualization to confirm if the data and residuals fit the assumptios. Here we will learn procedures to further understand our model and results.\n",
    "\n",
    ">   *Regression diagnostic is a set of procedures available for regression\n",
    ">   analysis that seek to assess the validity of a model in any of a number of\n",
    ">   different ways. This assessment may be an exploration of the model's\n",
    ">   underlying statistical assumptions, an examination of the structure of the\n",
    ">   model by considering formulations that have fewer, more or different\n",
    ">   explanatory variables, or a study of subgroups of observations, looking for\n",
    ">   those that are either poorly represented by the model (outliers) or that\n",
    ">   have a relatively large effect on the regression model's predictions.*\n",
    ">   [Wiki](https://en.wikipedia.org/wiki/Regression_diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q Plots to check normality (also called normal density plots when used with standard normal quantiles)\n",
    "\n",
    "- These plots are good way to inspect the distribution of model errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)\n",
    "f = 'sales\\~TV' \n",
    "f2 = 'sales\\~radio' \n",
    "model = smf.ols(formula=f, data=data).fit() \n",
    "model2 = smf.ols(formula=f2, data=data).fit() \n",
    "resid1 = model.resid \n",
    "resid2 = model2.resid \n",
    "\n",
    "fig = sm.graphics.qqplot(resid2, dist=stats.norm, line='45', fit=True) \n",
    "fig.show() \n",
    "```\n",
    "~~img src=\"media/9707e080f47e37b45f414bc7adcf1ad0.png\" width=400>~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal Q-Q Plots are a direct visual assessment of how well our residuals\n",
    "match what we would expect from a normal distribution.**\n",
    "\n",
    "In terms of Q-Q plots above, we can see that residuals are better normally\n",
    "distributed in the case of TV than that of radio. We can also spot an outlier in\n",
    "the left tail of radio residuals, dealing with this might help improve the\n",
    "fitness of the model. Outliers, skew, heavy and light-tailed aspects of\n",
    "distributions (all violations of normality) can be assessed from Q-Q plots\n",
    "\n",
    "-   Example Q-Q plots vs histogram/density plot (to help learn what Q-Q plot is\n",
    "    saying:\n",
    "<img src=\"media/bea1c75ce827d7327861c28b229667b2.png\" width=600>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression*\n",
    "\n",
    "\n",
    "### HOW TO: BLOG POST ON LINEAR REGRESSION IN PYTHON:\n",
    "\n",
    "<https://www.dropbox.com/s/bzg4o8ndtu70byg/Linear%20Regression%20in%20Python%20-%20Blog%20Post.pdf?dl.0=0>\n",
    "\n",
    "- Step 1: visualization\n",
    "    1.  Look for linear relationship – use Seaborn’s pairplot sns.pairplot(data, x_vars = [b1,b2,b3], y_vars=’Sales’,kind=’reg’)  \n",
    "        \\# Note, can also pass ‘size= “ for change plot size.  \n",
    "        \\# kind = ‘reg’ attempts to add line of best fit and 95% confidence interval (will aim to minimize the sum of squared error)\n",
    "\n",
    "- Step 2: SK Learn – Setting Variables\n",
    "    1.  Scikit-Learn expects X to be a ‘feature matrix’ (Pandas DataFrame) and y to be a ‘response vector’\n",
    "    2.  X=dataframe. y = y from the dataframe\n",
    "    \n",
    "- Step 3: SK Learn – Splitting our data\n",
    "```python\n",
    "from sklearn.cross_validation import test_train_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "```\n",
    "- Step 4: SK Learn – Training our model\n",
    "\n",
    "```python \n",
    "# Import linear regression and instantiate  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "linreg = LinearRegression()  \n",
    "\n",
    "# Fit model to training data  \n",
    "linrg.fit(X_train, y_train)\n",
    "```\n",
    "- Step 5: Interpreting Coefficients\n",
    "```python \n",
    "print(lingreg.intercept_) \\# prints y-intercept, BO  \n",
    "print(linreg.coef_) \\# prints beta coeffiicents in same order as passed  \n",
    "zip(feature_cols, linreg.coef_) \\# Pair feature names and coefficients\n",
    "```\n",
    "- Step 6: Making predictions  \n",
    "```python\n",
    "y_pred = linreg.predict(X_test)\n",
    "```\n",
    "- Step 7: Model Evaluation  \n",
    "```python \n",
    "from sklearn import metrics  \n",
    "\\# Most popular metric to use is root-mean-square-error (RMSE)  \n",
    "print(np.sqrt(metrics.mean_squared_error(y_true, y_pred)))  \n",
    "\\#People also use Mean Absolute Error or Mean-Squared Error, but harder to interpret\n",
    "```\n",
    "- Step 8: Feature selection:\n",
    "\n",
    "    1.  Once have error metric, take note which X’s have minimal impact on y.\n",
    "        1.  Removing some of these may increase the accuracy of the model\n",
    "    2.  Now, process of trial and error, starting over again (dropping columns) until reach a satisfactory model\n",
    "    3.  Recommended Steps:\n",
    "        1.  Replace feature_cols & X\n",
    "        2.  Train_test_split your data\n",
    "        3.  Fit the model to linreg again using linreg.fit\n",
    "        4.  Make predictions using (y_pred = linreg.predict(X_test))\n",
    "        5.  Compute RMSE\n",
    "        6.  Repeat until RMSE satisfactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code from: FEATURE SCALING AND NORMALIZATION LAB:\n",
    "\n",
    "1.  Performing binning / as categories for numerical categorical variables for\n",
    "    regression, create dummy variables ( and replace orig):\n",
    "    \n",
    "```python\n",
    "# first, create bins for based on the values observed. 5 values will result\n",
    "in 4 bins\n",
    "\n",
    "bins = [0, 3, 4 , 5, 24]\n",
    "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
    "bins_rad = bins_rad.cat.as_unordered()\n",
    "\n",
    "# first, create bins for based on the values observed. 5 values will result in 4 bins\n",
    "\n",
    "bins = [0, 250, 300, 360, 460, 712]\n",
    "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
    "bins_tax = bins_tax.cat.as_unordered()\n",
    "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\")\n",
    "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\")\n",
    "\n",
    "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n",
    "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
    "boston_features = boston_features.drop(\"NOX\",axis=1)\n",
    "```\n",
    "\n",
    "2.  Filtering out the columns of a dataframe using drop, filter, and regex :\n",
    "\n",
    "```python \n",
    "df= boston_features\n",
    "boston_cont = df[df.columns.drop(list(df.filter(regex='TAX')))]\n",
    "boston_cont = boston_cont[boston_cont.columns.drop(list(boston_cont.filter(regex='RAD')))]\n",
    "boston_cont= boston_cont.drop(['CHAS'], axis=1)\n",
    "```\n",
    "\n",
    "3.  Different Tpes of transformations on the dataframe:\n",
    "\n",
    "```python\n",
    "data_log = df_log\n",
    "age = boston_cont[\"AGE\"]\n",
    "b = boston_cont[\"B\"]\n",
    "rm = boston_cont[\"RM\"]\n",
    "logcrim = data_log[\"CRIM\"]\n",
    "logdis = data_log[\"DIS\"]\n",
    "logindus = data_log[\"INDUS\"]\n",
    "loglstat = data_log[\"LSTAT\"]\n",
    "logptratio = data_log[\"PTRATIO\"]\n",
    "features_final= pd.DataFrame([])\n",
    "\n",
    "features_final[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
    "features_final[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "features_final[\"RM\"] = (rm-min(rm))/(max(rm)-min(rm))\n",
    "features_final[\"DIS\"] = (logdis-np.mean(logdis))/np.sqrt(np.var(logdis))\n",
    "features_final[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
    "features_final[\"LSTAT\"] = (loglstat-np.mean(loglstat))/(max(loglstat)-min(loglstat))\n",
    "features_final[\"AGE\"] = (age-np.mean(age))/(max(age)-min(age))\n",
    "features_final[\"PTRATIO\"] = (logptratio)/(np.linalg.norm(logptratio))\n",
    "```\n",
    "### Code from: Regression modeling with Boston Housing Dataset\n",
    "\n",
    "![](media/05194d71a28f0a54e57e63ea704f485b.png)\n",
    "\n",
    "```python\n",
    "\\# Your code here\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# The results will be saved in results list\n",
    "results = [['ind_var','r_sqared','intercept','slope','p-value','norm_JB']]\n",
    "\n",
    "# TO LOOP THROUGH LIST OF DATACOLUMNS TO RUN OLS REGRESSION + PRINT/SAVE RESULTS*\n",
    "for idx, val in enumerate(['crim','dis','rm','zn','age']):\n",
    "    print (\"Boston Housing DataSet - Regression Analysis and Diagnostics for\n",
    "    formula: medv\\~\" + val)\n",
    "\n",
    "    print\n",
    "    (\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "    f = 'medv\\~' + val\n",
    "    model = smf.ols(formula=f,data=data).fit()\n",
    "    X_new = pd.DataFrame({val: [data[val].min(),data[val].max()]}\n",
    "    preds= model.predict(X_new)\n",
    "\n",
    "    data.plot(kind='scatter',x=val,y='medv')\n",
    "    plt.plot(X_new,preds,c='red',linewidth=2)\n",
    "    plt.show()\n",
    "\n",
    "    fig=plt.figure(figsize=(15,8))\n",
    "    fig = sm.graphics.plot_regress_exog(model, val, fig=fig)\n",
    "    fig = sm.graphics.qqplot(model.resid,dist=stats.norm, line='45',fit=True )\n",
    "    plt.show\n",
    "                         \n",
    "    results.append([val,model.rsquared,model.params[0],model.params[1],model.pvalues[1],sms.jarque_bera(model.resid)[0]])\n",
    "    input('Press Enter to continue...')\n",
    "```\n",
    "### Code from: Dealing with categorical variables lab\n",
    "```python\n",
    "# Get list of column names (to use for plotting from df)*\n",
    "names = boston_df.columns\n",
    "nameList = [str(x) for x in names]\n",
    "col_names = nameList[1:]\n",
    "print(col_names)\n",
    "\n",
    "# Loop through each column to plot\n",
    "for col in col_names:\n",
    "plt.figure()\n",
    "plt.scatter(boston_df[col],boston_df['MEDV'],label=col,marker='.')\n",
    "plt.legend()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION MODEL VALIDATION\n",
    "\n",
    "- using train-test-split\n",
    "\n",
    "![](media/480152d587e701dde0f1599c9d684426.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Using train-test-split from sklearn*\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "lingreg=LinearRegression(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)  \n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "train_residuals = y_hat_train – y_train  \n",
    "test_residuals = y_hat_test – y_test\n",
    "\n",
    "mse_train = np.sum((y_train – y_hat_train)\\*\\*2/len(y_train)  \n",
    "mse_test = np.sum((y_test – y_hat_test)\\*\\*2/len(y_test)\n",
    "```\n",
    "\n",
    "**Select columns using regex**\n",
    "```python\n",
    "df.filter(regex=('Mark'),axis=1).describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR FIRST EXAMPLE COMPLETE PROJECT (Section 12)\n",
    "\n",
    "### Modeling Our Data Lab/Lesson:\n",
    "\n",
    "-   Load in pre-cleaned file\n",
    "    -   This is after having cleaned the dataset and made dummy variables.\n",
    "    -   Must re-cast categories as categories when reloading data\n",
    "\n",
    "-   If there are a lot of possible predictors, should try starting with single\n",
    "    linear regressions (on CONTINUOUS)\n",
    "    -   Using statsmodels.formula.api as smf\n",
    "    \n",
    "```python\n",
    "\n",
    "import statsmodels.formula.api as smf  \n",
    "# .describe used to select non-categorical values, then drop target var\n",
    "col_names = dataframe.describe().columns.drop(['Target_Var'])                                             \n",
    "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]                                               \n",
    "                                               \n",
    "# Use loop to run ols model with f=’Target_Variable\\~’+val\n",
    "for idx, val in enumerate(col_names):\n",
    "\n",
    "    print (\"Walmart: Weekly_Sales\\~\" + val)\n",
    "    print (\"------------------------------\")\n",
    "\n",
    "    f = 'Weekly_Sales\\~' + val\n",
    "    model = smf.ols(formula=f, data=walmart).fit()\n",
    "\n",
    "    X_new = pd.DataFrame({val: [walmart[val].min(), walmart[val].max()]})\n",
    "    preds = model.predict(X_new)\n",
    "\n",
    "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
    "    print(results[idx+1])                    \n",
    "                                               \n",
    "pd.DataFrame(results)\n",
    "                                               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Examine outputs:**\n",
    "\n",
    "        -   What do the parameter estimates mean? Do they make sense?\n",
    "        -   What do the p-values tell us?\n",
    "        -   What does the R-squared tell us?\n",
    "\n",
    "    -   If poor R-squared, re-examine distributions\n",
    "        -   Dataframe.hist()\n",
    "        \n",
    "    -   If skewed data can log transform:\n",
    "        -   If negative data:\n",
    "        ```python\n",
    "            -   walmart_log= walmart[walmart[\"Weekly_Sales\"]\\ 0]\n",
    "            -   walmart_log[\"Weekly_Sales\"]= np.log(walmart_log[\"Weekly_Sales\"])\n",
    "        ```\n",
    "-   **Re-run loop from earlier:**\n",
    "\n",
    "    -   compare and constrast the results with the results obtained when we did not take the log(sales)\n",
    "        -   Which one would you want to proceed with based on this?\n",
    "\n",
    "-   Build a model with each category variable as a predictor (can re-run data vs data-log, re-examine the R-square output)\n",
    "    -   Put all categories for one categorical variable in 1 model (so 4 models if 4 different categorical variables\n",
    "        -   IF USED DUMMY CODES, MUST DROP 1 FOR BETTER RESULTS (not explained)\n",
    "    -   Use output to judge choice of data vs data_log.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **Use the model results to identify variables that we can drop from the\n",
    "    model.**\n",
    "\n",
    "    -   Can do manually (drop from dataframe and re-run)\n",
    "    -   **Can Use RECURSIVE FEATURE ELIMINATION FOR X NUMBER OF FEATURES**\n",
    "\n",
    "        -   Create a for loop (below is 5-\\ 85 by 10’s)\n",
    "        \n",
    "```python\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "r_list = []\n",
    "adj_r_list = []\n",
    "list_n = list(range(5,86,10))\n",
    "for n in list_n:\n",
    "    select_n = RFE(linreg, n_features_to_select = n)\n",
    "    select_n = select_n.fit(X, np.ravel(y))\n",
    "    selected_columns = X.columns[select_n.support\\_ ]\n",
    "\n",
    "    linreg.fit(X[selected_columns],y)\n",
    "    yhat = linreg.predict(X[selected_columns])\n",
    "\n",
    "    SS_Residual = np.sum((y-yhat)\\*\\*2)\n",
    "    SS_Total = np.sum((y-np.mean(y))\\*\\*2)\n",
    "\n",
    "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "    print(r_squared)\n",
    "\n",
    "    adjusted_r_squared = 1 - (1-r_squared)\\*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "    print(adjusted_r_squared)\n",
    "    r_list.append(r_squared)\n",
    "    adj_r_list.append(adjusted_r_squared)\n",
    "```\n",
    "\n",
    "> “What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!”\n",
    "\n",
    "-   Can do a 10-fold cross validation with the final model.\n",
    "```python\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        # select 85 best predictors\n",
    "        select_85 = RFE(linreg, n_features_to_select = 85)\n",
    "        select_85 = select_n.fit(X, np.ravel(y))\n",
    "        selected_columns = X.columns[select_n.support_]\n",
    "        cv_10_results = cross_val_score(linreg, X[selected_columns], y, cv=10,\n",
    "        scoring=\"neg_mean_squared_error\")\n",
    "        cv_10_results\n",
    "```\n",
    "> “Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might\n",
    "cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOD 1 FINAL PROJECT Workflow Notes (section12)\n",
    "\n",
    "### Order of Processing (using OSEMN model)\n",
    "1.  **OBTAIN: Import data, inspect, check for datatypes to convert and null\n",
    "    values**\n",
    "\n",
    "    -   Display header and info\n",
    "\n",
    "    -   Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
    "\n",
    "2.  **SCRUB: cast data types, identify outliers, check for multicollinearity,\n",
    "    normalize data**\n",
    "\n",
    "    -   Check and cast data types\n",
    "\n",
    "        -    Check for \\#'s that are store as objects (df.info())\n",
    "\n",
    "            -   when converting to \\#'s, look for odd values (like many 0's), or\n",
    "                strings that can't be converted\n",
    "\n",
    "            -   Decide how to deal weird/null values (df.unique(),\n",
    "                df.isna().sum(), df.describe()-min/max, etc\n",
    "\n",
    "        -    Check for categorical variables stored as integers (for now cast as\n",
    "            strings)\n",
    "\n",
    "    -   Check for missing values (df.isna().sum())\n",
    "\n",
    "        -   Can drop rows or colums\n",
    "\n",
    "        -   For missing numeric data with median or bin/convert to categorical\n",
    "\n",
    "        -   For missing categorical data: make NaN own category OR replace with\n",
    "            most common category\n",
    "\n",
    "    -   Check for multicollinearity\n",
    "\n",
    "        -   use seaborn to make correlation matrix plot [Evernote\n",
    "            Link](https://www.evernote.com/l/AArNyaEwjA5JUL6I9PazHs_ts_hU-m7ja1I/)\n",
    "\n",
    "            -   Good rule of thumb is anything over 0.75 corr is high, remove\n",
    "                the variable that has the most correl with the largest \\# of\n",
    "                variables\n",
    "\n",
    "    -   Normalize data (may want to do after some exploring)\n",
    "\n",
    "        -   Most popular is Z-scoring (but won't fix skew)\n",
    "\n",
    "        -   Can log-transform to fix skewed data\n",
    "\n",
    "3.  **EXPLORE: Check distributions, outliers, etc**\n",
    "\n",
    "    -   Check scales, ranges (df.describe())\n",
    "\n",
    "    -   Use histograms to get an idea of distribut(df.hist())\n",
    "\n",
    "        -   Can also do kernel density estimates\n",
    "\n",
    "    -    use scatterplots to check for linearity and possible categorical\n",
    "        variables (df.plot(kind-'scatter')\n",
    "\n",
    "        -   categoricals will look like vertical lines\n",
    "\n",
    "    -    Use pd.plotting.scatter_matrix to visualize possible relationships\n",
    "\n",
    "    -   ADVANCED pair-wise comparison\n",
    "        via [joint-plots](https://seaborn.pydata.org/generated/seaborn.jointplot.html)\n",
    "\n",
    "        -   ns.jointplot(x= \\<column\\>, y= \\<column\\>, data=\\<dataset\\>,\n",
    "            kind='reg')\n",
    "\n",
    "    -   **Check for linearity**\n",
    "\n",
    "4.  **Fit an intiial model**\n",
    "\n",
    "    -   Various forms, detail later...\n",
    "\n",
    "    -   **Assessing the model:**\n",
    "\n",
    "        -   Assess parameters (slope,intercept)\n",
    "\n",
    "        -   Check if the model explains the variation in the data (RMSE, F,\n",
    "            R_square)\n",
    "\n",
    "        -   *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "\n",
    "        -   *Whats the impact of collinearity? Can we ignore?*\n",
    "\n",
    "5.  **Revise the fitted model**\n",
    "\n",
    "    -   Multicollinearity is big issue for lin regression and cannot fully\n",
    "        remove it\n",
    "\n",
    "    -   Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "\n",
    "    -   Check for missed non-linearity\n",
    "\n",
    "6.  **Holdout validation / Train/test split**\n",
    "\n",
    "    -   use sklearn train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expression in Beautiful Soup\n",
    "```python\n",
    "# Import required packages\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\\# Use beautiful soup to get declared url\n",
    "url = 'https://www.azlyrics.com/p/panicatthedisco.html' \\#Put the URL of\n",
    "your AZLyrics Artist Page here!\n",
    "\n",
    "html_page = requests.get(url) \\#Make a get request to retrieve the page\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser') \\#Pass the page contents to beautiful soup for parsing\n",
    "\n",
    "# Print html-nested structured result\n",
    "print(soup.prettify()[:1000])\n",
    "\n",
    "# Get all links that have 'panic'\n",
    "def get_links(soup,str='panic'):\n",
    "link_list=[]\n",
    "for link in soup.find_all('a'):\n",
    "\ttest_link = link.get('href')\n",
    "\n",
    "\tif str in test_link:\n",
    "        link_list.append(test_link)\n",
    "    return link_list\n",
    "\n",
    "# Use function\n",
    "panic_links = get_links(soup,’panic’)\n",
    "\n",
    "# Constructing reg exp to find the last 2 branches of web address (using / ... /... .html), and saves the band and song strings\n",
    "pattern = **r**'\\\\/(?P\\<band\\\\\\w\\*)\\\\/(?P\\<song\\\\\\w\\*).html'\n",
    "exp = re.compile(pattern) \\# the exp is a re object and can be used in methods OR functions.\n",
    "\n",
    "# save a list of the captured band and song tokens O\n",
    "result = []\n",
    "[result.append(exp.findall(x)) for x in panic_links]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "511.991px",
    "width": "347.998px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "My Flatiron Data Science Bootcamp Cheatsheet & Example Code",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "427.917px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "187.431px",
    "left": "1087.44px",
    "right": "20px",
    "top": "58px",
    "width": "426.417px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
