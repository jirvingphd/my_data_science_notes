{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My Flatiron Data Science Cheat Sheet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cn1OSOHfw3IF",
        "o-k1Ccyxw3IG",
        "zC6EHN0Tw3II",
        "jhAy_v9uw3IJ",
        "y5Gy431nw3IK",
        "pftDkY-Dw3IL",
        "b5TGEzlDw3IM",
        "p-ehdf4Tw3IN",
        "_UOFVo8tw3IO",
        "mrf7MwCxw3IP",
        "5kFGfU5Ww3IR",
        "tjWBMjYPw3IR",
        "jHB8gF-Qw3IT",
        "ikNZptfLw3IU",
        "z_ubqwvbw3IW",
        "tRJOMZpjw3IW",
        "rPAYDUHkw3IX",
        "ydclwM1Yw3IX",
        "2yqWh1lBw3IY",
        "-eVvlckzw3IZ",
        "90uxhG0jw3IZ",
        "t4afuY15w3Ia",
        "LbEnK7DMw3Ib",
        "LBdDjOWJw3Ic",
        "R4xed8CZw3Ic",
        "cvpxcVhWw3Id",
        "hdzJUmM7w3Id",
        "YyPLU2fow3Ie",
        "rNLT8dc0w3If",
        "I8np5K5-w3Ik",
        "rhPYaRHLw3Il",
        "k64fB1ERw3Il",
        "dqBG210rw3Iq",
        "kfcCbLb7w3It",
        "CnuN9U_Dw3Iw",
        "XtsXDMrHw3Iw",
        "NbrX3dQtw3Ix",
        "xPqhsqWpw3Iy",
        "-G7_Rvf_w3Iz",
        "vZXrNZA_w3I3",
        "czs6nSt4w3I6",
        "z6YFE_xCw3I7",
        "8mzckl1uw3I9",
        "NHvNraTZw3I9",
        "o7U20CLWw3I-",
        "Fd5Spg6Iw3JB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jirvingphd/my_data_science_notes/blob/master/My_Flatiron_Data_Science_Cheat_Sheet_Pre-Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wZ0HvYkww3Hu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**My Flatiron Data Science Bootcamp Cheatsheet & Example Code**\n",
        "- This document will contain both a short-hand collection of code to re-use + a more complete notes collection"
      ]
    },
    {
      "metadata": {
        "id": "VYvpNlFiw3Hv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CODE SNIPPET LIBRARY"
      ]
    },
    {
      "metadata": {
        "id": "Y5kik5CRw3Hw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataframes and filtering / indexing data\n",
        "\n",
        "#### Code to select pandas columns that don’t include string\n",
        "```python\n",
        "df_test =df_run.loc[:,\\~(df_run.columns.str.startswith('logZ'))]\n",
        "```\n",
        "#### code to turn a results list (starts as list with first row as column names)\n",
        "```python\n",
        "results = [['set\\#','R_square_train','MSE_train','R_square_test','MSE_test']]\n",
        "# …\n",
        "results.append([i,R_sqare_train,train_mse,R_square_test,test_mse])\n",
        "df_res=pd.DataFrame(results)\n",
        "df_res.columns=df_res.iloc[0,:]\n",
        "df_res = df_res[1:]\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "35N4kuVfw3Hx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Graphing Functions \n",
        "#### Example customized Seaborn displot+boxplot"
      ]
    },
    {
      "metadata": {
        "id": "aA7hBt9zw3Hy",
        "colab_type": "code",
        "outputId": "76b29398-1518-4e89-cd71-bf36dfaefd77",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Example customized Seaborn displot+boxplot\n",
        "import seaborn as sns\n",
        "import pandas as pd \n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "data = pd.read_csv('weight-height.csv')\n",
        "\n",
        "# Create two vertical subplots sharing 15% and 85% of plot space\n",
        "# sharex allows sharing of axes i.e. building multiple plots on same axes\n",
        "fig, (ax, ax2) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)}, figsize = (6,4) )\n",
        "\n",
        "sns.distplot(data.Height, \n",
        "             hist=True, hist_kws={\n",
        "                                  \"linewidth\": 2,\n",
        "                                  \"edgecolor\" :'salmon',\n",
        "                                  \"alpha\": 0.4, \n",
        "                                  \"color\":  \"w\",\n",
        "                                  \"label\": \"Histogram\",\n",
        "                                  },\n",
        "             kde=True, kde_kws = {'linewidth': 3,\n",
        "                   `               'color': \"blue\",\n",
        "                                  \"alpha\": 0.7,\n",
        "                                  'label':'Kernel Density Estimation Plot'\n",
        "                                 },\n",
        "             fit= stats.norm, fit_kws = {'color' : 'green',\n",
        "                                         'label' : 'parametric fit',\n",
        "                                         \"alpha\": 0.7,\n",
        "                                          'linewidth':3},\n",
        "             ax=ax2)\n",
        "ax2.set_title('Density Estimations')\n",
        "\n",
        "sns.boxplot(x=data.Height, ax = ax,color = 'salmon')\n",
        "ax.set_title('Box and Whiskers Plot')\n",
        "ax2.set(ylim=(0, .08))\n",
        "plt.ylim(0,0.11)\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XlcFVX/wPHP3I3tArIJroi44y4aaeECai65pZmauWWbVmr2lGU9lUtqZWZmqbmkWWHpo/4yNTU1FS2XEHfFBVFBEJB9ucv5/XHj6lUQVJDF8369eOWcOTPzPRea750zZ84oQgiBJEmSJJUxqtIOQJIkSZLyIxOUJEmSVCbJBCVJkiSVSTJBSZIkSWWSTFCSJElSmSQTlCRJklQmyQQlSYWoVasWU6dOLfb9XrhwAUVR2L17d7Edf8eOHSiKwqVLl4ojxBJX1M9AejjJBCUVi+HDh6MoivXH1dWVRx99lN9++620QytRWVlZ2Nvb8/XXX9uUz549G0VR8i23t7cnKyuryMfYv38/48ePL5Z4H7QOHTpY/yZ0Oh3+/v5MmjSJzMzMe97n999/j6IoxRilVFbJBCUVm8cff5zY2FhiY2PZt28fLVu2pE+fPpw9e7a0QysxDg4OPProo2zbts2m/I8//qBmzZr5lrdt2xYHB4ciH8PLywsnJ6diifde5ebm3vO2gwcPJjY2lqioKD744APmzJnDm2++WYzRSRWVTFBSsdHpdPj4+ODj40PDhg2ZMWMGBoOByMhIa520tDRefPFFvLy8sLe3JzAwkN9//926ftWqVeh0Ov7++29r2fLly7G3t+eff/4p8NhffPEFzZs3R6/X4+PjwzPPPENsbKx1fV7X15YtWwgODsbR0ZFGjRqxefNmm/0cPnyYtm3bYm9vT7169Vi1alWh7Q4JCWH79u2YzWYATCYTu3bt4r333su3PDQ01Gb7K1eu8OSTT+Lo6Ejt2rVZsWKFzfpbu/jWrVtHixYtcHR0pFKlSrRp06bAz8ZsNjN27FiqV6/O0aNHATAajXzwwQf4+flhb29PQEAACxYssNlOURTmzp3L4MGDcXV1ZciQIQBMnz6d2rVrY2dnh5eXF127di30atDBwQEfHx9q1qzJ0KFDefbZZ1mzZk2B9U+dOkWPHj3Q6/Xo9XqefPJJoqKiAMvvcejQodYYFUVh+PDhdzy+VI4JSSoGw4YNEyEhIdblnJwc8dlnnwk7Oztx4cIFa3n//v2Fr6+v2LRpkzh+/Lh47bXXhFarFSdOnLDWef7550Xt2rVFSkqKOHXqlNDr9WLu3Ll3PP6cOXPEli1bxLlz50R4eLh49NFHRXBwsHX99u3bBSCaNm0qNm7cKE6fPi2GDh0qXF1dRXJyshBCiMzMTFG1alXRrVs3ERERIcLDw0VgYKBwcHAQU6ZMKfDY4eHhAhAHDx4UQgixd+9e4e7uLgwGg3Bzc7MpB8S+ffuEEEKcP39eAMLPz0+EhYWJM2fOiLfeekuo1Wpx+vRp6/59fX2tx4+NjRVarVbMnDlTnDt3Thw/flysXLlSREZG2rQzJiZGZGVliX79+omGDRuK6Ohom99VkyZNxObNm8W5c+fETz/9JFxdXcW3335rrQMId3d3MXfuXBEVFSVOnTolVq9eLZydncX69etFdHS0+Oeff8Tnn38uMjMzC/xs2rdvL0aNGmVT9uqrrwoPDw+bz2DXrl3W30HNmjVFp06dxIEDB8SBAwdEhw4dhL+/v8jJyRE5OTli3rx5AhCxsbEiNjZWXL9+vcDjS+WbTFBSsRg2bJhQq9XCyclJODk5CUVRhJOTkwgLC7PWOXPmjADEhg0bbLZt0aKFGDFihHU5MzNTNGrUSAwYMEA0b95c9O7d+67jOXTokADEpUuXhBA3TtyrV6+21omNjRWA2LRpkxBCiEWLFgknJyeRlJRkrXPkyBEB3DFBGQwG4eLiImbNmiWEEGLq1Kmib9++QgghevfubVPu6uoqjEajEOLGyfmzzz6z2ZeTk5P45ptvrGU3J6i8dp0/fz7fWPLaeeTIEfH444+Ltm3bisTEROv6c+fOCUVRbL4QCCHEhx9+KJo1a2ZdBsTIkSNt6syePVvUrVtX5ObmFvhZ3OrmBGU2m0V4eLhwc3MTAwcOtPkM8hLUt99+KxwcHERCQoJ1H3FxccLe3l589913QgghVqxYIeR364eD7OKTis0jjzxCREQEERERHDp0iPfff59hw4ZZu9GOHz8OQHBwsM12wcHBHDt2zLrs4OBAWFgYa9asIT4+niVLlhR67B07dtC1a1dq1KiBs7Mzjz32GADR0dE29Zo3b279t4+PD2q1mqtXr1rja9iwIW5ubtY6jRs3xtXV9Y7H1mg0BAcHs3XrVsByn6lTp04AdOrUyaa8Y8eOqNXqAmPSaDR4e3tbY7pV06ZN6dq1K40bN6Zv37588cUXxMTE3Fave/fuAGzduhV3d3dr+YEDBxBCEBgYaO1C0+v1TJ8+nTNnztjso02bNjbLTz/9NAaDAV9fX4YPH86KFStIS0u742cD8N1336HX67G3t+fxxx8nJCSEefPm5Vv32LFjNGrUCE9PT2uZt7c39evXt/kbkR4OMkFJxcbBwYE6depQp04dmjdvzn/+8x+Cg4OZNm3aHbcTQtw2Kitv2PH169eJj4+/4/YXL16ke/fu1KpVi59++okDBw6wfv164Pab+zqd7rbt8+4R5RdHUYWGhrJ7925SU1MJDw+3JqiOHTvalIeEhNy27a0xKYpijelWarWajRs38scff9C6dWtWr15NvXr1+PXXX23q9erVi4MHD7J379582xoeHm79MhEREcHRo0dt7hUCtw3MqFatGidPnmTJkiVUrlyZKVOmUL9+/XwT5M369u1LREQEZ86cITs7m59//tkmAd0qv9/B/fxupPJLJiipRGk0GuuQ4oCAAAD+/PNPmzq7du2yrgPLt+gJEyawYMECunXrxjPPPENOTk6Bx9i/fz9ZWVnMmTOHdu3aUb9+/QKvQO4kICCA48ePc/36dZtYUlJSCt02JCSEzMxMZs+eTaVKlWjUqBFguQJzcnJi9uzZZGdn3zZA4l4oikKbNm145513+PPPP2nfvj1Lly61qfP222/z4Ycf0rNnT5tBKK1atQIsST3vy0Tej7+/f6HHtrOz44knnmDWrFkcOXKEzMxM1q5de8dtXFxcqFOnDjVr1kSj0dyxbkBAAMeOHePatWvWsqtXr3L69Gnr30heQjeZTIXGK5VvMkFJxSY3N5e4uDji4uI4e/Ys8+fPZ/PmzfTt2xcAf39/BgwYwCuvvMLmzZs5efIkr7/+OkePHrUOO87OzuaZZ56hV69ejBo1ikWLFpGcnMzEiRMLPG7dunVRFIXPPvuM8+fPs3btWj766KO7jn/w4ME4Ozvz7LPPcvjwYfbt28fIkSOLNCS8cePGeHt7M3v2bDp27GgtVxSFDh06MHv2bKpVq0aDBg3uOq6bhYeHM2XKFP766y8uXrzItm3biIyMtCbEm02cOJEZM2bQu3dvNmzYAECdOnUYOXIko0ePZsWKFURFRXH48GGWLFnCzJkz73jsxYsXs2jRIg4fPkx0dDQrV64kLS0t32Pfq8GDB+Pl5cXAgQM5dOgQBw8e5JlnnqFatWoMHDgQAD8/PwDWr19PQkIC6enpxXZ8qYwp3VtgUkUxbNgwAVh/HBwcRKNGjcQnn3wiTCaTtV5KSop44YUXhKenp9DpdKJVq1Zi8+bN1vUvvfSS8PPzsxmZtWvXLqHRaMS6desKPP68efNE9erVhb29vWjXrp3YuHGjAMT27duFELaj226mVqvF0qVLrcuHDh0SQUFBQqfTidq1a4sff/zRZpDCnQwaNEgAYtGiRTbl8+fPF4B47rnnbMpvHSCQx9/fX/z3v/+1Lt98/KNHj4pu3boJb29vodPpRM2aNcXEiRNFTk5Oge2cP3++sLOzE2vXrhVCCGE0GsXMmTNF/fr1hVarFR4eHiI4OFisWrXKug0gVqxYYRPX6tWrxaOPPioqVaokHBwcREBAgM3Iv/zkN4qvsM/g5MmTolu3btYBNz169BBnzpyx2e71118XlStXFoqiiGHDht0xBqn8UoSQb9SVJEmSyh7ZxSdJkiSVSTJBSZIkSWWSTFCSJElSmSQTlCRJklQmyQQlSZIklUl3fmqulFy5cqW0Q7hvnp6eNg8bVnSyvRWbbG/F9qDbW7Vq1SLVK5MJSpJKwtatW+9phon8aLVaDAbDXW+XnJwMYDPfX2ny9vYultktJKkkyAQlPTSuXr1K/OVLeOvu/8/eCNzLzHCGHCMAirHgqZselKu5xtIOQZLuSCYo6aHirdPwXJXSu3pZHmu5girNGPIsj01GPqUvlWVykIQkSZJUJskEJUmSJJVJMkGVkHXr1llfVCdJklSYrVu3ynPGLeQ9qBJy+fLlexrlJUnSw6m4RphWJPIK6i6lp6ezcuVK6ztobl6+dZ0kSVJxyO+8s3z5cpYuXcry5cttzjkV6TwkE9Rd2rNnDzExMezZs+e25VvXSZIkFYf8zjtXrlzh6tWrXLlyxeacU5HOQzJB3YX09HSOHDkCwJEjR7h69ap1OTIyksjISOs6o1E+YyJJ0v3L77yTd67JExkZae3Fublueb+Kkveg7sKePXvIe7+jEIL169dbl00mE4qiWNfFxcWhKAorV64stXgfpHudWeFBio+PR2c0lXYYZUaywURufHyR/kbLw++3OJVGe+Pj49FqtbeV53feMZls/47NZrP1iunmunv27KFr164lHHnJKRMJ6ubRKzNmzCjlaAp27Ngx6x+GyWQiMTHRZv3NycpkMmFnZ/fAY5QkqWIp7LwDlnPPsWPHrHXy/nvs2DGZoO5XaGhouZgPLCAggMjISEwmE2q1mkqVKnH9+nXrH4SiKAghUKvVODo6UqlSJYYMGVLKUT8Y5WFyzZUrV6IkxJV2GGWGm1aN8KpcpL/R8vD7LU6l0d6CrmTzO+/cmqQURSEgIADApm5eWXkl70HdhXbt2lm78RRFoVevXtZltVqNSqWyrisrk4FKklS+5XfeUavVNnVUKhXt2rW7rW67du0eeLzFSSaou6DX62nSpAkATZo0wdvb27rctGlTmjZtal2n0ZSJi1NJksq5/M47eeeaPE2bNkWv199WV6/XP/B4i5M8i96ldu3ace3aNes3k1uX8/7922+/lWaYkiRVIPmdd65evWrtyrv5SunWuuWZTFB3Sa/X2/TZ37qc9+9q1aqRlZX1wOOTJKl88vb2LnBdfued5557rkh1yzOZoEpI7969H6qbypIk3Z/yMFDsQZP3oCRJkqQySSYoSZIkqUySXXzSQ+VqrtH6VttSOf6/r3wvzRjyXM01Urm0g5CkO5AJSnpo5N2ELo7XnN/rVDjaZEtiEmXgObnK3PnGvCSVNpmgpIdGcd6EfthmVpCk0iDvQUmSJEllkiLyZjiVJEmSpDJEXkGVkLfffru0Q3igZHsrNtneiq2stlcmKEmSJKlMkglKkiRJKpPUH3zwwQelHURFVbt27dIO4YGS7a3YZHsrtrLYXjlIQpIesDVr1hAfH89LL71UaN1Vq1YRFxfHa6+99gAik6SyRXbxSdI9GDNmDJGRkTZlO3bs4L333it02379+hUpOd1rHJJUUcgEJUmSJJVJciYJSSoBSUlJLFmyhBMnTmBvb0+PHj3o3r07cHu33c6dOwkLCyM7O5vu3buzfft2XnzxRetbU41GI/PmzePvv//G09OTMWPG4O/vz5dffsm1a9eYOXMmKpWK/v3707t371JrsyQVN3kFJUnFzGw2M3PmTGrVqsWCBQt4//33+e2334iIiLit7qVLl/j222957bXXWLhwIZmZmSQlJdnUOXjwIG3btmXZsmUEBgayZMkSAF599VU8PT156623WLFihUxOUoUjr6Ak6R598sknqNVq67LRaMTPz4+zZ8+SmppK//79AcuErCEhIYSHh9O8eXObfezbt49WrVrRoEEDAAYOHMjGjRtt6jRo0ICWLVsCEBwczIYNG0qyWZJUZsgEJUn36M0337R2w4FlkMS2bdtISEggOTmZ4cOHW9eZzWYaNmx42z6SkpLw9PS0LtvZ2eHs7GxTx9XV1fpvnU6HwWDAZDLZJEdJqohkgpKkYubp6UnlypWZO3duoXXd3Ny4cuWKdTk3N5e0tLSSDE+Syg15D0qSilmdOnVwcHBg7dq15ObmYjabuXjxIlFRUbfVDQoK4uDBg5w6dQqj0ciqVavu6liVKlUiPj6+uEKXpDJFJihJKmYqlYq33nqLCxcuMGbMGEaNGsWCBQvIzMy8rW6NGjUYOXIkc+bM4YUXXsDe3h4XFxe0Wm2RjtWnTx9Wr17N8OHDWb9+fXE3RZJKlZxJQpLKkOzsbIYPH87cuXOpXFm+kF16uMkrKEkqZQcOHCAnJ4fs7GyWL19OzZo18fLyKu2wJKnUyUESklTKDhw4wLx58xBC4O/vz7hx41AUpbTDkqRSJ7v4JEmSpDJJdvFJkiRJZZJMUJIkSVKZJBOUJEmSVCbJBCVJkiSVSTJBSZIkSWWSTFCSJElSmSQTlCRJklQmyQQlSZIklUkyQUmSJEllkkxQkiRJUpkkE5T00KpVqxZTp04t7TDuSocOHXj++edL7fjLli1Do5FTeEoPhkxQ0gMxfPhwFEVBURQ0Gg3u7u48+uijfPjhhyQlJZVKTPv372f8+PHW5Tp16vDBBx8Uy77z2nrrz9ixY4u0/dSpU6lVq9Zt5WvWrGH27NnFEuOdXLp0CUVR2LFjh035wIEDuXz5cokfX5JAzmYuPUCPP/44q1atwmw2k5yczF9//cWsWbP45ptv2LlzJ/Xq1Xug8ZT0Ky3mzZvHU089ZVPm5OR0X/t0d3e/r+3vl4ODAw4ODqUag/QQEZL0AAwbNkyEhITcVp6SkiJq164tOnbsaFP+448/imbNmgk7Ozvh6+srxo8fL9LT063r27dvL0aNGiU++ugj4e3tLdzc3MSwYcNs6hw9elR06dJFuLq6CkdHR9GgQQOxfPly63pfX18xZcoU6/4Am5+zZ88KPz8/MW3aNJvY0tPThbOzs1i6dGmB7QXEihUr7viZTJs2Tfj5+QmdTic8PT1Fly5dRGZmpli6dOltsfz3v/+1affNn8PIkSPFu+++K7y8vISrq6t45513hMlkEh9++KGoXLmy8PT0FO+8847NsVeuXCnatGkjXFxchIeHh+jevbs4deqUTfw3//j6+gohhFi6dKlQq9U2+9qwYYNo2bKl0Ol0wsvLS7z88ss2v4e83/2CBQtEzZo1hbOzs+jVq5eIj4+31omJiRH9+vUTHh4ewt7eXvj5+YlZs2bd8fOTKj7ZxSeVKhcXF15++WV27NhBQkICYLnP8fLLL/PGG29w/Phxli9fztatW3nppZdstv3ll19ISkpix44d/PDDD6xdu5ZZs2ZZ1w8aNAgPDw/Cw8M5cuQIs2fPxs3NLd841qxZQ61atXjjjTeIjY0lNjYWX19fRo8ezeLFixE3vZXmp59+QqVS8fTTT99zu9esWcOMGTP44osvOHPmDFu2bKFbt26ApRvtrbfeonr16tZYJk6cWOC+fvnlFwwGA7t372b27NlMnz6dnj17kp6ezq5du/j000+ZPn06GzdutG6Tk5PDe++9x6FDh9iyZQtqtZoePXqQm5sLwKFDhwBYvXo1sbGx7N+/P99jR0ZG0qtXL4KDg4mIiOC7777j119/ve13tX//frZv386GDRvYtGkTERERNm165ZVXSElJYevWrZw4cYLFixdTvXr1e/twpYqjtDOk9HAo6ApKCCE2btwoAPHXX38JISxXNl9//bVNnZ07dwpAJCUlCSEsVw5NmjSxqfPiiy+KoKAg67KLi8sdr3JuvoISQgh/f3/rlUqeuLg4odVqxZYtW6xlQUFB4pVXXim4scJyBWJnZyecnJxsfn766SchhBCzZ88WdevWFbm5ufluP2XKFOtVy83yu4Jq1qyZTZ1GjRqJxo0b25Q1bdpUvPHGGwXGm5iYKACxe/duIYTligYQ27dvt6l36xXUs88+K1q3bm1TZ+3atUJRFHHhwgUhhOV37+npKbKzs611Pv74Y+Hj42MT362fvSTJKyip1Il/r04URSEhIYHo6GgmTJiAXq+3/uRdXURFRVm3a968uc1+qlWrxtWrV63LEydO5Pnnn6dDhw588MEH1quCu+Ht7U3v3r1ZtGgRAMeOHWPfvn2MHj260G2nTZtGRESEzU+PHj0AePrppzEYDPj6+jJ8+HBWrFhBWlraXccH0KxZM5tlHx8fmjZteltZfHy8dTkiIoK+ffvi5+eHs7MzNWvWBCA6Ovqujn3s2DGCg4Ntytq3b48QguPHj1vLGjZsiJ2dnXX51t/VuHHjmD59Oo888ghvvfUWf/75513FIVVMMkFJpe7o0aMoikLt2rUxm80AfPHFFzYn9sOHD3PmzBmaNGli3U6n09nsR1EU6/YA7733HqdPn+bpp5/m6NGjBAUFMXny5LuO76WXXmLt2rUkJCSwaNEiWrdufVtyzI+3tzd16tSx+dHr9YDlBH3y5EmWLFlC5cqVmTJlCvXr1ycmJuau49NqtTbLiqLkW5b32WRmZtKlSxcURWHJkiX8/fff7N+/H0VRrF18d6Og19PfXJ7f70rc1G06YsQIoqOjeemll4iNjaVbt248++yzdx2LVLHIBCWVqtTUVL7++mtCQkLw8PDA29ubGjVqcOrUqdtO7nXq1MHe3v6u9l+7dm1eeeUVfvnlFz766CO+/vrrAuvqdDpMJtNt5Z06daJmzZosXLiQFStWFOnqqSjs7Ox44oknmDVrFkeOHCEzM5O1a9feMZbicOLECRISEpg2bRodO3akYcOGJCcn2ySMvIRSWAwBAQHs3LnTpmznzp0oikKjRo3uKq4qVaowYsQIli9fzuLFi1m5ciWpqal3tQ+pYpHDzKUHJjc3l7i4OIQQJCcns2/fPmbNmkVOTo5N4pg2bRqjRo2iUqVK9OnTB61Wy4kTJ9i4cSMLFiwo0rHS09N56623eOqpp/Dz8+P69ets2rTpjidNPz8/9uzZw8WLF3F0dMTd3R2VSoWiKLzwwgtMnjwZnU7HoEGDihRDSkoKcXFxNmX29vZUqlSJxYsXYzabadOmDZUqVWLbtm2kpaVZ4/Pz8yMuLo69e/dSt25dHB0dcXR0LNJxC+Pr64udnR1ffvklb7zxBhcuXODtt9+2ueLx9PREr9fz+++/ExAQgJ2dXb4DTN58801atmzJhAkTeOGFF7hw4QKvvvoqQ4YMsXYbFsXYsWPp3r079evXJzs7mzVr1lCjRg2cnZ2Lpc1S+SSvoKQHZteuXVSpUoUaNWrQrl07Fi5cyODBgzl69Ch16tSx1hs6dCirVq1iw4YNtGnThtatW/PBBx9QrVq1Ih9Lo9GQnJzMqFGjaNiwIV27dsXb25sffvihwG0+/PBDUlJSqF+/Pl5eXly8eNG6bsSIEQghGDx4sLWbrjBjx46lSpUqNj953VZubm4sXbqUDh060LBhQ2bPns3ChQsJCQkBoE+fPgwYMIAePXrg5eVlMzrxfnl6evL999+zZcsWAgICmDhxIp9++ikq1Y3TgUql4quvvmLVqlXUqFGDFi1a5Luvpk2bsn79enbu3EmzZs0YOnQoPXr04JtvvrmrmIQQjBs3jsaNGxMcHExGRgYbN24ssPtQejgo4ubrekmS8nX8+HECAgI4cOAArVq1Ku1wJOmhIBOUJN1BTk4Oly9fZvz48aSkpNw29Y8kSSVHdvFJ0h38+OOP1KlTh3PnzhX5/pckScVDXkFJkiRJZZK8gpIkSZLKJJmgJEmSpDKpTD4HdeXKldIO4b55enpy7dq10g7jgZHtrdhkeyu2B93eqlWrFqmevIKSJEmSyiSZoCRJkqQySSYoSZIkqUySCUqSJEkqk8rkIAlJqmhyTbnEZsSSkJVAtjEbM2acNE5UsqtENX017DV3N0u7JD0MZIKSpBJyNfMqf8X+RURCBNGp0RiFMd96Cgo1nWvSzKsZj/g8QnVn+apzSQKZoCSp2J1IOsFv538j8lpkkeoLBNFp0USnRbP+3Hrqu9WnW61uNPdqLmfzlh5qMkFJUjG5nH6Zn079VGBi8nb0xtvRG71Wj6IoZBgyiM+MJzYjFsGNGcdOJZ/iVPIp/F39GdJgCP6V/B9UEySpTClSgoqIiGDp0qWYzWZCQkLo06ePzfrjx4/z3XffER0dzbhx4wgKCrKu27FjB2vWrAGgX79+dOjQofiil6QywGg2suH8BtafXW/TjaegWLvtmng2wVmX/8v3soxZHE08yt+xf3Mw/iAmYXmL7dmUs0z5awqhNUMZUG8Admq7B9IeSSorCk1QZrOZxYsXM3nyZDw8PJg0aRKBgYFUr36jn9zT05NXXnmF//u//7PZNj09nV9++YUZM2YA8PbbbxMYGFjkF75JUll3LesaXx3+inMp56xlCgqPV3ucnrV74u3oXeg+HDQOtPZuTWvv1iRnJ/Pbhd/44+IfGIURgWDLxS0cSzzGK81eoYZzjZJsjiSVKYUOM4+KisLHxwdvb280Gg1t27Zl//79NnUqV66Mr6/vbf3lERERNG3aFL1ej16vp2nTpkRERBRvCySplBxLPMb7e9+3SU7+rv5MaTuFUY1HFSk53crN3o0hDYbw8WMf08SzibX8SsYVPvrrI/Zf3X+HrSWpYin0CiopKQkPDw/rsoeHB2fOnCnSzm/d1t3dnaSkpNvqbd26la1btwIwY8YMPD09i7T/skyj0VSIdhTVw9be7Re389WRrzApJnQ6HWpFzbNNnqVXvV6olPt/vNATTz6u8TFbz2/l24hvyTXlArDw+EIyVBk81eCpBzqA4mH7/cr2lg2FJqj8Xhd1P/9j5LdtaGgooaGh1uWKMEmjnGyy4tp8YTO/nP+F3FxL0qhkV4mxzcZS160uSYm3fwG7Hy1cWvBOy3f44p8vuJp5FYClh5ZyJfEKg+oPemBJ6mH6/YJsb0krtsliPTw8SEyHtR+xAAAgAElEQVRMtC4nJibi5uZWpJ27u7vbbJuUlFTkbSWpLNp8YTM/nPrBuuzr7Mt/g/5LXbe6JXbMavpqvP/I+zR0b3gjjujNLD+xPN8vkJJUURSaoPz9/YmNjSU+Ph6j0Uh4eDiBgYFF2nnz5s05fPgw6enppKenc/jwYZo3b37fQUtSadh4fqNNcqpbqS6T2kzC3d69xI+t1+l5o9UbBHrf+H/vj5g/+PnMzzJJSRVWoV18arWakSNHMm3aNMxmMx07dqRGjRqEhYXh7+9PYGAgUVFRfPrpp2RkZHDw4EFWrVrF7Nmz0ev1PPXUU0yaNAmA/v37yxF8Urm0JXoLP53+ybrcyLMRLzV8CQeNwwOLQavSMqbZGBZELmBf3D4ANpzfgL3anl7+vR5YHJL0oCiiDH79ki8sLH8qYnvtT1geuD2QdpLPY36yXqk0cKrFRw1fwJhlILth0wcel9Fs5MuIL4lIuDEidkiDIXTx7VJix6yIv987ke0tWfKFhZJUDGKMCcy/sgYUBUWlop7el8n+I3AoxcldNSoNY5qNoZF7I2vZDyd/IDKhaFMrSVJ5IROUJBUg0ZDCzAsryNY7Ilxc8fKpyxs9PkHTPKjwjUuYTq3j9Rav4+9qmQZJIJgfOZ8r6eW/90GS8sgEJUn5yDHl8MnFH0g2pAHgqHXkP4/8B1c711KO7AZ7jT2vt3jdOkgjy5jFF/98QaYhs5Qjk6TiIROUJOVjxYkVXMyOA0CtqJkQOKFMvgbD1c6VcS3GoVPpAIjLjGN+5HzMwlzKkUnS/ZOzmUvSLf68/Ce7Lu9C/e/yiCYjaOzV+L72mTfgoiB3M9ji1n3VB8Y4d2TupZ8BOMIR1p1dR986fe86TkkqS+QVlCTdJCYthhXHV1iXg92aE+IbUiz71ul0+f4Ux76CvVrSv0on6/p1Z9dxMulkscQtSaVFXkFJ0r+yjFnMi5hHrtkyhVFVOy9GV+tNerrCmTNqLl5UEROjIiNDgas1ycwyoK3mjJOTGb1e4OQkcHIy4+QkrMsqlUAI0F50QqPRYqjTCJMJjEaF3FwwnzpDVraRzDg7DAbIzVUwmSz/NRoVVCqBo6Plx9vbRM2aJvLGDxqbtLSJ/2lh5ljqeY6SiEDwTeQ3TG07Fb1OPnsolU8yQUkPjcK62b41/U1cpuW+k0bR8VjaC3y+vB4RV50wmWzrqjOcMBmNmBK1RTq2Or0+ikqFcLZ9sFeV4IUQAmFnewAlJxsAYXfrcHY1HtraBAZk0OZZFQ0bmlH92w+iUlSMqdaPN6/9SLohneScZBYdXcS4FuPkm3mlckkmKOmhUlCXWnhiJLuSdyEEJCaqcDk2llWnWv2bVEo2JkWjxZpl8soUBdSa28oBkjMc2HLQmc3nHfDwMNOzp4GQECMawF3rwugmo/n80OcARCREsOXilhJ9iFeSSopMUNJD59ausYx//mTRlfWkGrRcuqTGMeExPC93BFKtderUMVG7tpmaNc14eAicL0eTk51BStX6pKcrZGRYuv5yoq6QnqkmI1tDeqYGIUBRQKNLRWNvh6m6HpUKdDrQagX2566ic9Si1K+LVsu/PwKHY0fR6u3IqdeUjAyF1FS4dEnFxYsqjJezrHElJqr47js7/u//dAxo6c7jzeJo7tWcrr5d2Ry9GYCfT/9ME88mVHGq8kA+X0kqLjJBSQ81IQRzz63jyCVBYoYGrcGN6nGjAXDVG+jxWDJBg7RUrmw7I5iTUyZpaelkNzTYlNufiMn3Kk11+SKK3pmcx2xfYqjbdPTfct9byi/8W97QptxkgvNLDrLnvC+7EzxIS7N03SUlKSz8X3W2/e3KcxPVDKg3gBNJJ7iYdpFccy6Ljy7mnTbvFMu7qiTpQZEJSnqordy7i+8jL2IwakEDNa6MoZKDEz17ZtK96lGc9VqMle/++adbr9J0ly8WS7xqNTSqcZ2AhiYGtfFj2zYN69bpuH7dkqiiYpx4/31nevfWMqrDaD766wNMwsSZ62fYfGEz3fy6FUsckvQgyAQlPZSEgF82pDL97+8xmlWAwDOpK12aNOLZZ1NwdhbYnbjDPMoXz6P9dyDDzbRxl1C7umEsudCtdDro1s1ISIiRdeu0rF8hMJjBZFJYs8aR48cDCOnem9/j1gCwOmo1zbyaUVVftIk6Jam0yet96aFjNMI339jxyR/LMSoZADgZKzPlqb68/HIGzs5Fm+Bf4+p22/NIavWD/86n08GAAQZmvXaaujUyrOUnT2rZvXAI+txaABjMBr49+q2cZUIqN+QVlPRQychS8ckMe3Zd+Jvr1fYC4KTJ4av6jQhyPgYnbtQtytVQSXXl3Qtf4xmmPnmCVSdbs2Z7FYSAnHTICnuRjPZv4lZDw9mUs2y9uFWO6pPKBXkFJT00klK0/HeBPxHHs7nkvQgAD0/By3Vr0NGvfpm4GrpfOjc3Bj2RyIcvnsfd1YSiUuGYUwtDxDNcjFFbujbP/EJSdlJphypJhZIJSnooxMer+GBRfaLjHLjitRyDJomqVQXN6rkw3K0dYLkauvmnvDI2aUm93vWZ9rUjdVrqUbKz8LnYmayLVbhw0kRO8jV+/PMT7E9EFvrwsiSVpiJ9RYyIiGDp0qWYzWZCQkLo06ePzXqDwcC8efM4d+4czs7OjBs3jsqVK2M0Gvnmm284f/48ZrOZ4OBg+vaVE1hKD9aVKypmzXIh9Xo6Gc6nSHTbTC1fM+4eghFNRqCPjC3tEEuEm5vgvfeyWTYxlh0na1AzZhSnHaZw9pIeRTlDRFYUzR3qlHaYklSgQq+gzGYzixcv5p133uHzzz9nz549XLp0yabOH3/8gZOTE19++SU9evRg5cqVAOzbtw+j0chnn33GjBkz2Lp1K/Hx8SXTEknKx+XLaj7+2IXkZBUCE5drLqG2vyU5BfoE0qZKm9IOsUTpdDCm23H6Px6DXvUIHundSM+141SsGwsu/kqWKae0Q5SkAhWaoKKiovDx8cHb2xuNRkPbtm3Zv3+/TZ0DBw7QoUMHAIKCgjh69ChCWEZCZWdnYzKZyM3NRaPR4OjoWPytkKR8xMaqmDHDmdRUy5/59aq/U7XeKVxdBXZqO0Y0GfFQzFGnKDCoYwzPPZdDtfjn0JhcycqE/eeN/Bi7o7TDk6QCFdrFl5SUhIeHh3XZw8ODM2fOFFhHrVbj6OhIWloaQUFBHDhwgBdeeIHc3FyGDRuGXn/7zMpbt25l69atAMyYMQNPT8/7alRZoNFoKkQ7iqqstTc+HubOVZOdraDTgdopCVXQSjT2AkWtYXDTwfh6WWZvEBoNaDRob/nbLKgcQKgsbS7qNsVVfj/7evppe9zdHfjwu9Gc8/mMjCwNC48fo0fnDPw9bWeyuFVZ+/2WNNnesqHQBJV3JXSzW791FlQnKioKlUrFggULyMjI4P3336dJkyZ4e9tO9xIaGkpoaKh1+dq1a0VuQFnl6elZIdpRVGWpvUlJCtOnu5CQYHneR6cTVH9yPueSUzCbVfjYexFSLYT09HTLeqMRxWgk59/lPAWVAziZwXgX2xRX+f3uKygIxiYG8t6OANLtIrieDqMXLOCn0eNRqQq+mixLv98HQba3ZFWtWrSHxQvt4vPw8CAxMdG6nJiYiJubW4F1TCYTmZmZ6PV6du/eTfPmzdFoNLi6ulK/fn3Onj17N+2QpLuSkqIwc6YLCQmW9+FqtYK+ow9yxrjLWmdEkxFoVOVvCHlx6dHDxIuBw1CMAsxmTl+LZP6izdZRfXJ0n1RWFJqg/P39iY2NJT4+HqPRSHh4OIGBgTZ1WrVqxY4dOwDLwIiAgAAURcHT09N6Pyo7O5szZ85QrVq1EmmI9PC59YRqOHiM2ZNyuXYsEU1iPNrMFF7vfoC/4z9BnZaKkpPNo3a1aVq56K9Xr6heeLoq7XUtLTeoFIXlsVs4eFZ/X2/5laTiVmiCUqvVjBw5kmnTpjF+/HgeffRRatSoQVhYGAcOHACgU6dOpKen8+qrr/Lrr78yZMgQAJ544gmys7N54403mDRpEh07dsTX98593ZJ0N/JOqAI7PltZn0sJTiiKgkqrYfyQS6RW+5OY3HgUlQo7lZbhnsXz+vbyTlFgTms/POzsQa0h1yGVSfuiiPFsVdqhSZJVkfo5WrZsScuWtg8uDhw40PpvnU7HhAkTbtvO3t4+33JJKk65AS2Z87kdp69rwBlU2Zm82juKek/5Mv6PgwgXVwCeyq6Nl9YVObDaopLWjvcbBzLx5N8YciFGv5YZ8zoyp3/FH9kolQ9yJgmp3Pv+ex3799/4rjUy5DTtmyYQdjKMTEMmAD5OPvRyLr+zQ5SU3pUD6NjUD0UFQjEQnr2MHzf7lHZYkgTIBCWVc7/vc+e337TW5R49DHRreYnonHi2R2+3lg9vPByt8vAOjCiIoii8/tgwqlWzjHhM0f/N9xFXiDjtUsqRSZJMUFI5dibGiaX/d2PQTZs2Rp59NhchBMuubUNgefyheeXmNPduXlphlnl13eoyoFV7XFwtn9el6iv4anV1UlNlV59UuuRXSqlcSk1VmPNjbYwmy0m0Vi0zY8bkoCjwT84FIrMugIMnCgpDGg0p3WDzIYQgLS0NUd0PRavFlJxss15VozaKRnNb+Z3W3U95vxp9qRFak6TrJswmgWNGNGfO1KBBAyOKAlevXiUn5+G5eyfbe/+EEKhUKuzt7e95xhaZoKRyx2SC+fP1JKdmoajAyUkwYUI2dnZgNBv57vqNZ55CfEOo4VKjFKPNX1paGoqiYOdVGVRqhIODzXrF0yvf8jutu59yBxwIrNmSBI8ksrMFilBjn2OH2WyHs7NAo9GgVquLqfVln2xv8TAajWRnZ+OQz99xUcguPqnc2bDBnhMnLPedFASvvppD5cqW7qlt0du4bLS868hB48CABgNKLc47MZlMaLXawis+QC52LthpNWjVAqGYMGiTSUpSYTCUdmRSeaXRaDCb7/0NzjJBSeVKdLSatWtvfBvrHxJP8+YmADIMGfx88mfruj51++Bq5/rAYyyvVIoKd3t3tBqBSgGjOgWjMHDtmop8ZjOTpCK5nwmZZRefVOblTbuTa1BYNL8hpKShBuq5x/F0qzMYsQyU+N/p/5FuSEcFeGlc6Va7W+kFXU45aZ1wUOswa3PJzlUwaBPJzvYhJQXymbdWkkqUvIKSygWdTsfq7TWJTXREUamwt4PXe54gr9s8LiOOTec3WesP9eiATi2n7LmT2i1vzBqxbds22rZty+XLl/HQuqJWBFotmFQZmFRZJCZCbu79H7N///4cPnw43/LHH3+c0NBQgoODeffdd0lJSbn/A97k8OHDvPfeewCEh4ff9tqgwnz22We0atWKzp07W38KijElJYVly5ZZl+Pi4hg9evQ9x36zTZs2cfr0aevyJ598wp9//nnf+w0PD6dBgwZ06dKF9u3bM3v2bGv5c889V+i2d/t5FoVMUFK5cPaSA79G1kE4uyKcXRkyxpEqblnW9T8e/xGj2QhAPV0V2uobllao5c6uXbt49913+eGHH6hevTp2Ki1OGge0WoFKBQZtIkJg09VnNBqLPY558+ZZX72j0+kYOXJkse6/WbNmTJkyBYC9e/dy8ODBu97H6NGj2bJli/XH1TX/LuTU1FSWL19uXfbx8WHRokX3Fvgtbk1Qb775JsHBwcWy7zZt2vD777+zceNGVq9eTWRk0SYNvtfPszAyQUllntkMi9ZWs54cmzQxERp64wR5MvEkf8X+ZV0eXin4oXgRYXHYt/8AEydOZMWKFdSqVQuAa4mJTHr9XZ5/+nnGDh3Fkcj9GNVpzJ//KePG/YdBgwbx+uuvExYWxvPPP8+QIUNo164dU6dOte53586dPPnkk3Tt2pUXXniBjIyMIsek0+mYPHkyly9f5tixYwCsXr2aHj160LlzZ/7zn/9gMlnuO9atW5cZM2YQGhpKz549SUhIAOD//u//6NSpE6GhofTr1w+4cSUQExPDihUrWLRoEZ07d+avv/4iKCgIw7+jQdLS0ggMDLQuF+bUqVPW2EJDQzl37hzTp08nOjqazp07M2XKFGJiYujUqRMAYWFhjBw5kmHDhhEUFMTSpUtZsGABXbp0oWfPniT/+zjAypUr6d69O6GhoYwePZqsrCz279/Pli1bmDp1Kp07d+bChQuMGzeOX3/9FbB82ejSpQshISFMmDDBOnT8kUce4dNPP6Vr166EhIQQFRV1xzY5OjrStGlTLly4YFOenJzMyJEjrZ/38ePH8/08i4u8ByWVedv2e3L2kiM4W16fMWqU5XknsDxrseLYCmvdttXaUi+hSilFem+GvlgVNLf8r2hwsszoemv5ndblU758+fUCj5uba2D4K6+wes0a6tatay1//8OPePG556gbGMDJi1GMf3EiS1a1AGHmSGQk//spDFdvV8LCwjh27BibN29Gp9MRHBzMiBEjcHBw4IsvviAsLAxHR0e++uorFi5cyPjx44v8majVaho1akRUVBQ6nY7169ezdu1atFotkyZNYs2aNQwYMIDMzExatmzJ22+/zdSpU1m5ciXjxo1jzpw5rFy5kipVqtzWDVejRg2GDh2Kk5MTL730EgCPPvoo27Zt44knnmDdunX06NEj31GWixYtYvXq1QC4urryyy+/sGLFCkaNGkW/fv3Izc3FZDLxzjvvcOrUKbZs2QJATEyMzX5OnTrF5s2bycnJoV27drzzzjv8/vvv/Pe//+WXX35h9OjRdOvWzTrx9syZM/nxxx8ZOXKkNRH27NnTZp/Z2dmMHz+esLAw/P39ee2111i+fLm1a9Hd3Z3NmzezbNkyvvnmGz799NMCP/+kpCQOHTrEuHHjbF639Nlnn9G4cWOWLFnC7t27ef3119myZcttn2dxkQlKKtOuX1cI23JjtojevQ34+NwYUrYr/RhnDZZ3jGlVWgY1HAQJex54nOWRVqMhsEULfvjhB5urnz/37uX02bMIBQxmI5kZmWRlp2JW5/BYuy6kZrmgt1zA8Nhjj+HiYpkWqV69ely+fJmUlBROnz5N7969ATAYDLRqdfezpOe9CHX37t0cOXKE7t27A5YTcd7bX3U6HZ07dwagSZMm7NpleQYuMDCQ8ePH8+STT9KtW+GDZQYPHsz8+fN54oknCAsLs95/udXo0aNvOwm3atWKuXPnEhsbS7du3ahdu3ahx2vbti16vR69Xo+zs7O1DQ0bNuT48eOAJYnNmjWL1NRUMjIyaN++/R33efbsWWrWrIm/vz8AAwYM4LvvvrMmqLzPoWnTpmzcuDHfffz999906dIFlUrFmDFjqF+/PuHh4Tbr87oqH3vsMZKTk0lNTS20vfdKJiipTPv5Z0cys3NQVODjY6ZXrxvdLjlmA98n7QQXy2CIHv498HL0Kq1Qyx1FpbDwizk8Pep5vvjiC15//XUAhNnMr6vCsPeqTGpOKteyriEEmNU52Nm5YTIqJCZa7g7c/O4olUqF0WhECEFwcDDz58+/59hMJhMnT56kbt267Nu3jwEDBjBp0qTb6mk0Gmt3rlqttt4bmzlzJocOHWLbtm106dKF33///Y7Ha926NTExMezduxez2UzDhg2LfJ+tb9++tGjRgm3btjFkyBA++eSTQl8rdOvnZmdnB1iGZOd1X44fP57FixcTEBBAWFgYe/fuveM+83uz+c3yjqFWq63HuFWbNm1s7p0V5Rgl2Z0uE5RUZkVHq9mzxw7Vvy/IGDEil5vfpfdr+j8kGlMBT1x0LvSq06t0Ar1PKxZcQTjbTs6qpCRbZnlwvn3S1oLW3Wmbgjg6OLB8+XL69OmDl5cXgwcPpn27diz5/nteGT8BZ50z+yP241ffD7VaYFJbBqZkZChkZ+d/YmrVqhXvvvsu58+fx8/Pj6ysLK5cuWL9Zl8Yg8HAzJkzqVq1Ko0aNUKj0TBixAhGjx6Np6cnycnJZGRkUL169QL3ceHCBetrgrZs2cKVK1ds1js5OZGenm5T1r9/f8aMGWNN1EUVHR2Nr68vo0aNIjo6mhMnTtCoUaPb9n+30tPT8fb2xmAw8L///Q8fH8ss83q9Pt97enXq1CEmJsb6ua9evZqgoKD7iuFWQUFBrFmzhvHjxxMeHo67uzvOzs75fp7FQQ6SkMqEW9+Oa3c8kp/npaP69024rf2u0qzZjW9917Ov87+0G8Nan27wNI5ax9IIvdxzc3Pjhx9+YM6cOWzatImpk9/h8JGjdOrUifbt27Ph5w0AqFSgaLIxqSzjzdPTFfL7Iu7h4cHnn3/OmDFjCA0N5cknn+Ts2bOFxjF27FhCQ0Pp1KkTmZmZLFmyBLB0Hf7nP5bBGaGhoQwaNIirV6/ecV9Tp04lJCSETp06ERQUREBAgM36zp07s2nTJpub+v369SMlJYU+ffoUuN+8gQB5PzExMaxfv55OnTrRuXNnzp49S//+/XF3d6d169Z06tTJOnLwbr355pv07NmTQYMGUadOHWt57969+frrr+nSpYvNIAZ7e3tmz57Niy++SEhICCqViqFDh97TsQsyYcIEIiMjCQ0NZfr06cyZMwfI//MsDooo7LqwFNz6bac88vT05Nq1a6UdxgNzv+21PxFp0+1x8IQzM77zA0Cdk8nnY47i1betdf2CiAXsPPAjaDRU823BjPYzUKssD0XpNq1F0TuT85jt23OLqxzAaeuvGO0d7nlfycnJODg43NPV0N1uUxzlVzOvkpGbASYjhmwnNNmWqxeNBqpWNVERpq379ddf2bx5M19++SUajaZEhtKXVSXZ3szMTBwdbb88Vq1atUjbyi4+qUwxNmmJyQTLlzkgnC0X+J0bnKG6V5b1TbjRKdHsuLiDvA6m5xo/Z01OUsnwcPCwJCizQK1NR+SmoTI4YjJBQqyJKh6W345wKJ9XsZMnT2b79u13vP8iPXhFSlAREREsXboUs9lMSEjIbZfABoOBefPmce7cOZydnRk3bhyVK1cGLP2zCxcuJCsrC0VR+Pjjj22+KUvSrXbs0HD5siU5OTgInm53DrAHLDdplx9bjkCgAC0d/Wni1aT0gn1I6NQ6XHQupBoSLV19+muYr9dEQSE7R0NSqsDdpRimmiglN49ilMqOQhOU2Wxm8eLFTJ48GQ8PDyZNmkRgYKDNDco//vgDJycnvvzyS/bs2cPKlSsZP348JpOJL7/8krFjx1KrVi3S0tLQ5PdchyT9KzcX1qy58fxJr14GXB0M5CWof67+w7Frloc3VYrCMM9OpRHmQ8nN3o30zCTMCITWjL17GjkpbgCkpINWY0Z/b29VkKR8FTpIIioqCh8fH7y9vdFoNLRt2/a2OZcOHDhAhw4dAMsoj6NHjyKE4PDhw9SsWdP6hLqzszMqlRyXIRVs2zaNdQizi4ugW7cbw8qNZqPNQ7mdHZtQXef5wGN8WKlVatxUTtZlgyYZB8cb9y2uXdeRnV0akUkVVaGXM0lJSXh4eFiXPTw8OHPmTIF11Go1jo6OpKWlERsbi6IoTJs2jdTUVNq2bWt9eO9mefNvAcyYMcP6EF55ptFoKkQ7iuq+26vXk5Or4tdfHa0TIQwaJPD01CM0GtBo2B23m4TsBDRqDY5aR4bYPYZGo0F7yzTbefVLqhxAqLivY6elpVm+rCkKKArKrV/cCiq/07oSLlepVFTSOJJqyMYAmIUZnet1zCZPcjIBFBIS1FSvDmXsVVf35GHr7Smp9trZ2d3zuaHQiIryYFZBdfIetvv444+xs7Pjo48+onbt2jRpYnvPIDQ0lNDQUOtyRRj9Jkfx3R379HQ2hlcjMdEybtndXdCuXSbp6aAzGsnISeP7w2sxmizf2J+s/ySOUSaMRiM5tzx/oTMaUUqwHMDJzH0d22g0otVqUYQAIRC3vNStoPI7rSvJcpVKhdlsRhHgoXEmTljakZJzHR9PPQmXNJhMYDQKrlwRVKlipjx3lshRfMUnJyfntnNDUUfxFfon5OHhYTMXU2JiIm5ubgXWMZlMZGZmotfr8fDwoFGjRri4uGBnZ0eLFi04f/58kQKTHi6Z2SrW/XljFoh+/Wwfyv05eQ/pBstJ0dvRmyf8nnjQIUr/clLZY6+xty6nGpPw9sglb1hlbq5yXy85DAsLIy4ursD1d/t6iSlTptCxY0emTJnC8uXL+fnnn4t0HKn0FXoF5e/vT2xsLPHx8bi7uxMeHs5rr71mU6dVq1bs2LGDevXqsW/fPgICAlAUhWbNmrF+/XpycnLQaDScOHGCHj16lFhjpPJr097KpGVqwBm8vc106HDj29wVQzIbrx8Ed3cABjcajFZdAfqQyjFXjSvZRssNp0xDJpWEgqfeiWtplmHmmamQioFKzpZ7iHcz/Pznn3+mQYMG1pkTbmYymXjzzTfvKtbvv/+eyMhI61Q/RTmOVDYUmqDUajUjR45k2rRpmM1mOnbsSI0aNawz5gYGBtKpUyfmzZvHq6++il6vZ9y4cYBlSo4ePXowadIkFEWhRYsWtGzZssQbJZUv6ekKG3Z7W5efespgM1H38pRdmLB0NzX0aEibKm0edIgVTkxMDIMHDqRFs2YcPXWK2rVrM3fuXBwdHfnsq/n8vn0H2QYDgYGBfPLJJ4BlpoXWTRrz9z8RdO3eHfeq7iz4agEGg4FKLi4s+XwuLs41+HzuHK7ExpCYeJUrV87y4buTOHj0GNu3b8fHx4dly5ah1WqJjIzkww8/JCMjA3d3dz7//HP279/P4cOHGTt2LPb29qxfv54OHTrwzDPPsHPnTkaMGMH27duts3lHRETw/vvvk5mZiZ2dHWFhYehvuv83fPhwMjMz6dmzJ2PHjiUqKgonJyeqV69+23EcHOQQxLKmSHfF8ua0utnAgQOt/9bpdEyYMCHfbYODg4vtZVpSxfTbb/Zk5RhQVFC1qpnHHrtx9XQk4QgHss+BRoOCwh7hCuIAACAASURBVHMBz1W4dz0N3fHS7a/OMBqAAl63UdC6fMqXdyv4wdOo8+eZPX0arTt0ZPz48Xz33Xe8/PLLjBwymDdefRXh7MLYsWPZsmULTzxh6VJNSUtj7crvEc4uXEu6RuDjgaDA+p/+x+cLv2Hq9FlodApXYqP58ss1XDh3nBdf7sWiRYuYPHkyo0aNYtu2bYSEhDB58mSWLl2Kh4cH69atY+bMmcyePZtly5bx3nvv0axZM2usdnZ2rF27FoDt27cDkJuby8svv8zXX39N8+bNSUtLw97e3qaNy5Yto27dutbXXnz22WcA9OzZM9/jSGXLwzVMRSpzUlIUtmyxByxdQQMG5FpvrpvMJpYfvXGCbV+jPX6V/EohyoqpWhUf2rRqhQCeeuopvv32W15++WX2/PU3Xy1eQlZuLtevX6d+/frWBNX7pldXJFxNYPL7k4m7Goch10C16lUQmHFygrZtO6HRaKnt2wCTyUz7NkEoWZk0qOPPpXNnOVfFh1MnT/LMM88Aluct8x7uz0+vXrdPBHz27FkqV65M8+bNActjLFLFIhOUVKo2bHAgN1dBDdSqkkVQ0I0/ye0XtxOTFoMKsFe0DGw4sMD9SPfglitRRVHIzs7m7Y+msHnNaqrWq8+nn35qfSsrWGY/z/Puu+/ywgsv0PDRhuzfs5clXy/jevZ1VCpwd9ehKJbRfxqNhqQUe7w9clCrVJhMlu7a+nXrsn7DhiKFeutcbmAZPVzRrqYlWzJBSaUmKUnFH3/cuHE9sHMcimL5FpxhyGDVyVXWdX3dHsXN3u22fVQEKzp8Uyqv27h8JZYD//zz/+3deXxTVd748c+9WZo2Sbd0pyyl7AWEUqSCylZAZVQUkHFERJzHjQd/oOOIKDNujOCoqGUcdVQYHFRQNkUFxYIj9GG3ooBAgUILpaVNl6Rp9vv7IxIoZRNa0qbn/Xr11dxzT26+pzfNN/fec8+hz/UDWb58Of369fMno+ioKGpqali1alW9mVtPslgsJCYmEq2L5qvP1gBQ5ajCq3hRqyEuzktJka9ujUtLlUsNGi1otaSmpFBuNrNt2zb/9OoHDx6kc+fOFz11Q4cOHSgpKSEvL49evXphtVrR6XQXfT9PY00RITQckaCEgPnsMx0ul+8bcGpyDX26Wjg5e8OKfSuodvpm6jSpjNwSeTVNbtj9Zq5januWLF/O4888S0pKChMmTCAsLIzxY8cw+Hc307ptW//ps7N57LHHuP/++0lISKBTt1SKjxajoFDrqsWIEb0eIsJOjc9XXi5z8lYbrVbLO/OymTnrb1RXV+PxePjjH/9I586dueOOO5g+fbq/88K5aLVa/vnPf/L0009jt9vR6XQsXrz4ohPUma8jOkk0PWK6jUYibtQ9v9JSmenTI/B4fAnq6THb6dPNgbtHOsdrjvOndX/C7fV9mj3q7s11cRmNNn1GS5xuo7CwkLvv+gPfffHFRdX336h7jtewV5ZwzF0Jal/3/yRDku9eqcpKjlbocSi+I2WNRiE5WUGqrUFRlCY7+rm4UbfhXM50G834Xm+hOVuxItSfnLp0cdE91eJf9+HuD/3JqWNURwaEdgpIjMLFC5W06OVTPejKa8t/vUakEBfl8F/ucrkkKirEdSPh4ogEJVxxR4/K5OaeuvY0enSt/wNsV9kuthRv8a+b0D34upU3Ba1bt+a7z899+uxSmNSnetE5PA5qXL5pybUqL9HRp4ZNqqyUcLrER49wYeJdIlxxK1aE+YfB6dnTRadOvqMlt9fDgp8W+OsNaDWAjlEdAxChcCk0kpqIkAj/cnltOd5frxyGh4NOd+pqQmmFVlxTFC5IJCjhijp8WMWWLacG2bv9dpv/8ZryzRRaCgHQqXT8odsfrnh8wuWJ0kWhknyzG3sUDxUe31GUJEFMjOI/Una6ZKqtYrgq4fxEghKuqGXLTvWU6tPHSUqKr99epdvCkpJv/etu63QbplBTvecLTZssyUSHRvuXqzw2nIrvCFmrhaioU8dNFRYNLagfgnAJRDdz4YrJz1eRl+c7epIkuP32Wv+6j0vWYvPYgRAS9YmMTG05gwqH5O9GCanbxVmqtYEs1Ss/37ozyx3dAjOEj0FjoFpVjcPjQAHK3NUkKFFIkkREhILFAi4PKF6oqJCJja0/pYgggEhQQiPR7dlZr2zl+x1Rl/tuBL2mr40OlgLYA3ttR/i+ZBOSRoMC3NvjXtRyy3prarR1T3dJhIIkoZxl5r9zrTu93OV01Xvemdqn9+FgXp5/efHixfz444+8+MTj/Pujj9BFRnHHHXec9bm5ubloNBr69u1bPz5JIiY0hqPWowDUeh3YXDb0Wj2SBCaTwnHfKqxWifBwOGOgcUEARIISGpH2tAmdfj6gZ3dBBJJUi6xRcecNZWi1WryKlw9KV/t76l2deDU943oGKuSA8vTo438s1dpAklHOGPz0fOtOlsv7d112LPfceed5R6TIzc1Fr9efNUEBhKhDMGqNWFxmAMrt5YRqQpElmbAwCNN5sNX6rjCUliokJ0tnjrwkCCJBCY3L3SMdRYEPP9GhGFVI9loG9ywldnB33MDXh77moMaGDGglNXen3R3okAXg729ko4+O5qGHHuLdd9/lgw8+QKVS0SmlHU/96U8sXLgQlUrF0qVLeeGFF0gONzDtqZmUV1VhMpmYO3cuiUmJ7N37M3+d/jxer8KgwYNY+N5CDhw4wP5dOcx+/S1Mpnj25+/im1Vr+N9p93OsuBiHw8F9//M/jB8/HoCOHTsyceJEvv/+eyIiIpg+fTqzZs3i6NGjPPvsswwfPjywfyyh0YgEJTS6vDwV+/b5enapZS9jBxYC7ah2VLP4l8X+eqOj+hMbFnuOrQgNzW53MPSWW0Hl2zcVFRWMGDGiXr158+axdetWNBoN1YWHiYiMYsKECej1eh566CEAJtx5J2NHjeKOe+7ho48+4umnn2bBggX8Y86b3HHXGIbdcgMrPl7h36ZKVtjzSx4LF6wjKakNFRYvc+fMJioyElttLTeNHsNNN91EdHQ0NpuNa665hqeeeor77ruPl156iY8++oh9+/YxdepUkaCCmOjFJzQqRYHFi0+d6ht21VFiI3zjsy3avch/M2e8OoJbIsVEhFeSThfCt5+tZO3ataxdu5Y///nPZ63XtWtXHn74YT799FPUvyazM23Py+P2m32Dyo4ZM4YtW3w3W/+Y9xM33JAFwLDfDUNB4eToar169qRVmxRQqXApGt6c/xFDR/6Om8eM5dixYxw6dAjwnSoePHgwAF26dCEzMxONRkPXrl0pKipquD+I0OSIBCU0qi1bVBQU+N5mWq3CbZkFAPx84me+K/zOX29SxEC0srgvpin6z3/+w7333svOnTsZPnrsRY3ZdvroH7HqiDrrrC7fCOL6sFAiI33JaseOjfz3v9/z+aefsnbV53Tv3t0/srparfZvT5Zl/9Ttsiy3qPHyWqKLOsWXl5fH/Pnz8Xq9DB06lFGjRtVZ73K5mDdvHgcPHsRoNDJ16tQ6k4+VlZUxbdo0xo4de9aJx4Tg5PXCkiWnjp5GjHATbXDi9Mq8u/Ndf3lmUiZ9ytoFIMKmRfXTdv9jyek8dy++c6w733Muldfr5dixY1x77bX07duX5cuWUWOzYTAYsFhOjZ+Y0bs3K774gjF3T2DZsmVcfbXvaDi911V88/U6BtyaxcolK4G6I0xERChUVUnU1FRjNEbg9hrYf+AXduzY0WBtEJqvCx5Beb1e3nvvPWbMmMHcuXPZuHFjvcPqnJwc9Ho92dnZjBw5kkWLFtVZv2DBAnr37t2wkQtN3oa8SI4e9b3FQkMVbrnFd2rvk4qNHK85DkCYJox7ut8TsBibCpfTVfenthaXvbZ++fnWnVbeUDweD5MnT2bgwIEMGzaMB+6ZQER4OMOGDeOrr74iKyuLTZs28cJTM/h42TKGDBnCp59+yvPPPw/A809O5+3587n79rupKKtAb9DjVbxUe3wjiMgyREYq9Os3BI/Hw0233chLc18jPT29wdogNF8XPILKz88nISGB+Ph4APr378/WrVtJTk7219m2bRtjx44FIDMzk/fff98/2+WWLVuIj4/3H5YLLYPbI/HJt/H+5RtvdGE0wmFXGSsrNkO0b7SBu7rdFbQTEV4sR4duAZmw8OCO7XWWx40bx7hx46CqgscfmeLfzmeffVZ3ug0gNTWVnJycOq+9dOHCeq+dEB/Pl58sgfAIFi9dzJ7uewDokpHGv/pfB0B4uEJVVQivvPIReDxEhzsJjz11FLh//37/48cee6zO9k9fJwSfCyYos9mMyXRqyBmTyVTvTXF6HZVKRVhYGBaLBa1Wy8qVK5k5c+Z5Jx47eZEWYPbs2cTExFxSY5oStVodFO24WGe29+s9rSitCEUdocJggHHjQggN0/BOVQ5eSUGtUtMtthu3dLsFSZJQ1GpQq9EYDPW2fa51gSoHUGRfmy91WxaLBVmWfUNqSBKSfMbJjHOVn29dI5dfSrw/7d7Nk8+/gCLJRERE8NSsp/zrTniqaSPFoVZLREfDiRO+8iqrhsh4NWdr+pV0sRMfBovGam9ISMglfxZeMKKzzWd45vQH56qzZMkSRo4cie4sNxueLisri6ysLP9yMEz015InLHQ64cOvIvF6vShuDzfe6ERRXCz96Sv22o+BWo2kwISuE6ip+XVKBrcbye3GcZYpuM+1LlDlAHovuC9jW263G41Gg6QooCgo3rrD/Zyr/HzrGrPcfwT1G7fVr08fcj77zH9k5fa6KbIU4QVcXjfltnKiQ6MxGKCiQsLtAY8HzGaPvwNFIIgJCxuOw+Go91l4sRMWXjBBmUwmysvL/cvl5eVERUWdtY7JZMLj8WD79SJqfn4+mzdvZtGiRdTU1CBJElqtlhtuuOGighOap/XrQzBXeZBk3+mbESNclNeWs3jPqXueRnUcRbIx+TxbEYKRWlYTrYumzFkMQKWjEr1WT4gqhKgohRO+S5NUVckYjR7O0atdaEYuZ9L2Cyao1NRUiouLKS0tJTo6mtzcXB555JE6dfr06cP69evp1KkTmzZtIi0tDUmSeO655/x1lixZgk6nE8kpyNXWwuefhwK+I4VRo5yEhCi8tvlf2D12ZCBZG8OtHW4NaJyBplKpcLlcaC9cNegYtUasUhl2fJ05TthO0MrQCoNBolLtxeWS8HqhqkoiOlrMGtWcud1u36nhS3TBBKVSqZg0aRKzZs3C6/UyePBgWrduzeLFi0lNTSUjI4MhQ4Ywb948pkyZgsFgYOrUqZcckNC8ff21jupqGRVginCRlaVm3ZF15JX6BiWVkHgw9gY0qpZ9z5PRaMRisWA/UYqk0eBR1/17yGUnkNTqeuXnW9eY5SdPATXUa4RW2NjjKMAT4kvRNeE1tAlvA7UW8g/pUdQaZNk3JYs2AFk8JCTEfx9WS9AY7VUUBVmWL3iJ53wu6qpYenp6vW6f48aN8z/WarU8+uij593GuUZFFoJHdbXEl1+emgLi98OPU+U2sPDnhf6ykYZedA1tTcv51z87SZIIDw9HW3QIyWDE0blbnfXazd+dtfx86xqz3GAwYLVaG/A1ivjRtY8PFN+o9ypJxazrZ9FFbeZfqyI4ZPXdR1lcbGf8eBtXWku+htyUiJEkhAazalUodruvA01SrJ3repl5K+8t7B47AIn6RP4QMSCQIQpNyM2RfekU3Qnwzb775g9v4lE83JF11F9n3boQysvFx1RLJfa80CBKS+Hbb0/d6zZu2FG+rtjErjLf1A8SEg+nP4xWalldd4VzkyWZB3s9iFb2ncM7Un2ET0py6N25mtRUX48yt1ti5cr6kzYKLYNIUEKD+PhjGbfbd/SUmuomsX0+/yle419/a8db6RjVMVDhCU1UkiGJ33f7vX95+Ynv+MVWwJgxp07rff+9luJi8VHVEom9LlwW3Z6dlK3fx/qVVais1ais1fy+z1be3L8Al9P3IdMmvA2jO40OcKRCU3Vjyo2kxaQBvgvrbx5dRruO1XTt6uvl5/VKfPJJWCBDFAJEJCjhsn2a0wYF3ygC6V1q+Mm4iiNu371zGlnD/6b/b4vvtSecmyRJTO49GYPGgGSvxWwt4T/rX2R8+g7/l5687+wc+vJgoEMVrjCRoITLsu+Inq17wpEiIlGMEaRNOMwXzlNTjo9PG+/rPiwI5xEdGs39ve4HQNJo2GzZTWnUVq5Pr0KSZSRZ5j9fJXMZ93wKzZBIUMIlUxT4+OtW/uXe15xgZcmb/uUMfQeGtxOznQoX5+rEq8nSdwdACY/gXesGrnvAhcbkGybp0LEwcnNb4q3NLZdIUMIl27FDwy8FvsFPZZWH8q4vU+2sBiBKpWdy3Mh64zYKwvlMjBhIksY30r3dY+ffB15l2I2n5p369NMw7PZARSdcaSJBCZfE5YLFi09duI4YuJAj9t2Ar0v5lKgRhKvEhW3ht9HJGv6UcJu/63mRpYjy9m8Rrvd1mDCbZZYtE++rlkIkKOGSrF2ro6TEN5KnPW4TJ0zL/evGdhlLT5247iRcmrYhcdzX8z7/8qaS70kbvtS//PXXOg4eFKPItgQiQQm/WXX1qZsn7SHF2NOzOTmVTO+43tzW8bYARicEg4FtBjK4zWD/8tbQj2nVxTcskqLAggV6PJ5ARSdcKSJBCb/ZsmWh1NZKeGQbJWmvEBHpu+4UGxrLw+kPi+tOQoO4t8e9tA1vC4Bb8VB21d8h1Hf7wuHDalavvvRBSIXmQSQo4TfJz1ezbp0OBS8Fya8S2eogkgQalYZpfadh1BoDHaIQJLQqLdP6TkOv0QPgkCtRrp+FV3ICvi9KBQXiVF8wEwlKuGhuNyxY4LtAfSz+30hJ2wk3+C5eT86YTPvI9oEMTwhCCfoEpmZMRZZ+/aiK3o81LRsFBbdb4s03DaJXXxATCUq4aN98o6OwUE155DeUx3xOcrIHCbgtbiCD2g0KdHhCkOoR24OJSTcBIEkQ0vk7zAm+ThMlJSo++EAfyPCERiQSlHBRyspkli0LpVqfR1HiOyQkeNFqFfqEd+HOhGGBDk8IcjeYMhkSlQFASIiC1OsDzBHrAdiwIYT//jfkPM8WmiuRoIQLUhRYMKeGansehxP/hk5dS3xYJe1deqaqMlFXVwY6RCHISZLExMSb6BLdBYDoaC813bOp1u8A4N//DuOXX8RULsHmovZoXl4e8+fPx+v1MnToUEaNGlVnvcvlYt68eRw8eBCj0cjUqVOJi4tj586dLFq0CLfbjVqt5u6776Z79+6N0hCh8axZo2PH0RMc6PIyXpWDdol24kIieTL1HvQnqgIdntACyEePEOpx8+fYoTznOkyhvYTWURIHUmah3TkTfWV7srMN/PWv1cTFeQMdrtBALngE5fV6ee+995gxYwZz585l48aNFBUV1amTk5ODXq8nOzubkSNHsmjRIgCMRiNPPPEEr7zyCpMnTyY7O7txWiE0msJCFYuW28jvOBu32kpCKxVxyQlMv+llIvsMvvAGBKGBqCOiiAoNZ2aHScTqolGrJFLaVHKk60vU6o5itcrMnWvEahW3OQSLCyao/Px8EhISiI+PR61W079/f7Zu3VqnzrZt2xg0aBAAmZmZ/PzzzyiKQkpKCtHRvnG1WrdujcvlwuVyNXwrhEbhdMIb/3Kwt9WzOLXl6HUe2rbW8ETmEyQbkwMdntACuXukE54+iOk3voze1AqNyUjbhEIOdngel2svJftqeONpO/z4M7o9O9Ht2RnokIXLcMFTfGazGZPJ5F82mUzs37//nHVUKhVhYWFYLBbCw8P9dTZv3kxKSgoaTf15gdauXcvatWsBmD17NjExMZfWmiZErVY363YoCrz4WiXfhzyLS1OM7JHokOzi6YEz6J3Y+1Q9tRrUamRZxmAw1CvXnFZ2KeUNua0GjUn27eOAvHYA2n1y/zaVfdHZ0JlnhzzLX9f/FVVoCcltSshXvUjn/TM5VJzIvE+68vQfC1GrvBgu4f+wuf///lZNtb0XTFDKWSZgOXOkgAvVKSwsZNGiRTz11FNnfY2srCyysrL8y2VlZRcKq8mLiYlp1u1Y9pWNdw/NwRFyDBRoF2vniQ5j6GzsjNVq9dfTut1IbjeS13vWcsdpZZdS3pDbasiY9F5wB+i1A9Fug8GA1WptUvuiVUgrHst4jL8XPUKU0YGzQxW/qObQ6cgL7DiWyJwFTiaPycd9Cf+Hzf3/97e60u1NSkq6qHoXPMVnMpkoLy/3L5eXlxMVFXXOOh6PB5vN5v82XV5ezssvv8zkyZNJSEi46AYIgbMxr4I522b7khMQE63wXPdbyYxIC3BkglBXV1NXnoy5Fa2kJjZOIaZNGfvazqA2pIAtuyLIXpyC2x3oKIVLdcEElZqaSnFxMaWlpbjdbnJzc8nIyKhTp0+fPqxfvx6ATZs2kZaWhiRJ1NTUMHv2bO688066dOnSKA0QGtbmvUd5dPWL2LXFAOhD4YUbH6BfRLcARyYIZ5cWksyMxLFoZS2JCV6ikszsa/MUVv1etu6O5J//NIgk1UxdMEGpVComTZrErFmzmDZtGtdccw2tW7dm8eLFbNu2DYAhQ4ZgtVqZMmUKq1at4q677gJg9erVHD9+nKVLl/L444/z+OOPU1UluiU3VTtyVvP/lr6Aw1OK5HahVTzMSRvBYEsImuNFqKoqAh2iIJxVj7B2TM+cTpgmjORWXkyJVvZ3eJGq8B/Ytk0rklQzdVH3QaWnp5Oenl6nbNy4cf7HWq2WRx99tN7zRo8ezejRoy8zROFK+DZ/C09v+wQ7XpAktIqO1/uMZkQ7X289WSVughSatm4x3fjLgL/w4qYXoVUVUnUVB1JeJvlYCTvWj+BfpVamjDuEWuW7Zm7v2jPAEQsXIkaSaOG8ipcFP3zKk6veodblm2BHK8Xy6qjnGHrrLbh7pOPukX6BrQhC09Auoh3PXvsscfo4WsfUEG9yUNRmEYVt32fL3nDeXNoBWRbDIjUXIkG1YDaXjb9tfIN/rF+Nw+HrdamzJ/DyiGcY3rdtgKMThEuToE/guWufo6M2gdYxNuKSVJTFb2B/t1f5viiClxa2w+EUN/M2B+K8TQuk27OTQ7XHeHH/cv6vwI7LLSEBkRXdmHvVCAZc2/TuhxCE3yJSF8mzsWN427aBddHHAZnSkl38kjIV+/4/Yl3QkUdmSYSF1b9FRmg6xBFUC6MoCl+U5/Lo7oVsPOTA5ZFBkkg6cTP/6jaYIWm2QIcoCA1CK6mZEvc77ux2J62TFRISFVyqCvZ3mM1612r+NjuMqipxJNWUiQTVgpjtZl7d8Sqv/bKOX46E4JE0yLKBzpV/JnvKRPp2EL30hOAiSRK3dryV6ZnT6dLOQHJrL0gKxxNXkCM9w1NzLJSXi4/BpkrsmRZAURTWFa5j+vczWLVjF4UloShAmL0j/Stf4R9/7kuPHp5AhykIjeaquKuYM2gOg7t1o11iLQA1YfvYYHycB17/liNF4lRfUyQSVJA7aj3K7K2zeeeHf7NzjwuzWQVAfMlIhkuzePmZKNq0EdMTCMEvShfFU9c8xeTOA+nQyoEkKSiym/36D/nDgtl8uflwoEMUziA6SQQpq9PK8gPLyTmSQ1k5FB1V4/VKhDiSaHtgPCM7JTFppgudLtCRCsKVI0syY92ppCeF8azmBzYcqcTrBau0lxlr/8q6nd15cvx9xCA6CjUFIkEFGafHSU5hDisPrKSq1kZRkZqqKhkUmbjyUbQyj+HeQfn87rpCPLrYQIcrCAHRIaYT77XP4N3ILbz+80bsHt8p7m9Kf2b7v59i6g23kdVqAGGasABH2rKJBBUkHB4H6wrX8cWhL6h2VFNWJlNcrMHjlTDUpNHq+CTaRbbmgRlW0pwnkCRtoEMWhIBSevblvp59uf7asTwy/2MO2DYCUF7lYtaKT1jcdjl39BzB8LbDCVWHBjjalkkkqGauylHF+qL1rD2ylmpHNRaLzLFiNbW1MrqaaNoV3UlEVR+G9i1n/I0b0Tm9vnH1IqIQQ5MJAnRMjGPlnx7hlZd78lHZ59Qaj+N0ws/7XBw7sZLP26wmK2UgWW2yiAkVp/6uJJGgmiFFUThQdYCcwhw2F2/G7XVjtUocL1FjtcpoXNEkl91ObFE/kmMU/vg/h+nZ0crJ3S3G1ROEurRamHlzOIPzJvHCFgtHwpdRqz6KuUJFVbWLotKv+fLgGvolZjCo9SC6RXerNy+e0PDEJ1UzYrab2XhsIxuObuC47TiKFyqrZE4c9VJrV6FxRtLm+M2YygcSolIxqvcexmRVoAweUudoSXv0SMDaIAhN2dXdLLw1+CqWrxjMirx1lMQsxRFyjOJiFaWlCiWl29lYtIVEYwwDWg1gQNIA4sPiAx120BIJqokrsZWwvWQ720q2caDqAChQWythNqswV8h4PBKGqlRSym4gsvJq1KjIyjQzemgJMZbDSBojjkA3QhCaAfnoETQeN0nAE8MMDDCFs2DVTPa791Aav5rqqH0cP67i+HGZwvBK8o9/zrJ9K2kf2ZY+8X3IiM8gSZ8kjqwakEhQTYzVaWWPeQ+7zLvYXb6bElsJKGCzSVhKnVRYNDicErJXS1TF1cScGIqhohUhOhXX3h7O737nIiEhHoiH1QcD3RxBaFbUEVFIWi2SJHF1dzvpXQ7w/Tew9P8e4FCRlTLTeszRuVjcVixm30gVh0MPsiW6CL1+Oa2io+gZl0aayfcTrg0PdJOaNZGgAsireCmuKaaguoBDVYfYV7GPI5YjKCi4XGCxyFiqVVRbfEdKkksm3JpGovk6IqsyUHl1xEY6GXrtfkYMqEQ3YmCgmyQIzZ67Rzo6gwG31QrA0JIVDO5nZcORFL7ZPIafd91FVcQOzFEbqA7/CYsNqp0qQMWBAxa2hv4fBnUOep2bfmqhdAAADeJJREFUDsY4ekYl0DGsFe1DW5EcEotKUom5qC6SSFBXgKIoVDgqKK4p9v8UWgopqC7A4XGgKGCvlbDZJGorXNTYVdgdMqAgeTWEW7oTWZFB5IluaIhCm2QiY4SHgQPddO+uJmTNISS9OJUnCI1FpYLMu9uTeTccPy7x/feD2LEjiwM/lVBp/AFz/E6s+h/xqGqx1UrUurWckEIoOF5DjpRPaMg+wnQejDqZDvp4OjrTaBORRJIhiSR9EtG6aHFq8CxEgrpMiqJg99ipdlZTXluO2W7GbDfjPOyksLwQs91Mia3En4gcDgmHQ8JZWYvDqcLulLHZVSgKgILk0aCvbU9CTU/CLWnoazoiK1oiDW56dzlC3x4lpN3TG624jUkQAiIhQWHsWBdjx7qoXrKRvEMR7LGOZs/h8eTbjmEx/oxF/yM1xoMoWhVeoMbl+zlR6eagUsaaglxCQhTCQr2EhoIxVEtCuInkSBNxxmhidDHEhMYQERJBuDaccG04Bo2hxSWxi0pQeXl5zJ8/H6/Xy9ChQxk1alSd9S6Xi3nz5nHw4EGMRiNTp04lLi4OgOXLl5OTk4Msy9x777306tWr4VtxkbyKF7fX7ftRfL89Xo//scPjwO6x43D/+tvjqPPY5qrF4rRSZbdicVixOH2/nR4PXg94PBIeD3i8ABpqa9243RIuF7hdGlzuU28uya0DSULjiiTc1h69rT1hthSM5W1QYUSKjaFTNw+9enm46ioPbduqCVmzG8lgxCGSkyA0CTHhDoYNqGVIxHEArDYV+wvT2fdDV/KrDOSpFYqd+7Hp8qkJ3Y9LOu5/ru/LqoqKSgAPeykFSlGrFbRaBa0WVCoFlQrUKtCoJQxaI+GacAxaAwaNnlCNDr1WR5hWh0Ebij4kFGOIDmNoKCEqLRpZg0alQSNrUMvqOr81sgaVpGrSSe+CCcrr9fLee+/x9NNPYzKZePLJJ8nIyCA5OdlfJycnB71eT3Z2Nhs3bmTRokVMmzaNoqIicnNzefXVV6moqOD555/n9ddfR5YbZ4xarxdef93ANs08SqVdeHHjxY3n198Kvw6KqsDJsYsV/4NTZQCKV8KrgOLltN8Sktt17hcH+LVtkuRGUbz+cpVixGBPQmdPJMSeRGh1DHpHB9TGjgCYTF46dPfS1fp/dGjvIXl0XzFOniA0E+4e6QDogB79oI9hhe/L5LVDqapK5fBhFQUFMvu+2cTPlgqOKDXU6o5h1x3DrjuKR672bUiW8bih1g61UO9zBSp9P/XKz0KjRpJ8VSTp1x+Ak48lBQkJlaRBo9ageBQkSUZGRkKFjArJ/1j2P77G+Tg3DjSSnn6Oz8IGdMEElZ+fT0JCAvHxvr7+/fv3Z+vWrXUS1LZt2xg7diwAmZmZvP/++yiKwtatW+nfvz8ajYa4uDgSEhLIz8+nU6dOjdIYSYK8PC2H29iwGCrPUqOBEuMZ3zhkrwa1U4/WZULjiUXrjCbEHYPaEUWI1YDWHY9KikYGYiJdJMY4SI4pJjGpksS2P9A6wU50uO9OJfnoESSDEc/+Hed8efVPZ1/X2OXnW6fs2IzaUf8q2JV47ab49wi211ZCQurs32DfF2e293Je2wSYJEhPAXlkIZLBSI2uLUdKOlNwTMfh4lAKC8s44nRx3GPDpi7HqS3DqS3HTTlubQ0urQWP+ozJRE9mnbNRFBRFQlFO5bL6Tj7XjSx58CoXN+WIYb9E37QrMxHGBROU2WzGZDL5l00mE/v37z9nHZVKRVhYGBaLBbPZTMeOHf31oqOjMZvN9V5j7dq1rF27FoDZs2eTlJR0aa0BvvkG4IVLfv6VkxLoABqcJtABXGGivcGtMdsbCsQA6f6Szo34as3XBdOgcpaseuY5y3PVOVv52WRlZTF79mxmz559UfWbg+nTpwc6hCtKtDe4ifYGt6ba3gsmKJPJRHl5uX+5vLycqKioc9bxeDzYbDYMBkO955rNZqKjoxsqdkEQBCGIXTBBpaamUlxcTGlpKW63m9zcXDIyMurU6dOnD+vXrwdg06ZNpKWlIUkSGRkZ5Obm4nK5KC0tpbi4mA4dOjRKQwRBEITgonrmmWeeOV8FWZZJSEggOzub1atXc91115GZmcnixYux2+0kJSXRpk0bNmzYwIcffkhBQQH3338/BoOBiIgIrFYrb7/9Nhs2bGDSpEmXdX2puWnfvn2gQ7iiRHuDm2hvcGuK7ZWUi71QJAiCIAhX0JXpKygIgiAIv5FIUIIgCEKTJMbiawCTJ09Gp9MhyzIqlYrZs2ezZMkSvv32W8LDfcPt33nnnaSnp19gS81DTU0Nb731FoWFhUiSxEMPPURSUhJz587lxIkTxMbGMm3aNAwGQ6BDbRBna29eXl5Q7t9jx44xd+5c/3JpaSl33HEHAwcODMr9e6721tTUBOX+BVi1ahU5OTlIkkTr1q15+OGHqays5LXXXsNqtZKSksKUKVNQqwOfHsQ1qAYwefJkXnzxRf+bGWDJkiXodDpuueWWAEbWOObNm0fXrl0ZOnQobrcbh8PB8uXLMRgMjBo1ihUrVmC1Whk/fnygQ20QZ2vvF198EbT79ySv18sDDzzA3/72N9asWRO0+/ek09u7bt26oNy/ZrOZmTNnMnfuXLRaLa+++irp6ens2LGDfv36MWDAAN555x3atWvH8OHDAx2uOMUn/DY2m409e/YwZMgQANRqNXq9nq1btzJwoG8+qoEDB7J169ZAhtlgztXeluCnn34iISGB2NjYoN2/pzu9vcHM6/XidDrxeDw4nU4iIyPZtWsXmZmZAAwaNKjJ7N/AH8MFiVmzZgEwbNgwsrKyAFizZg3//e9/ad++PRMmTAiKUyKlpaWEh4fz5ptvcvjwYdq3b8/EiROpqqry38AdFRVFdXV1gCNtGOdqLwTn/j3dxo0bGTBgAEDQ7t/Tnd5eCM79Gx0dzc0338xDDz2EVqvlqquuon379oSFhaFSqfx1zjYkXSCII6gG8PzzzzNnzhxmzJjBmjVr2L17N8OHDyc7O5uXXnqJqKgoFi5cGOgwG4TH4+HQoUMMHz6cl156iZCQEFasWBHosBrNudobrPv3JLfbzfbt2/3fqoPdme0N1v1rtVrZunUr//jHP3j77bex2+3k5eUFOqxzEgmqAZwcvikiIoK+ffuSn59PZGQksiwjyzJDhw7lwIEDAY6yYZhMJkwmk38Q4MzMTA4dOkRERAQVFRUAVFRU1Lke15ydq73Bun9P+uGHH0hJSSEyMhIgaPfvSWe2N1j3708//URcXBzh4eGo1Wr69evH3r17sdlseDweoGkNSScS1GWy2+3U1tb6H+/cuZM2bdr4/5kBtmzZQuvWrQMVYoOKjIzEZDJx7NgxwPeGT05OJiMjg++++w6A7777jr59+wYyzAZzrvYG6/496czTXcG6f086s73Bun9jYmLYv38/DocDRVH87+e0tDQ2bdoEwPr16+sNZxcoohffZSopKeHll18GfKeDrr32Wm6//Xays7MpKChAkiRiY2O5//776w2y21wVFBTw1ltv4Xa7iYuL4+GHH0ZRFObOnUtZWRkxMTE8+uijQXHOHs7e3vnz5wft/nU4HDz00EPMmzePsLAwACwWS9Du37O1N5j/f5csWUJubi4qlYp27drx4IMPYjab63Uz12gCP8GKSFCCIAhCkyRO8QmCIAhNkkhQgiAIQpMkEpQgCILQJIkEJQiCIDRJIkEJgiAITZJIUIJwhS1btoy33nrrououWbKEN954o5EjEoSmSSQoQbgEkydPZufOnXXK1q9fz8yZMy/43Ntvv50HH3yw0eIQhGAhEpQgCILQJInRzAWhEZjNZt5//3327NmDTqdj5MiR3HTTTYDvtN3x48d55JFHAN/QQYsXL8Zut3PTTTexbt06HnjgAXr27An4BjKdN28eW7ZsISYmhsmTJ5Oamkp2djZlZWXMmTMHWZYZM2YMt956a8DaLAgNTRxBCUID83q9zJkzh3bt2vH222/zl7/8hS+//PKso0YXFRXx7rvv8sgjj/DOO+9gs9nqTXWwfft2+vfvz4IFC8jIyOD9998HYMqUKcTExPDEE0/wwQcfiOQkBB1xBCUIl+jvf/+7fw4d8B3ppKSkcODAAaqrqxkzZgwA8fHxDB06lNzcXHr16lVnG5s2baJPnz506dIFgHHjxvHVV1/VqdOlSxf/dOPXX389X3zxRWM2SxCaDJGgBOESPf744/7TcODrJPHtt99y4sQJKioq/BMbgu+oqmvXrvW2YTabiYmJ8S+HhIRgNBrr1ImIiPA/1mq1uFwuPB5PneQoCMFIJChBaGAxMTHExcVdVPfwqKgo/1QeAE6nE4vF0pjhCUKzIa5BCUID69ChA6GhoaxYsQKn04nX6+XIkSPk5+fXq5uZmcn27dvZu3cvbrebJUuW/KbXioyMpLS0tKFCF4QmRSQoQWhgsizzxBNPUFBQwOTJk7nvvvt4++23sdls9eq2bt2aSZMm8dprr3H//fej0+kIDw+/6Ll4Ro0axdKlS5k4cSKfffZZQzdFEAJKzAclCE2I3W5n4sSJvPHGG8TFxQU6HEEIKHEEJQgBtm3bNhwOB3a7nYULF9KmTRtiY2MDHZYgBJzoJCEIAbZt2zbmzZuHoiikpqYydepUJEkKdFiCEHDiFJ8gCILQJIlTfIIgCEKTJBKUIAiC0CSJBCUIgiA0SSJBCYIgCE2SSFCCIAhCk/T/AdrjPeBLPNL9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VNNtYQJCw3H4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### plot_host_scat_sns"
      ]
    },
    {
      "metadata": {
        "id": "IUW1qHOAw3H5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Import matplot.pyplot, and matplotlib.ticker \n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "# Plots histogram and scatter (vs price) side by side\n",
        "def plot_hist_scat_sns(df, target='price'):\n",
        "    \n",
        "    \n",
        "    ## ----------- DEFINE AESTHETIC CUSTOMIZATIONS ----------- ##\n",
        "   # Axis Label fonts\n",
        "    fontTitle = {'fontsize': 16,\n",
        "               'fontweight': 'bold',\n",
        "                'fontfamily':'serif'}\n",
        "\n",
        "    fontAxis = {'fontsize': 14,\n",
        "               'fontweight': 'bold',\n",
        "                'fontfamily':'serif'}\n",
        "\n",
        "    fontTicks = {'fontsize': 12,\n",
        "               'fontweight':'bold', \n",
        "                'fontfamily':'serif'}\n",
        "\n",
        "    # Formatting dollar sign labels\n",
        "    fmtPrice = '${x:,.0f}'\n",
        "    tickPrice = mtick.StrMethodFormatter(fmtPrice)\n",
        "    \n",
        "\n",
        "    ## ----------- PLOTTING ----------- ##\n",
        "    \n",
        "    ## Loop through dataframe to plot\n",
        "    for column in df.describe():\n",
        "    \n",
        "        # Create figure with subplots for current column\n",
        "        # Note: in order to use identical syntax for large # of subplots (ax[i,j]), \n",
        "        # declare an extra row of subplots to be removed later\n",
        "        fig, ax = plt.subplots(figsize=(12,10), ncols=2, nrows=2)\n",
        "\n",
        "        ## ----- SUBPLOT 1 -----##\n",
        "        i,j = 0,0\n",
        "        ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
        "        \n",
        "        # Define graphing keyword dictionaries for distplot (Subplot 1)\n",
        "        hist_kws = {\"linewidth\": 1, \"alpha\": 1, \"color\": 'blue','edgecolor':'w'}\n",
        "        kde_kws = {\"color\": \"white\", \"linewidth\": 1, \"label\": \"KDE\"}\n",
        "        \n",
        "        # Plot distplot on ax[i,j] using hist_kws and kde_kws\n",
        "        sns.distplot(df[column], norm_hist=True, kde=True,\n",
        "                     hist_kws = hist_kws, kde_kws = kde_kws,\n",
        "                     label=column+' histogram', ax=ax[i,j])\n",
        " \n",
        "\n",
        "        # Set x axis label\n",
        "        ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
        "    \n",
        "        # Get x-ticks, rotate labels, and return\n",
        "        xticklab1 = ax[i,j].get_xticklabels(which = 'both')\n",
        "        ax[i,j].set_xticklabels(labels=xticklab1, fontdict=fontTicks, rotation=45)\n",
        "        ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "        \n",
        "        # Set y-label \n",
        "        ax[i,j].set_ylabel('Density',fontdict=fontAxis)\n",
        "        yticklab1=ax[i,j].get_yticklabels(which='both')\n",
        "        ax[i,j].set_yticklabels(labels=yticklab1,fontdict=fontTicks)\n",
        "        ax[i,j].yaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "        \n",
        "        \n",
        "        # Set y-grid\n",
        "        ax[i, j].set_axisbelow(True)\n",
        "        ax[i, j].grid(axis='y',ls='--')\n",
        "\n",
        "        \n",
        "        ## ----- SUBPLOT 2----- ##\n",
        "        i,j = 0,1\n",
        "        ax[i,j].set_title(column.capitalize(),fontdict=fontTitle)\n",
        "\n",
        "        # Define the ketword dictionaries for scatter plot and regression line (subplot 2)\n",
        "        line_kws={\"color\":\"white\",\"alpha\":0.5,\"lw\":4,\"ls\":\":\"}\n",
        "        scatter_kws={'s': 2, 'alpha': 0.5,'marker':'.','color':'blue'}\n",
        "\n",
        "        # Plot regplot on ax[i,j] using line_kws and scatter_kws\n",
        "        sns.regplot(df[column], df[target], \n",
        "                    line_kws = line_kws,\n",
        "                    scatter_kws = scatter_kws,\n",
        "                    ax=ax[i,j])\n",
        "        \n",
        "        # Set x-axis label\n",
        "        ax[i,j].set_xlabel(column.title(),fontdict=fontAxis)\n",
        "\n",
        "         # Get x ticks, rotate labels, and return\n",
        "        xticklab2=ax[i,j].get_xticklabels(which='both')\n",
        "        ax[i,j].set_xticklabels(labels=xticklab2,fontdict=fontTicks, rotation=45)\n",
        "        ax[i,j].xaxis.set_major_formatter(mtick.ScalarFormatter())\n",
        "\n",
        "        # Set y-axis label\n",
        "        ax[i,j].set_ylabel('Price',fontdict=fontAxis)\n",
        "        \n",
        "        # Get, set, and format y-axis Price labels\n",
        "        yticklab = ax[i,j].get_yticklabels()\n",
        "        ax[i,j].set_yticklabels(yticklab,fontdict=fontTicks)\n",
        "        ax[i,j].get_yaxis().set_major_formatter(tickPrice) \n",
        "\n",
        "        # Set y-grid\n",
        "        ax[i, j].set_axisbelow(True)\n",
        "        ax[i, j].grid(axis='y',ls='--')       \n",
        "        \n",
        "        ## ---------- Final layout adjustments ----------- ##\n",
        "        # Deleted unused subplots \n",
        "        fig.delaxes(ax[1,1])\n",
        "        fig.delaxes(ax[1,0])\n",
        "\n",
        "        # Optimizing spatial layout\n",
        "        fig.tight_layout()\n",
        "    return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XheM8K-w3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FLATIRON BOOTCAMP NOTES"
      ]
    },
    {
      "metadata": {
        "id": "OioV1NqGw3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting started \n",
        "\n",
        "### Git Bash Terminal\n",
        "* Launch Git Bash on Windows\n",
        "    * Can right click inside a folder in Windows and select GitBash to start in current folder\n",
        "```python      \n",
        "      source activate learn-env # Make sure to use learn-env \n",
        "```\n",
        "* [!] New Conda Warning / Updating Your Learn-Env Packages\n",
        "   * If you see a message that states “WARNING: A newer version of conda exists” run :\n",
        "```python\n",
        "    conda update -n base conda # and then try again to create the environment using:\n",
        "    conda env create -f environment.yml.\n",
        "```\n",
        "#### [!] if Jupyter Notebook doesn’t have the Learn-env kernel as an option:\n",
        "```bash\n",
        " python -m ipykernel install --user --name=learn-env\n",
        "```\n",
        "#### General terminal commands\n",
        "\n",
        "cd d: # change to d drive before calling folders\n",
        "cd('D:/Users/My Name/My Flatiron Files') # in quote\n",
        "cd .. # move up one level \n",
        "\n",
        "ls # list folders in current directory\n",
        "pwd # print working directory\n",
        "mkdir #new folder\t\t\n",
        "\n",
        "Ctrl + C # to interrupt kernel\n",
        "Ctrl + Shift + Insert # to paste\n",
        "\n",
        "Up Arrow / Down Arrow # cycles through previous commands \n",
        "        \n",
        "#### Cloning Git, Loading Jupyter Notebook\n",
        "```bash\n",
        "source activate learn-env #gitbash\n",
        "git clone <URL> # control+shift+insert to paste\n",
        "cd(''D:/Users/My Name/My Flatiron Files'/new-cloned-git-learn-lesson/) \n",
        "\n",
        "jupyter notebook #launches notebook in current dir         \n",
        "```\n",
        "- Click on index.ipnb # Lessons are containeed in index.ipnb*\n",
        "- Click Kernel > Change Kernel > learn-env\n",
        "    \n",
        "#### Pushing notebooks back to git\n",
        "git add .\n",
        "git commit -m \"Comments go here\"\n",
        "git push       \n",
        "\n",
        "### Jupyter Notebook Hotkeys & Mouse Tricks\n",
        "\n",
        "* Shift + Tab # inside method/function () for help\n",
        "\n",
        "* % matplotlib inline #for graphs in notebook\n",
        "\n",
        "* ctrl+/  # comment / uncomment selection\n",
        "* shift + enter  #run cell, select below.\n",
        "* ctrl + enter # run cell.\n",
        "* alt + enter #run cell, insert below.\n",
        "  \n",
        "* A # insert cell above.\n",
        "* B # insert cell below.\n",
        "\n",
        "* C # copy cell.\n",
        "* V # paste cell.\n",
        "\n",
        "* X # delete selected cell.\n",
        "* Y # change cell to code\n",
        "* M # change cell to markdown\n",
        "\n",
        "* Ctrl +Click # create multiple cursors at once (edit simultaneously)\n",
        "\n",
        "#### [!] if Jupyter Notebook doesn't have the Learn-env kernel as an option:\n",
        "```python\n",
        "         *python -m ipykernel install --user --name=learn-env*\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Z7xlg-kzw3H-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BASIC PYTHON FUNCTIONS/METHODS/INDEXING\n",
        "```python\n",
        "\tlen(), type()\n",
        "    var+=1 # can add / sub \n",
        "\tset(list) # returns unique values\n",
        "\tlist(range(0,len(variable))) # create numerical index for variable length\n",
        "\tround(result,num_decimals) # Display only 2 decimal places\n",
        "```\n",
        "### List Indexing:\n",
        "```python\n",
        "\t\tlist=['str','str']\n",
        "\t\tdata[0:5] # select data elements 1-4\n",
        "\t\tdata[5:] # select 5 to the end\n",
        "\t\tdata[0:end:2] #Select every other ek\n",
        "\t\tdata[-1] #last element\n",
        "```\n",
        "### List Methods \n",
        "```python\n",
        "    list.append()\n",
        "    list.pop()\n",
        "    list.extend() #joins 2 list\n",
        "    list.insert()\n",
        "    list.remove()\n",
        "    list.count()\n",
        "    \n",
        "    list.reverse()\n",
        "    list.sort() # doesn't return a value \n",
        "    s=sorted(list,key_func,reverse=True)\n",
        "    \n",
        "    filtered_list = filter(func_that_filters, orignal_long_list )\n",
        "```\n",
        "\n",
        "### String methods\n",
        "```python\n",
        "\n",
        "    str.upper()\n",
        "\tstr.lower()\n",
        "\tstr.capitalize() \n",
        "\tstr.title() \n",
        "\n",
        "\tstr.strip()\n",
        "\tstr.endswith(txt)\n",
        "\tstr.startswith(txt)\n",
        "\tstr.split('_')\n",
        "\tstr=f'This string references my {variable} named variable.'\n",
        "    \n",
        "     # Print vars inside of strings with f-string formatting\n",
        "    print(f'My str will have {variable_names} inserted into it.')\n",
        "```\n",
        "\n",
        "### Dictionary Indexing:\n",
        "```python\n",
        "    new_dict=dict()\n",
        "    ex_dict  = {'key1' : value1 , 'key2' : value2}\n",
        "    \n",
        "\tex_dict['key1'] [element_index]# returns element from value1\n",
        "    \n",
        "    key_to_add='Name'\n",
        "    ex_dict[key_to_add]= 2 \n",
        "    \n",
        "    ex_dict.keys() # returns all keys\n",
        "\tex_dict.values() # returns all values\n",
        "\tex_dict.items() # returns all items\n",
        "\n",
        "\tex_dict.get(var, value_if_DNE) #DNE=does not exist \n",
        "    \n",
        "```\n",
        "#### Ex: Updating a dictionary value (if it exists) by  looping through an iterable\n",
        "```python\n",
        "\t\twords=txt.split() # A long list of strings\n",
        "\t\tword_counts={} # Empty dictionary\n",
        "    \n",
        "        #Loop through words list \n",
        "\t\tfor word in words:\n",
        "\t\t\tword_counts[word] = word_counts.get(word, 0_ ) #dict.get(key, default_value)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "sJbyRo5uw3H_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Flow control (conditionals and loops)\n",
        "#### If, elif, else\n",
        "```python\n",
        "if <condition>:\n",
        "\t\tcode_to_run\n",
        "\telif other_condition:\n",
        "\t\tother_code_to_run\n",
        "\telse:\n",
        "\t\totherwise_run_code\n",
        "# Ends via indentation\n",
        "```    \n",
        "#### Conditional statement to chceck of variable exists inside of the list/iterable var \n",
        "\n",
        "##### try, except \n",
        "```python\n",
        "try:\n",
        "    df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "```\n",
        "#### For loops \n",
        "```python\n",
        "\tfor element in iterable:\n",
        "\t\t'run this code'\n",
        "\n",
        "\t*for key, value in exampl_dictionary.items()*\n",
        "\t\t'run this code'\n",
        "```\n",
        "#### While loops"
      ]
    },
    {
      "metadata": {
        "id": "YE2RYQUfw3IA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Defining functions\n",
        "```python\n",
        "\tdef function_name(parameters_in=default_value:  #can do (), but variables must already exist\n",
        "\t\tstr='run this code'\n",
        "\t\treturn value_to_send_back\n",
        "```\n",
        "\n",
        "### Lambda functions\n",
        "```python\n",
        "    df['column'] = df.column_to_operate_on.map(lambda x:  'N' in x)\n",
        "```\n",
        "### List Comprehensions\n",
        "..."
      ]
    },
    {
      "metadata": {
        "id": "51gIHKdIw3IB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GRAPHING WITH MATPLOTLIB\n",
        "```python\n",
        "    import matplotlib.pyplot as plt\n",
        "\t%matplotlib inline # onlu jupyter notebooks\n",
        "    \n",
        "\tplt.figure(figsize=(x,y))\n",
        "\n",
        "\tdata_to_graph.plot(kind='barh') # default is line\n",
        "```    \n",
        "   Can call plotting *functions:*  \n",
        "```python\n",
        "    plt.scatter(x,y)\n",
        "    plt.hist(x,bins=num)\n",
        "\n",
        "\tplt.title('Top 5 Lego Themes', fontsize=16) #fontsize is optional\n",
        "\tplt.xlabel('Number of Lego Sets') #you could also pass in fontsize if you wanted here\n",
        "\tplt.ylabel('Theme') #you could also rotate text if you wanted\n",
        "\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "```\n",
        "\n",
        "#### Matplotlib from lesson - two subplots:\n",
        "```python\n",
        "\t# Define a new figure with matplotlib's .plot() function. Set the size of figure space\n",
        "\tnew_figure = plt.figure(figsize=(10,4))\n",
        "\t# Add a subplot to the figure - a new axes\n",
        "\tax = new_figure.add_subplot(121)\n",
        "\t# Add a second subplot to the figure - a new axes\n",
        "\tax2 = new_figure.add_subplot(122)\n",
        "\t# Generate a line plot on first axes\n",
        "\tax.plot([1, 4, 6, 8], [10, 15, 27, 32], color='lightblue', linewidth=3, linestyle = '-.')\n",
        "\t# Draw a scatter plot on 2nd axes\n",
        "\tax2.scatter([0.5, 2.2, 4.2, 6.5], [21, 19, 9, 26], color='red', marker='o')\n",
        "\t# Set the limits of x and y for first axes\n",
        "\tax.set_xlim(0, 9), ax.set_ylim(5,35)\n",
        "\t# Set the limits of x and y for 2nd axes\n",
        "\tax2.set_xlim(0, 9), ax2.set_ylim(5,35)\n",
        "\t# Show the plot\n",
        "\tplt.show()\n",
        "\n",
        "```\n",
        "#### Matplotlib from lesson - inset subplot\n",
        "```python\n",
        "\t# Generate sample data \n",
        "\tx = np.linspace(0, 5, 11)\n",
        "\ty = x ** 3\n",
        "\n",
        "\t# Creates blank canvas\n",
        "\tfigure = plt.figure()\n",
        "\n",
        "\t# Add new axes to the figure with absolute positions\n",
        "\tax1 = figure.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "\tax2 = figure.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes\n",
        "\n",
        "\t# Larger Figure Axes 1\n",
        "\tax1.plot(x, y, color = 'blue', linestyle = '-.')\n",
        "\tax1.set_xlabel('X_label on axes1')\n",
        "\tax1.set_ylabel('Y_label on axes1')\n",
        "\tax1.set_title('Axes 1 Title')\n",
        "\n",
        "\t# Insert Figure Axes 2\n",
        "\tax2.plot(y, x, color = 'green', linestyle = '--')\n",
        "\tax2.set_xlabel('X_label on axes2')\n",
        "\tax2.set_ylabel('Y_label on axes2')\n",
        "\tax2.set_title('Axes 2 Title')\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Vgd2G7rjw3IB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Stem & leaf plots\n",
        "\n",
        "The last major digit is convertd to category on x-axis, the ones-digits are then\n",
        "plotted as Y-values (cannot see multiple instances of same value)\n",
        "\n",
        "![](media/2a56e9788cee9b0d83f8b81a87a8ccb7.emf)\n",
        "```python\n",
        "Import matplotlib.pyplot as plt  \n",
        "%matplotlib inline  \n",
        "plt.style.use(‘ggplot’)  \n",
        "\\# Create a stem and leaf plot including the above styling\n",
        "plt.figure(figsize=(12,8))\n",
        "\\# markerline, stemlines, baseline =\n",
        "plt.stem(stems, leafs, '-.', 'o' )\n",
        "plt.title('Stem and Leaf Plot for Student Marks', fontsize = 30 )\n",
        "plt.ylabel('Leafs', fontsize = 20)\n",
        "plt.xlabel('Stems', fontsize = 20)\n",
        "plt.show()\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "XygYZ8uHw3ID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### My Histograms from PDF lab\n",
        "\n",
        "```python\n",
        "fig2=plt.figure()\n",
        "male_df['Height'].plot(kind='hist',color='blue',edgecolor='pink',label='Male',density=True,alpha=0.7)\n",
        "\n",
        "female_df['Height'].plot(kind='hist',color='pink',edgecolor='blue',label='Female',density=True,alpha=0.7)\n",
        "\n",
        "plt.xlabel('Height (inches)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "\\# You code here\n",
        "x_male,y_male=density(male_df['Height'])\n",
        "plt.plot(x_male,y_male,':',color='cyan',linewidth=3)\n",
        "x_female,y_female=density(female_df['Height'])\n",
        "plt.plot(x_female,y_female,'--',color='magenta',linewidth=3)\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "cn1OSOHfw3IF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PANDAS AND DATAFRAMES\n",
        "```python\n",
        "\timport pandas as pd\n",
        "\tdataframe= pd.read_csv('filename.csv',header=1, encoding='latin-1',usecols=[1,2,3])\n",
        "\tdf=pd.read_excel('filename.xlsx',sheet_name='sheet name')\n",
        "\t\n",
        "\tworkbook = pd.ExcelFile('filename.xlsx')\n",
        "\tworkbook.sheet_names\n",
        "\tdf = workbook.parse(sheet_name=1)\n",
        "\n",
        "\tdf.to_csv('file.csv',index=False) #create csv file\n",
        "\tdf.to_excel() #excel \n",
        "\tdf.to_dict()\n",
        "```\n",
        "\n",
        "\n",
        "### Pandas methods and functions\n",
        "```python\n",
        "\tdf.head() # display first few rows ; can do df.column.head()\n",
        "\tdf.tail()\n",
        "\tdf.info() #\n",
        "\tdf.shape() # rows and columns-\n",
        "\tdf.describe() # quick statistics for all of dataframe\n",
        "\tdf.dtypes()\n",
        "\tdf.index()\n",
        "\tdf.columns()\n",
        "\tdf.drop() \n",
        "\tdf.set_index('column')\n",
        "\tdf.reset_index()\n",
        "```\n",
        "#### Dataframe Indexing  \n",
        "```python\n",
        "# For series/column\n",
        "    df['col_ name'] # OR:\n",
        "    df.col_Name\n",
        "# For rows ..?\n",
        "    # []TBD!\n",
        "# Index data by position .iloc[ ]\n",
        "\tdf.iloc[row_idx_start : row_idx_exclusive, col_idx_start: col_idx_end] # slice row row_idx\n",
        "# Index data using .loc[]: \n",
        "    # Index based upon their labels (row index and column name)\n",
        "        df.loc[row1:rowEnd,'column_name' ]     \n",
        "    # Index based upon conditional (boolean) statements\n",
        "        df.loc[df['col_to_test'] < condition1 ]\n",
        "        singe_col_filtered = df.loc[df['col_to_test'] < condition1, ['column_name']]\n",
        "    # Index based upon two conditionals\n",
        "        df.loc[(df[\"col_to_test1\"] == condition1) & (df[\"col_to_test2\"]== condition2)]\n",
        "    # Changing values via .loc indexing\n",
        "        df.loc[df[\"color_intensity\"]>10, \"color_intensity\"] = 10\n",
        "    # Changing values if contain string\n",
        "        df.loc[df[\"Home Team Name\"].str.contains('Korea'), \"Home Team Name\" ]        \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "o-k1Ccyxw3IG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Useful pandas series methods:\n",
        "```python\n",
        "    df.col_name.value_counts() #[0:5]\n",
        "    df.col_name.astype()\n",
        "    series.mean() #Changing notation here: series refers to df.col_name (which is a series)!\n",
        "    series.median()\n",
        "    series.min()\n",
        "    series.max()\n",
        "    series.std()\n",
        "    series.unique()\n",
        "    series.nunique()\n",
        "    series.sample()\n",
        "    series.sort_values()\n",
        "    series.hist()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "zC6EHN0Tw3II",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Examples: using pandas \n",
        "##### Ex from lesson: conditional indexing\n",
        "```python\n",
        "    # Index based upon an  3 variables, var1/cond1 & (var2/cond2 | var3/cond3)} # / just means var+ condition \n",
        "\tUSA_home_and_away = df[(df.Year==2014)  & ((df['Home Team Name'] == 'USA') | (df['Away Team Name']=='USA'))\n",
        "```\n",
        "##### Ex from lesson: operating on dataframes (change names, cols)\n",
        "```python                           \n",
        "    # Drop a column of the df\n",
        "    df = df.drop('C/A', axis=1) #drop the COLUMN(axis=1) 'C/A'\n",
        "\n",
        "    # Rename columns\n",
        "    df = df.rename(columns={'DATE' : 'date'})\n",
        "\t\t\n",
        "    # Operate on columns names\n",
        "    new_cols = [col.lower() for col in df.columns]                       \n",
        "    df.columns = [my_function(col) for col in df.columns] \n",
        "```\n",
        "##### Ex from lessons: using datetime type \n",
        "```python\n",
        "    df.DATE = pd.to_datetime(df.DATE, format='%m/%d/%Y') # convert dates to datetime type\n",
        "    df.DATE.dt.day_name() #dt.day_name\n",
        "    df['Dayofweek'] = df.DATE.dt.dayofweek \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "jhAy_v9uw3IJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Groupby \n",
        "```python \n",
        "grouped = df.groupby('Dayofweek').sum()\n",
        "grouped.plot(kind='barh')\n",
        " # HMmm weird\n",
        "df['Num_Lines'] = df.LINENAME.map(lambda x: len(x))\n",
        "```\n",
        "#### Dataframe statistics methods\n",
        " (.mean(), .std(), .count(), .sum(), .mean(), .median(), .std(), .var() and .quantile())"
      ]
    },
    {
      "metadata": {
        "id": "y5Gy431nw3IK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Map/apply to operate on data frames\n",
        "```python\n",
        "df[‘column’].map(lambda x: len(x.split()).head()\n",
        "#LAMBDA + MAP FUNCTIONS WITH CONDITIONALS\n",
        "df['text'].map(\n",
        "    lambda x: 'Good' if any([word in x.lower() for word in ['awesome', 'love', 'great']]) else 'Bad').head()\n",
        " ```\n",
        " #### Using .applymap()\n",
        "```python\n",
        "string_df=df.applymap(lambda x: str(x))\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "pftDkY-Dw3IL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## HOW TO: cleaning a dataset and checking for missing values\n",
        "```python\n",
        "\tprint('   HEROES_DF INFORMATION:\\n')\n",
        "\tprint(heroes_df.info())\n",
        "\tprint('\\n')\n",
        "\t# print('heroes_df value counts (check for redundancy):')\n",
        "\t# print(heroes_df['name'].value_counts()[0:10])\n",
        "\t# print('\\n\\n')\n",
        "\n",
        "\tprint(f'NaN values in data? \\n {heroes_df.isna().any().any()}\\n')\n",
        "\n",
        "\t# print('heroes_df names - Number of Redundant:'.upper())\n",
        "\t# print(f'Num unique names: {len(heroes_df.name.unique())}')\n",
        "\t# print(f'Num of repeated names: {len(heroes_df.name)-len(heroes_df.name.unique())}')\n",
        "\t# print('\\n')\n",
        "\n",
        "\tprint('heroes_df -  Missing Publisher values:'.upper())\n",
        "\t#print(f'Num unique: {len(heroes_df.Publisher.unique())}')\n",
        "\tprint(f'Num missing: {heroes_df.Publisher.isna().sum()} out of {len(heroes_df.Publisher)}, ({round((heroes_df.Publisher.isna().sum() /len(heroes_df.Publisher) * 100),2) }%)')\n",
        "\t# print(f'{heroes_df.Publisher.isna().sum()/len(heroes_df.Publisher)*100}%')\n",
        "\tprint('\\n')\n",
        "\n",
        "\tprint('heroes_df - Missing Weight values:'.upper())\n",
        "\t# print(f'Num missing: {heroes_df.Weight.isna().sum()}')\n",
        "\tprint(f'Num missing: {heroes_df.Weight.isna().sum()} out of {len(heroes_df.Weight)}, ({round((heroes_df.Weight.isna().sum() /len(heroes_df.Weight) * 100),2) }%)')\n",
        "\tprint('\\n')\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "b5TGEzlDw3IM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SQL (sect 05)\n",
        "\n",
        "### Using sqlite3 with SQL databases\n",
        "```python\n",
        "import sqlite3\n",
        "connection = sqlite3.connect('pet_database.db') # Creates pet_database, but empty until create a table    \n",
        "cursor = connection.cursor()\n",
        "\n",
        "# use the corsor to execute sql commands\n",
        "cursor.execute(''' \n",
        "CREATE TABLE cats (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    age INTEGER,\n",
        "    breed TEXT\n",
        ")\n",
        "''')\n",
        "\n",
        "# Insert into table\n",
        "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES ('Maru', 3, 'Scottish Fold');''')\n",
        "# Select from table\n",
        "cursor.execute('''SELECT name FROM cats;''').fetchall()\n",
        "\n",
        "# Select only distinct entries\n",
        "cursor.execute('''SELECT DISTINCT name FROM cats;''').fetchall()\n",
        "# Selecting by conditionals using WHERE\n",
        "cursor.execute('''SELECT * FROM [table name] WHERE [column name] = [some value];''').fetchall()\n",
        "\n",
        "# Altering a table \n",
        "cursor.execute('''ALTER TABLE cats ADD COLUMN notes text;''')\n",
        "# Updating data\n",
        "cursor.execute('''UPDATE [table name] SET [column name] = [new value] WHERE [column name] = [value];''')\n",
        "# Deleting data\n",
        "cursor.execute('''DELETE FROM [table name] WHERE [column name] = [value];''')\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "p-ehdf4Tw3IN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Some Notes on Displaying Query Outputs\n",
        "```python \n",
        "    import pandas as pd\n",
        "    #Demonstrating running a query and previewing results as pandas DataFrame\n",
        "    results = cursor.execute(\"\"\"select * from planets;\"\"\").fetchall()  \n",
        "    df = pd.DataFrame(results)\n",
        "    df. columns = [i[0] for i in cursor.description]\n",
        "    df.head()\n",
        "\n",
        "    # CAN MAKE A FUNCTION TO SIMPLIFY\n",
        "    def sql_select_to_df(SQL_COMMAND, cur=cursor):\n",
        "        results = cur.execute(SQL_COMMAND).fetchall()\n",
        "        df = pd.DataFrame(results)\n",
        "        df.columns = [i[0] for i in cur.description]\n",
        "        return df\n",
        "    \n",
        "    # Call function to select data\n",
        "    df = sql_select_to_df(\"\"\"select * from planets;\"\"\")\n",
        "    df.head()\n",
        "    \n",
        "    # Select with function + conditional\n",
        "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE mass > 1;\"\"\")\n",
        "    df.head()\n",
        "    \n",
        "    # Select with AND \n",
        "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE (num_of_moons>1 AND mass < 1);\"\"\")\n",
        "    df.head()```"
      ]
    },
    {
      "metadata": {
        "id": "_UOFVo8tw3IO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Filtering and Ordering\n",
        "```python\n",
        "# ORDER BY\n",
        "cursor.execute('''SELECT column_name FROM table_name ORDER BY column_name ASC|DESC;''').fetchall()\n",
        "# LIMIT\n",
        "cursor.execute('''SELECT * FROM cats ORDER BY age DESC LIMIT 3;''').fetchall() #Fetch top 3\n",
        "cursor.execute('''SELECT * FROM cats ORDER BY age DESC;''').fetchone() #returns the first \n",
        "# BETWEEN\n",
        "cursor.execute('''SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2;''').fetchall()\n",
        "# NULL - placeholder\n",
        "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES (NULL, NULL, \"Tabby\");''')\n",
        "#SELECT BY NULL\n",
        "SELECT * FROM cats WHERE name IS NULL;\n",
        "# COUNT\n",
        "SELECT COUNT([column name]) FROM [table name] WHERE [column name] = [value];\n",
        "# GROUPBY\n",
        "SELECT breed, COUNT(breed) FROM cats GROUP BY breed;\n",
        "SELECT breed, owner_id, COUNT(breed) FROM cats GROUP BY breed, owner_id;\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "mrf7MwCxw3IP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Object-Oriented Programming (Sect 06-07)\n",
        "\n",
        "\n",
        "### Defining classes \n",
        "\n",
        "```python\n",
        "# Must define class NameConventionCase\n",
        "class MyNewClass: \n",
        "    pass # If no attributes, must pass\n",
        "# Instantiate an MyNewClass object\n",
        "new_instance = MyNewClass() \n",
        "\n",
        "```\n",
        "### Class Attributes & Methods \n",
        "* Instance methods are like attributes, but are *callable.*\n",
        "* When calling a object **.method()**, the object *implicitly* called\n",
        "    * Must use `self` to tell methods to expect input variable \n",
        "\n",
        "```python \n",
        "# Defining an instance method:\n",
        "class Dog():\n",
        "    def bark(self):\n",
        "        return \"Ruh-roh!\"\n",
        "    def needs_a_walk(self):\n",
        "        self.gotta_go = False \n",
        "        return 'Phew that was close!'\n",
        "    def whose_a_good_dog(self, name):\n",
        "        return f'Whos a good dog???\"\\n {name.title()} is!'  \n",
        "\n",
        "# Calling an instance method\n",
        "new_rex = Dog()\n",
        "new_rex.bark() # Ruh-roh!\n",
        "new_rex.whose_a_good_dog('Fido')\n",
        "\n",
        "```\n",
        "\n",
        "###  Instance Variables & Setters and Getters\n",
        "\n",
        "```python \n",
        "# _instance_ variables are protected from unwanted external edits\n",
        "# They have class.methods() defined to set and get the values.\n",
        "class BankAccount():\n",
        "    \n",
        "    def set_balance(self, amount):\n",
        "        self._balance += amount    \n",
        "    def get_balance(self):\n",
        "        return self._balance\n",
        "        \n",
        "    def make_withdrawal(self, amount_requested):\n",
        "        if (self.check_min_bal(amount_requested)):\n",
        "            return self.check_min_bal(amount_requested)\n",
        "        else: \n",
        "            self.set_balance(-amount_requested)\n",
        "            return print(f'$ {amount_requested}')\n",
        "\n",
        "        # ---- Note: some code cut -----\n",
        "[BOOKMARK TO RETURN TO LATER]                \n",
        "## Using Properties with Setters & Getters\n",
        "\n",
        "# ----------- HERE is where we are using the property() function ----------------------------------- #\n",
        "    balance = property(get_balance, set_balance)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "jgdIJYDvw3IQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python        \n",
        "# Initializing Instance Objects Using _init_ \n",
        "class Business():\n",
        "    def __init__(name=None, biz_type=None, city=None, customers = {}):\n",
        "        business.name = name\n",
        "        business.biz_type = biz_type\n",
        "        business.city = city\n",
        "        business.customers = customers\n",
        "\n",
        "    # Normal function to instantiate a BankAccount\n",
        "    def make_account():\n",
        "        new_account = BankAccount()\n",
        "        new_account._balance = 0\n",
        "        new_account._minimum_balance = 250\n",
        "        new_account._max_withdrawal = 150 \n",
        "        return new_account\n",
        "```\n",
        "```python\n",
        "class Customer():\n",
        "    def __init__(self, name=None, orders=[], location=None):\n",
        "        self.name=name\n",
        "        self.orders = orders\n",
        "        self.location = location\n",
        "    def add_order(item_name, item_cost, quantity):\n",
        "        self.orders.append({'item_name': item_name, 'item_cost':item_cost, 'quantity':quantity})\n",
        "```\n",
        "\n",
        "```python\n",
        "\n",
        "# Simple / lazy way\n",
        "class Person:\n",
        "    def set_name(self, name):\n",
        "        self.name = name\n",
        "    def set_job(self, job):\n",
        "        self.job = job\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "5kFGfU5Ww3IR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using NumPy & Arrays (section 08)\n"
      ]
    },
    {
      "metadata": {
        "id": "tjWBMjYPw3IR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy & element-wise math operations"
      ]
    },
    {
      "metadata": {
        "id": "IkxjA1Gkw3IS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Intitialize a np array\n",
        "import numpy as np\n",
        "x=np.array([1,10,20,30]) \n",
        "print(x)\n",
        "\n",
        "#np  Array Math Operations\n",
        "print('x*3 =', x * 3 ) # Array .* (element-wise function)\n",
        "print('[1,2,3] * 3=' ,[1,2,3] * 3)\n",
        "print('x + 2=',x + 2) #Adds two to each element\n",
        "# But can't do element-wise addition\n",
        "[1,2,3] + 2 # Returns an error; different data types\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "jHB8gF-Qw3IT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scalar Math\n",
        "Here arr = np array\n",
        "```python\n",
        "np.add(arr,1) # Add 1 to each array element\n",
        "np.subtract(arr,2) # Subtract 2 from each array element\n",
        "np.multiply(arr,3) # Multiply each array element by 3\n",
        "np.divide(arr,4) # Divide each array element by 4 (returns np.nan for division by zero)\n",
        "np.power(arr,5) # Raise each array element to the 5th power  \n",
        "```\n",
        "### Vector Math\n",
        "Here arr1, arr2 are both np arrays\n",
        "```python\n",
        "np.array_equal(arr1,arr2) # Returns True if the arrays have the same elements and shape\n",
        "\n",
        "np.add(arr1,arr2) # Elementwise add arr2 to arr1\n",
        "np.subtract(arr1,arr2) # Elementwise subtract arr2 from arr1\n",
        "np.multiply(arr1,arr2) # Elementwise multiply arr1 by arr2\n",
        "np.divide(arr1,arr2) # Elementwise divide arr1 by arr2\n",
        "\n",
        "np.power(arr1,arr2) # Elementwise raise arr1 raised to the power of arr2\n",
        "np.sqrt(arr) # Square root of each element in the array\n",
        "np.log(arr) # Natural log of each element in the array\n",
        "\n",
        "np.abs(arr) # Absolute value of each element in the array\n",
        "np.ceil(arr) # Rounds up to the nearest int\n",
        "np.floor(arr) # Rounds down to the nearest int\n",
        "np.round(arr) # Rounds to the nearest int\n",
        "\n",
        "np.sin(arr) # Sine of each element in the array\n",
        "```\n",
        "### Appending / adding elements\n",
        "```python\n",
        "[1,2,3] + [4,5,6] #Adding raw lists is just appending\n",
        "np.array([1,2,3]) + np.array([4,5,6]) #Adds elements\n",
        "\n",
        "#Same as above with built in method\n",
        "x = np.array([1,2,3])\n",
        "y = np.array([4,5,6])\n",
        "np.add(x,y)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ikNZptfLw3IU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi-dimensional Arrays with Numpy\n"
      ]
    },
    {
      "metadata": {
        "id": "WLXk0U0xw3IU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* numpy displays arrays in more user friendly way ( rows above rows)\n",
        "    * <img style=float src=\"attachment:ScreenClip.png\" align=\"left\"/>\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "yRJPqLjVw3IV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* np.shape returns length of each dimensions (row, col, __) \n",
        "\n",
        "```python\n",
        "    y = np.array([[1,2,3],[4,5,6]])\n",
        "    print(y.shape) # (2,3)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "z_ubqwvbw3IW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Functions for Creating Arrays\n",
        "```python\n",
        "# np.zeroes(shape) and np.ones(shape)\n",
        "    np.zeros(5) # #one dimensional; 5 elements, all 0\n",
        "    np.zeros([2,2]) #two dimensional; 2x2 matrix\n",
        "    np.zeros([3,4,5]) #3 dimensional; 3 4x5 matrices\n",
        "    \n",
        "    np.ones(shape) # Returns 1's\n",
        "\n",
        "# np.full(shape,fill) \n",
        "    np.full(shape, fill) # fill array with arbitrary values\n",
        "    np.full(5, 3) #Create a 1d array with 5 elements, all of which are 3\n",
        "    np.full(5, range(5)) #Create  array with 5 elements (0-4) (ONLY WORKS WITH 1-2 DIMENSIONS)\n",
        "    \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "tRJOMZpjw3IW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NP Array Indexing / Subsetting\n",
        "```python\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
        "print(x.shape) #(4,3)\n",
        "#Result displays as:\n",
        "np.array([[1,2,3], \n",
        "          [4,5,6], \n",
        "          [7,8,9], \n",
        "          [10,11,12]])\n",
        "\n",
        "# Slice rows with 1 index:\n",
        "x[0] # array([1,2,3])\n",
        "\n",
        "#Slice rows, columns  \n",
        "# x[slice_dim1, slice_dim2]\n",
        "x[:,0] #All rows, column 0\n",
        "\n",
        "# If array has more than 2 dimensions:   \n",
        "print(\"NOTE: [!] If have multi-dim array (3+ dim), can't use row,col indexing!!\")\n",
        "\n",
        "#To slice along a second dimension with lists - list comprehension\n",
        "[i[0] for i in x] #returns first element from each row \n",
        "\n",
        "#Doing this in multiple dimensions with lists\n",
        "[i[1:3] for i in x[2:4]] #returns rows (second-third), columns (third:fourth) [[8,9],[11,12]]\n",
        "```\n",
        "\n",
        "#### Slicing 3D arrays\n",
        "```python \n",
        "#With an array\n",
        "x = np.array([\n",
        "              [[1,2,3], [4,5,6]],\n",
        "              [[7,8,9], [10,11,12]]\n",
        "             ])\n",
        "x\n",
        "    #returns: \n",
        "    array([[[ 1,  2,  3],\n",
        "            [ 4,  5,  6]],\n",
        "\n",
        "           [[ 7,  8,  9],\n",
        "            [10, 11, 12]]])\n",
        "\n",
        "# Array is 3-D\n",
        "x.shape #(2,2,3)\n",
        "# 3-D indexing\n",
        "x[:,:,-1]\n",
        "#returns last element of ebery row, col:\n",
        "array([[ 3,  6],\n",
        "   [ 9, 12]])\n",
        "```\n",
        "\n",
        "### Get unique vanlues and counts from a np array\n",
        "values, counts = np.unique(np_it, return_counts=True)"
      ]
    },
    {
      "metadata": {
        "id": "rPAYDUHkw3IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## STATISTICS AND PROBABILITY (Section 08)\n",
        "\n",
        "### Set definions\n",
        "#### set :  \n",
        "- a *well-defined colletion of objects*.\n",
        "- _Math notation:_\n",
        "    - define a set by $S$. \n",
        "    - If an element $x$ belongs to a set $S$:\n",
        "        - $x \\in S$.\n",
        "    - If $x$ does not belong to a set $S$:\n",
        "        - $x\\notin S$.\n",
        "        \n",
        "#### subset: \n",
        "- set $T$ is a subset of set $S$ if *every element* in set $T$ is also in set $S$. \n",
        "    - Notation for a subset is $T \\subset S$.   \n",
        "        - $T$ and $S$ can be the SAME\n",
        "    - If $T$ != $S$, but $T \\subset S$, called a '_proper subset_'\n",
        "        - Can use notation:  $T \\subsetneq S$ and $T \\subseteq S$ \n",
        "\n",
        "#### Universal set:\n",
        "- The collection of all possible outcomes in a certain context or universe.\n",
        "    -  often denoted by $\\Omega$.\n",
        "    - Example: all possible outcomes of a 6-sided die:\n",
        "        - $\\Omega = \\{1,2,3,4,5,6\\}$\n",
        "    - Can have infinite # of elements (e.g. the set of all real numbers!)\n",
        "\n",
        "### Set operations:\n",
        "- Data used in examples:\n",
        "\n",
        "Imagine you have two sets of numbers, say the first 4 multiples of 3 in set $S$:\n",
        "\n",
        "$ S = \\{3,6,9,12\\}$\n",
        "\n",
        " and the first 4 multiples of 2 in set $T$:\n",
        " \n",
        "$ T = \\{2,4,6,8\\} $.\n",
        "\n",
        "#### Union (combining elements)\n",
        "- the union of $S$ and $T$ is denoted as $S \\cup T$\n",
        "\n",
        "#### Intersection\n",
        "- contains all elements of $S$ that also belong to $T$. \n",
        "    - denoted as $S \\cap T$.\n",
        "    \n",
        "#### Relative complement / difference\n",
        "-  the relative complement of S contains all the elements of T that are NOT in S.\n",
        "    - relative complement of S (or $ T\\backslash S $) is $\\{2,4,8\\}$.\n",
        "    - relative complement  of T (or $ S\\backslash T $) is $\\{3,9,12\\}$.\n",
        "\n",
        "#### Absolute complement\n",
        "- The absolute complement of $S$, with respect to the Universal set $\\Omega$, is the collection of the objects in $\\Omega$ that don't belong to $S$.\n",
        "    -  absolute complement of $S$ is denoted as $S'$ or $S^c$.\n",
        "\n",
        "- Example: Let's define $\\Omega$ (box around the two venn diagrams) = multiples of both 2 and 3 until 20.\n",
        "\n",
        "    - Elements of $\\Omega$ are $\\{2,3,4,6,8,9,10,12,14,15,16,18,20\\}$. \n",
        "\n",
        "    - The absolute complement of $S$ (so $S'$ or $S^c$) is then given by $\\{2,4,8,10,14,15,16,18,20\\}$.\n",
        "    \n",
        "#### Inclusion Exclusion principle\n",
        "- When combining  2 sets, the method for obtaining the union of two finite sets is given by:\n",
        "\n",
        "    - $\\mid S \\cup T \\mid = \\mid S \\mid + \\mid T \\mid - \\mid S \\cap T \\mid $\n",
        "    \n",
        "        - Horizontal lines denote the *cardinality* of a set, which is the number of elements, considering a finite set. \n",
        "        \n",
        "        \n",
        "- *The formula expresses the fact that the sum of the sizes of the two sets may be too large since some elements may be counted twice. For the double-counted elements, one is substracted again.*\n",
        "\n",
        "### Empty \n",
        " - An **empty** set has no elements\n",
        " - denoted by $\\emptyset$ or simply $\\{\\}$\n"
      ]
    },
    {
      "metadata": {
        "id": "ydclwM1Yw3IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Into to probability \n",
        "#### Sample Space & Event Space\n",
        "##### Sample space:\n",
        "$$S = \\{ 1,2,3,4,5,6\\}$$ \n",
        "being the possible outcomes when throwing a dice.\n",
        "\n",
        "##### Event space:\n",
        "-   The **event space** is a subset of the sample space, $$E \\subseteq S$$\n",
        "-   Example:\n",
        "    -   Throwing an odd number would lead to an event space $$E = \\{ 1,3,5\\}$$.\n",
        "\n",
        "### Law of relative frequency\n",
        "- Limit of large infinite outcomes produce fixed numbers .\n",
        "$$P(E) = \\lim_{n\\to\\infty}\\frac{S(n)}{n}$$\n",
        "    - Probability of Event E having Successful(S) outcomes for $n$ trials\n",
        "    \n",
        "#### Probability axioms\n",
        "\n",
        "1.  Positivity : Prob is always 0 \\<= P(E) \\<=1\n",
        "\n",
        "2.  Probability of a certain event: P(S)=1\n",
        "\n",
        "3.  Additivity Union of 2 exclusive sets = sum prob of individual events\n",
        "    happening <br>\n",
        "If $A\\cap B = \\emptyset $, then $P(A\\cup B) = P(A) + P(B)$\n",
        "\n",
        "### Addition law of probability \n",
        "\n",
        "-   Prob of union of A and B is individual P minus intersection\n",
        "$$P(A\\cup B) = P(A) + P(B) - P(A \\cap B)$$\n"
      ]
    },
    {
      "metadata": {
        "id": "2yqWh1lBw3IY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### HOW TO: test probability of an event: \n",
        "\n",
        "1.  What is the prob of E happening at least once?\n",
        "\n",
        "    1.  Get Boolean result for E:  \n",
        "        Set_E =sample_population == E\n",
        "\n",
        "    2.  Verify condition:  \n",
        "        true_E=np.any(set_E, axis = 1)\n",
        "\n",
        "    3.  Prob_E=np.sum(true_E)/len(sample_population)"
      ]
    },
    {
      "metadata": {
        "id": "-eVvlckzw3IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Permutations and Factorials:\n",
        "----------------------------\n",
        "\n",
        "### Permutations of a subset\n",
        "\n",
        "How many ways can we select k elements out of a pool of n objects?\n",
        "- $k$-permutation of $n$:\n",
        "\n",
        "$n*(n-1)*...*(n-k+1)$ or in other words, $P_{k}^{n}= \\dfrac{n!}{(n-k)!}$\n",
        "\n",
        "### Permutations with replacement \n",
        "\n",
        "\\# of possible options doesn’t change, so n is raised to the power of j, the number of draws from the pop<br>\n",
        "$n^j$\n",
        "\n",
        "### Permutations with repetition ...?\n",
        "\n",
        "The \\# of permutations of *n* objects with identical objects of type 1<br>\n",
        "$(n_1^{j_1}* n_2^{j_2})$\n",
        "<img src=\"https://www.dropbox.com/s/5qrwxgv541u6kj5/00ff12464dd108477fd6a5dbeac9868d.png?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "90uxhG0jw3IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Combinations\n",
        "- How many ways can we create a subset $k$ out of $n$ objects? \n",
        "    - Unordered\n",
        "$$\\displaystyle\\binom{n}{k} = \\dfrac{P_{k}^{n}}{k!}=\\dfrac{ \\dfrac{n!}{(n-k)!}}{k!} = \\dfrac{n!}{(n-k)!k!}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "t4afuY15w3Ia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Distributions: Discrete vs Continuous \n",
        "#### Discrete Distributions\n",
        "-   Bernoulli = Repeated trials of binary outcome event. ( x successes in n trials)(flipping a coin)\n",
        "-   Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "-   Poisson = The probability of n events in a given time period when overall rate of occurrence is constant (i.e. receiving mail)\n",
        "-   Uniform = all outcomes equally likely\n"
      ]
    },
    {
      "metadata": {
        "id": "LbEnK7DMw3Ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distributions (sect 19)\n",
        "- **Can be discrete or Continuous Probability Functions**\n",
        "<img src=\"https://www.dropbox.com/s/7qooiy76s3jvcr1/pmf_pdf.png?raw=1\" width=400>\n",
        "<img src=\"https://www.dropbox.com/s/ovrzewnefk2qc97/exp-var.png?raw=1\" width=400>\n",
        "\n",
        "- **Common Distributions:**\n",
        "<img src=\"https://www.dropbox.com/s/lu8iffegqjnp4kq/dists.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "id": "LBdDjOWJw3Ic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discrete Distributions\n",
        "#### Bernoulli Distribution / Binomial Distribution\n",
        "- Probability of $x$ successes in $n$ trials for Bernoulli/binomial variable (binary outcome)\n",
        "    - Described by only one parameter $p$\n",
        "- For binomial *trial*: $Y = Bernoulli(p)$ and $p=P(Y=1)=0.8$\n",
        "- For binomial *distribution*, events are independent. \n",
        "$$ P(Y=k)= \\binom{n}{k} p^k(1-p)^{(n-k)}$$ \n",
        "\n",
        "#### Geometric Distribution\n",
        "- Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "\n",
        "#### Poisson\n",
        "- Represents the probability of $n$ events in a given time period when the rate of occurrence is constant\n",
        "\n",
        "#### Uniform\n",
        "- All outcomes are equally likely. \n",
        "- BOTH continuous AND discrete\n",
        "\n",
        "### Continuous Distributions\n",
        "#### Normal / Gaussian Distribution\n",
        "- Bell shape curve very common in natural data\n",
        "- Symmetrical, mean = median = mode \n",
        "- AUC == 1\n",
        "\n",
        "###### Normal Density Function\n",
        "- Density of normal distribution for given value of x\n",
        "- Can describe from its center and spread\n",
        "$$y = \\frac{1}{\\sigma \\sqrt{2}{2\\pi}}e^{\\frac{{(x -\\mu)}{^2}}{2 \\sigma ^{2}}}$$\n",
        "- $\\mu$ = mean\n",
        "- $\\sigma$ = standard deviation\n",
        "- $\\pi \\approx 3.14159$\n",
        "- $e \\approx 2.71828$\n",
        "\n",
        "#### Standardized Normal Distribution\n",
        "$$z = \\frac{x-\\mu}{\\sigma}$$"
      ]
    },
    {
      "metadata": {
        "id": "R4xed8CZw3Ic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Probability Mass Function (PMF) / probability distribution\n",
        "- Converts frequency of events to probability of a particular outcome of a **discrete** function, by normalizing so that the sum of all outcomes == 1.\n",
        "- Can test what is the probability that $x$ takes on a particular value $k$\n",
        "    - $P(X=k)$\n",
        "\n",
        "-   Gives probability for discrete random variables, if we have x outcomes, we want to know what is the probability of getting k (our value of interest) from x\n",
        "- Maps a value from its probability \n",
        "\n",
        "#### How to convert frequency to probability  for PMF\n",
        "```python\n",
        "import numpy as np  \n",
        "import collections  \n",
        "x = [1,1,1,1,2,2,2,2,3,3,4,5,5]\n",
        "counter = collections.Counter(x)  \n",
        "\\# Convert frequency to probability - divide each frequency value by total number of values\n",
        "pmf = []\n",
        "for key,val in counter.items():\n",
        "    pmf.append(round(val/len(x), 2))\n",
        "    print(counter.keys(), pmf)  \n",
        "  \n",
        "# Proof that is normalized to overall prob of 1 (needed for PMF)  \n",
        "np.array(pmf).sum()\n",
        "# Visualizing PMF – similar to histogram, but normalized to P=1*  \n",
        "import matplotlib.pyplot as plt  \n",
        "plt.style.use(‘ggplot’)  \n",
        "plt.stem(counter.keys(), pmf)  \n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/ghbwhp17z4ulyvc/e51d10e06e9b70069c792d9fa8172e5e.png?raw=1\" width=300>\n",
        "\n",
        "### CUMULATIVE DENSITY FUNCTION\n",
        "- With large sample space $S$ (# of possible outcomes) for values of $X$, too hard to visualize with pmf\n",
        "- maps a value from its percentile rank for **discrete** functions\n",
        "- calculated as the $$F(x) = P(X \\leq x)$$\n",
        "\n",
        "### PROBABILITY DENSITY FUNCTION\n",
        "- Essentially equivalent to the pmf, but for **continuous** functions\n",
        "- Line represents regions where observations most likely to occur (the density)\n",
        "<img src=\"https://www.dropbox.com/s/y8i8azec6ncpuum/pdf1.png?raw=1\" width=300>\n",
        "\n",
        "#### Calculate area under the curve around the value of interest\n",
        "$$F(X) = P(a \\leq x \\leq b) = \\int_a^b f(x) dx \\geq 0$$\n",
        "<img src=\"https://www.dropbox.com/s/5q9gnarklq769zt/pdf2.jpg?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "cvpxcVhWw3Id",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Kernel Density Estimation \n",
        "- Non-parametric estimation to plot a curve at every individual data point (kernels)\n",
        "- Added together to plot smooth density estimation ( most common kernel is Gaussian)\n",
        "- Below example histogram and kde are from the same data\n",
        "<img src=\"https://www.dropbox.com/s/vrgcphxmry5148l/Comparison_of_1D_histogram_and_KDE.png?raw=1\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "hdzJUmM7w3Id",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Skewness\n",
        "- Symmetrical distribution: skewness = 0\n",
        "- **Fisher-Pearson Coefficient of skewess:**\n",
        "$$∑ N_{i=1} \\frac{{(Yi−\\bar{Y})}^3}{N} / {\\sigma^3}$$\n",
        "- Rules of thumb\n",
        "    - Symmetrical-ish: -0.5 to +.05\n",
        "    - Moderate Skew:\n",
        "        - Negative skew: -1 to -0.5\n",
        "        - Positive skew: +0.5 to +1\n",
        "    - Highly skewed:\n",
        "        - Less than -1\n",
        "        - Greater than +1\n",
        "    \n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/mqr3kux0caa64nk/skew1.jpeg?raw=1\">\n",
        "\n",
        "\n",
        "### Kurtosis \n",
        "- Lengths of tails of distribution to describe extreme values (outliers)\n",
        "- Univariate kurtosis:\n",
        "$$\\Sigma N_{i=1} \\frac{{(Yi−\\bar{Y})}^4}{N} / {\\sigma^4}$$\n",
        "\n",
        "- **Mesokurtic:**\n",
        "    - Kurtosis similar to standard normal distribution\n",
        "- **Leptokurtic (Kurtosis >3)**\n",
        "    - Tails are fatter, peak is higher sharper\n",
        "    - Data are heavy-tailed or many outliers\n",
        "- **Platykurtic: (Kurtosis < 3)**\n",
        "    - Shorter peak, tails are thinner than the normal distribution. \n",
        "    - Data are light-tailed or lack of outliers vs normal dist\n",
        "<img src=\"https://www.dropbox.com/s/5ynsy7vkb196ilb/kurt2.jpg?raw=1\" width=300>\n"
      ]
    },
    {
      "metadata": {
        "id": "YyPLU2fow3Ie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Statistical Distributions Recap (Sect 23)"
      ]
    },
    {
      "metadata": {
        "id": "rNLT8dc0w3If",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Uniform distribution\n",
        "- Equal probability\n",
        "- Probability function:<br>\n",
        "$$\\rho_{uniform}(x) = \\dfrac{1}{b-a} \\quad \\mbox{ for } a \\leq x < b $$\n",
        "- Mean of uniform distribution:<br>\n",
        " $\\dfrac{b+a}{2}$\n",
        "- Variance of uniform distribution:<br>\n",
        "$V = \\dfrac{(b-a)^2}{12}$\n",
        "- Standard Deviation:<br>\n",
        "$\\sigma = \\dfrac{b - a}{2 \\sqrt{3}}$.\n",
        "#### Generate uniform in python"
      ]
    },
    {
      "metadata": {
        "id": "UKz6JTHuw3Ig",
        "colab_type": "code",
        "outputId": "29201d1c-bd29-4b17-8abd-38f7c5f5e7ab",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate uniform data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "values = np.random.uniform(-10.0, 10.0, 100000)\n",
        "\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.hist(values, 50) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I8np5K5-w3Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Binomial Distribution\n",
        "- Discrete version of normal distribution describing the probability distribution of a given # of successes \n",
        "\n",
        "$$\\mu = n * p$$\n",
        "\n",
        "where $n$ is the number of trials, and $p$ is the probability of success for a given trial. \n",
        "\n",
        "- The **_Standard Deviation for a Binomial Distribution_** is:\n",
        "\n",
        "$$\\sigma = \\sqrt{n * p * (1 - p)}$$\n",
        "\n",
        "- The formula for the **_Point Probability of the Binomial Distribution_** is:\n",
        "\n",
        "$$ \\Big(\\frac{n!} {x! (n-x)!}\\Big) p^x (1 - p)^{n - x}$$\n",
        "\n",
        " where $n$ is the number of trials, $p$ is the probability of success for a given trial, and $x$ is the number of successes.\n",
        "\n",
        "- The formula for the **_Cumulative Probability of the Binomial Distribution_** is:\n",
        "\n",
        "$$\\sum_{i=0}^{x}  \\Big(\\frac{n!} {x! (n-x)!}\\Big) p^x (1 - p)^{n - x}$$\n",
        "\n",
        "where $n$ is the number of trials, $p$ is the probability of success for a given trial, and $x$ is the number of successes."
      ]
    },
    {
      "metadata": {
        "id": "rhPYaRHLw3Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normal Distributions\n",
        "- **_Probability Density of the Normal Distribution_** is:\n",
        "$$f(x\\ |\\ \\mu,\\ \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e$$\n",
        "\n",
        "- Where:\n",
        "$x$ is the **_point_** we want to calculate the probability for\n",
        "$\\mu$ is the **_mean_** of the sample\n",
        "$\\pi$ is a mathematical constant, the irrational number $3.14159$\n",
        "$\\sigma^2$ is the **_variance_** (since $\\sigma$ is the **_standard deviation_**)\n",
        "$e$ is **_Euler's Constant_**, also known as the **_Base of the Natural Logarithm_**, $2.71828$"
      ]
    },
    {
      "metadata": {
        "id": "k64fB1ERw3Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gaussian Distributions\n",
        "- For Gaussian distribution, the probability function is calculated as:\n",
        "$$\n",
        "\\rho_{Gaussian}(v) = \\dfrac{1}{\\sqrt{2 \\pi \\sigma}} e^{-\\frac{v^{2}}{2\\sigma^2}}\n",
        "$$\n",
        "- Mean of Gaussian distribution is $\\mu$,\n",
        "- Standard deviation is $\\sigma$.\n",
        "- Visualize Gaussian distributions with the probability density function ( scipy.stats.norm)"
      ]
    },
    {
      "metadata": {
        "id": "AP7L-4rRw3In",
        "colab_type": "code",
        "outputId": "2407104b-12cb-4212-8d32-7ab2efb0b014",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generating and Plotting Normal Distributions \n",
        "# Generate norm distribution\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Generating and Plotting Normal Distributions \n",
        "fig, ax = plt.subplots(1,4, figsize=(10,3))\n",
        "\n",
        "# Use scipy.stats.norm.pdf \n",
        "# to generate data for np array of x\n",
        "n=0\n",
        "ax[n].set_title(f'Continuous Norm From\\n scip.stats.norm')\n",
        "x = np.arange(-3, 3, 0.001) # Declare the range of x-values with np.arrange\n",
        "# Use scipy.stats.norm to generate continuous kerndel density estimation for those x-values\n",
        "ax[n].plot(x, norm.pdf(x), color='red')\n",
        "\n",
        "# Generate nomral distribution in numpy\n",
        "# using mean and std\n",
        "n+=2\n",
        "ax[n].set_title(f'Discrete Norm Data\\n from np.random.norm')\n",
        "values = np.random.normal(5.0, 2.0, 100000) #mean, std, size\n",
        "ax[n].hist(values, 50)\n",
        "\n",
        "# Showing the KDE for The Discrete norm distribution from numpy\n",
        "n+=1\n",
        "ax[n].set_title('Same Discrete Norm Data -> Kde')\n",
        "sns.distplot(values, ax=ax[n])\n",
        "\n",
        "# Finalize figure\n",
        "plt.delaxes(ax[1])\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dqBG210rw3Iq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exponential Distribution\n",
        "- **For exponential distribution, the probability function is:**\n",
        "$$\n",
        "\\rho_{exponential}(t) = \\dfrac{ e^{-\\frac{t}{\\tau}} }{ \\tau } \\mbox{ for } t \\geq 0\n",
        "$$\n",
        "- Mean is $\\tau$\n",
        "- Std is $\\sigma = \\tau$\n",
        "- From scipy.stats import expon\n",
        "    - expon.pdf to generate pdf <br>\n",
        "  \n",
        "#### Probability Density Function:\n",
        "- Probability that our random variable $X$ will be a specific value $x$\n",
        "$$PDF(x)=\\lambda e^{-\\lambda x}$$\n",
        "\n",
        "- $\\lambda$  = **decay parameter**(a.k.a. $m$)\n",
        "    \n",
        "$$\\lambda = \\frac{1}{\\mu}$$\n",
        "\n",
        "#### Cumulative Density Function:\n",
        "\n",
        "$$CDF(x) = 1 - e^{-\\lambda x}$$\n",
        "- distribution is unique:\n",
        "    - $\\sigma = \\mu$\n",
        "  \n",
        "#### Generate expoenential distribution"
      ]
    },
    {
      "metadata": {
        "id": "19srlQPMw3Ir",
        "colab_type": "code",
        "outputId": "877a13d5-1f0c-4885-fc6d-2c63b1800053",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Generate Expon Distibution\n",
        "from scipy.stats import expon\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(0, 10, 0.001)\n",
        "plt.plot(x, expon.pdf(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x175acc0bba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kfcCbLb7w3It",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    \n",
        "### Poisson Distribution\n",
        "- Allows us to calculate the prob of a given event by examining the mean number of events that happen in a given time period. \n",
        "    - Described by parameters:\n",
        "        - $\\mu$:average # of successes over given time period \n",
        "        - $x$:our random variable - the number of successes we want to find the pmf for. \n",
        "- Probability mass function gives way to predict the odds of getting another value instead, on a given future day/interval\n",
        "$$P(X) = \\frac{\\lambda^x e^{-\\lambda}}{X!}$$\n",
        "- $\\lambda$ is average # of successful events\n",
        "- $X\\$ is  number of successes\n",
        "- scipy.stats.poisson\n",
        "#### Generate Poisson Disbtribution"
      ]
    },
    {
      "metadata": {
        "id": "dtyN0GXew3Iu",
        "colab_type": "code",
        "outputId": "2578a283-85f3-4310-a8cf-b218f95fb8fe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate poisson distribution\n",
        "from scipy.stats import poisson\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "mu = 500\n",
        "x = np.arange(400, 600, 0.5)\n",
        "plt.plot(x, poisson.pmf(x, mu))\n",
        "plt.axvline(550, color= 'g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x175acae4e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CnuN9U_Dw3Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Distribution Cheat Sheet\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/k6qgj702dwn7vfr/distribution%20cheatsheet.jpg?raw=1\" width=800>"
      ]
    },
    {
      "metadata": {
        "id": "XtsXDMrHw3Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Negative binomial distribution\n",
        "#### Negative binomial trials \n",
        "- Describes number of failures\n",
        "\n",
        "#### Negative binomial distribution describes the ways negative binomial trials \n",
        "- Describes the of successes $k$ until observing a pre-determined # of failures $r$ for $x$ trials, where the probability for success for each independent trial is $p$.\n",
        "- Calculating **Negative Binomial Probability** by multiplying binomial probability by the probabiltiy of failure on trial x:\n",
        "    - $P^r∗(1−P)^{x−r}$\n",
        "$$b(x, r, P) =\\  _{x-1}C_{\\ r-1} * P^{\\ r} * (1-P)^{\\ x-r}  $$\n",
        "\n",
        "where C is the binomial distribution equation $$_{x-1}C_{\\ r-1}$ = \\frac{(x-1)!}{((n-1)-(r-1))!(r-1)!}$$.  \n",
        "\n",
        "#### Characteristics of Negative Binomial Distribution:\n",
        "\n",
        "- **_mean_**:\n",
        "\n",
        "$$\\mu = \\frac{r}{p}$$\n",
        "\n",
        "- **_variance_**:\n",
        "\n",
        "$$\\sigma^2 = \\frac{r\\ (1-p)}{p^{\\ 2}}  $$"
      ]
    },
    {
      "metadata": {
        "id": "NbrX3dQtw3Ix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Geometric Distribution\n",
        "- Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "- Same constraints as negative binomal dist:\n",
        "    -Multiple trials \n",
        "    - Outcome is binary\n",
        "    - Prob success same across trials\n",
        "    - Trials are independent \n",
        "- **Geometric Distribution Equation:**\n",
        "$$P(X=x) = q^{(x\\ -\\ 1)}p$$\n",
        "\n",
        "Where $$q = 1 - p$$\n",
        "\n",
        "- $X$ denotes the _Discrete Random Variable_,\n",
        "- $x$ the trial that we want to calculate the *Geometric Probability*\n",
        "- $p$ the probability of failure for a given trial\n",
        "- $q$ (1-p) is probability for success for given trial \n",
        "\n",
        "- **If p == q (equal prob), equation simplifies:\n",
        "$$P(X=x) = q^x$$"
      ]
    },
    {
      "metadata": {
        "id": "xPqhsqWpw3Iy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Distribution descriptions  in words\n",
        "**_Binomial Distribution_**: \"I flip a fair coin 5 times. What are the chances that I get heads 0 times? 1 time? 2 times? Etc...\"\n",
        "\n",
        "**_Negative Binomial Distribution_**: I flip a fair coin 5 times. What are the chances it takes me two flips to get heads twice? How about 3 flips to get heads twice? 4 Flips? Etc...\n",
        "\n",
        "The **_Exponential Distribution_** describes the probability distribution of the amount of time it may take before an event occurs.  In a way, it solves the inverse of the problem solves by the Poisson Distribution.\n",
        "\n",
        "The **_Poisson Distribution_** lets us ask how likely any given number of events are over a set interval of time.  \n",
        "\n",
        "The **_Exponential Distribution_** lets us ask how likely the _length of an interval of time_ is before an event occurs exactly once. \n",
        "\n",
        "Another way to think of the Exponential Distribution is as the continuous analogue of the **_Geometric Distribution_**. "
      ]
    },
    {
      "metadata": {
        "id": "VNBGdkb9w3Iy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-G7_Rvf_w3Iz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kolmogorov-Smirnov Test\n",
        "\n",
        "#### Noramlity assumption is important for many models-\n",
        "- Examine with plots:\n",
        "    - qqplots\n",
        "    - boxplot\n",
        "- Test with stats:\n",
        "    - The Shapiro-Wilk test;\n",
        "    - The Anderson-Darling test, and;\n",
        "    - The Kolmogorov-Smirnov test.\n",
        "    \n",
        "#### KS test used observed/empirical CDFs for comparisons:**\n",
        "- Uses CDFs to compare data to either:\n",
        "    - an ideal normal distribtuion for a one-sample KS test\n",
        "    - or another population for a two-sample KS test. \n",
        "- Similar to t-test but is sensitive to changes in the mean, variance, and shape of the data. \n",
        "    \n",
        "<img src=\"https://www.dropbox.com/s/jle5rdzan84qmfj/d.gif?raw=1\" width=400>\n",
        "\n",
        "- **Empirical distribution function:**   \n",
        "    - If X is a random variable with CDF $F(x)=P(X≤x)$ <br>\n",
        "      and  $x1,…,xn$ are i.i.d. random variables sampled from X empirical distribution function.\n",
        "\n",
        "$$\\hat{F}(x) = \\frac{\\text{# of elements in sample} \\leq x}{n} = \\frac{1}{n} \\Sigma_{i=1}^n I(x_i \\leq x) \\tag{1}$$\n",
        "\n",
        "\n",
        "#### One-Sample KS Test\n",
        "- Must provide completely specified theoretical distribution fucntion \n",
        "- Sensitive to mean, variance, shape. \n",
        "- Used to test normality assumption\n",
        "$$\n",
        "d\t   =    \tmax(abs[F_0(X)-F_r(X)])\n",
        "$$\n",
        "where\n",
        "- **d** is the maximum deviation Kolmogorov statistic \n",
        "- **F<sub>0</sub>(X)** = (No.of observations ≤ X)/(Total no.of observations) i.e. the non parametric empirical distribution\n",
        "- **F<sub>r</sub>(X)** = The theoretical frequency distribution of X - parametric (e.g. based on mean value) \n",
        "\n",
        "#### Two-Sample KS test\n",
        "- checks if two **independent** samples have been drawn from the same population, or, equivalently, from two identical populations (X = Y).\n",
        "- compares two **sample** distributions (instead of theoretical)\n",
        "\n",
        "$$d\t   =    \tmax[abs[{F_{n1}(X)-F_{n2}(X)}]]$$\n",
        "- $n_1$ = Observations from first sample.\n",
        "\n",
        "- $n_2$ = Observations from second sampl\n",
        "\n",
        "\n",
        "##### Interpreting d statistics\n",
        "- When the CDF shows large maximum deviation d reflects difference between the two sample distributions.\n",
        "    - Critical value of d for samples where n1=n2 and is ≤ 40, the K-S table for two sample case is used. \n",
        "    - When n1 and/or n2 > 40 then the K-S table for large samples of two sample test should be used.\n",
        "- The null hypothesis is accepted if the calculated value is less than the table value and vice-versa."
      ]
    },
    {
      "metadata": {
        "id": "WS62kvwrw3I0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Gm9In0TWw3I1",
        "colab_type": "code",
        "outputId": "5e6e267f-3b0e-4023-8d59-26960cb66176",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run me!O\n",
        "from IPython.display import HTML, display\n",
        "display(HTML(\"<table><tr><td><img src='https://www.dropbox.com/s/dcug9z684le4813/dists1.png?raw=1' width=600></td><td><img src='https://www.dropbox.com/s/3h6gmpy8iy11z91/dists2.png?raw=1' width=400 ></td></tr></table>\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table><tr><td><img src='https://www.dropbox.com/s/dcug9z684le4813/dists1.png?raw=1' width=600></td><td><img src='https://www.dropbox.com/s/3h6gmpy8iy11z91/dists2.png?raw=1' width=400 ></td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vZXrNZA_w3I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple Linear Regression\n",
        "### Using statsmodels to run Ordinary Least Squares Regressions*"
      ]
    },
    {
      "metadata": {
        "id": "i2qcWV_cw3I4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# TESTING ASSUMPTIONS AND RUNNING LINEAR REGRESSION\n",
        "\\# For all the variables, check if they hold normality assumption\n",
        "for column in data:\n",
        "    data[column].plot.hist(normed=True, label = column+' histogram')\n",
        "    data[column].plot.kde(label =column+' kde')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "![](media/a0ddfd1b41d9348b678840beeb05cd27.png)\n",
        "\n",
        "# [Test linearity assumption] visualize the relationship between the preditors and the target using scatterplots\n",
        "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
        "for idx, channel in enumerate(['TV', 'radio', 'newspaper']):\n",
        "    data.plot(kind='scatter', x=channel, y='sales', ax=axs[idx], label=channel)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "![](media/f216f3686df0bc39bd30a6cd13f45993.png)\n",
        "\n",
        "# Run a simple regression in **statsmodels**\n",
        "# import libraries\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# build the formula\n",
        "f = 'sales\\~TV'\n",
        "\n",
        "# create a fitted model in one line\n",
        "model = smf.ols(formula=f, data=data).fit()\n",
        "model.summary() \\# Will spit out stastics and coefficients, R2\n",
        "\n",
        "## Draw the prediction line from the model with the scatter plot:  \n",
        "# We can use model.predict() functions to predict start and end point of regression line for min and max values in variable]\n",
        "\n",
        "# create a DataFrame with the minimum and maximum values of TV\n",
        "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
        "print(X_new.head())\n",
        "\n",
        "\\# make predictions for those x values and store them\n",
        "preds = model.predict(X_new)\n",
        "print (preds)\n",
        "\n",
        "\\# first, plot the observed data and the least squares line\n",
        "data.plot(kind='scatter', x='TV', y='sales')\n",
        "plt.plot(X_new, preds, c='red', linewidth=2)\n",
        "plt.show()\n",
        "```\n",
        "![](media/79706ce0909dbf6a29f02a441cc4dd4a.png)\n",
        "\n",
        "```python\n",
        "# Visualize the error term for variance and heteroscedasticity:\n",
        "fig = plt.figure(figsize=(15,8))\n",
        "fig = sm.graphics.plot_regress_exog(model, \"TV\", fig=fig)\n",
        "plt.show()\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "X9isALZvw3I5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](media/8b847a77d81a31166697e6c519f543c6.png)\n",
        "\n",
        "**For the four graphs we see above:**\n",
        "\n",
        "-   The “Y and Fitted vs. X” graph plots the dependent variable against our\n",
        "    predicted values with a confidence interval. The positive relationship shows\n",
        "    that height and weight are correlated correlated, i.e., when one variable\n",
        "    increases the other increases.\n",
        "\n",
        "-   The “Residuals versus height” graph shows our model's errors versus the\n",
        "    specified predictor variable. Each dot is an observed value; the line\n",
        "    represents the mean of those observed values. Since there's no pattern in\n",
        "    the distance between the dots and the mean value, the OLS assumption of\n",
        "    homoskedasticity holds.\n",
        "\n",
        "-   The “Partial regression plot” shows the relationship between height and\n",
        "    weight, taking in to account the impact of adding other independent\n",
        "    variables on our existing height coefficient. We'll see later how this same\n",
        "    graph changes when we add more variables.\n",
        "\n",
        "-   The Component and Component Plus Residual (CCPR) plot is an extension of the\n",
        "    partial regression plot, but shows where our trend line would lie after\n",
        "    adding the impact of adding our other independent variables on the weight.\n",
        "    We shall look at this in more detail in multiple regression.\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "czs6nSt4w3I6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Regression Diagnostics in Statsmodels\n",
        "- We’ve already used R2 value (from ols model.summary()) and visualization to confirm if the data and residuals fit the assumptios. Here we will learn procedures to further understand our model and results.\n",
        "\n",
        ">   *Regression diagnostic is a set of procedures available for regression\n",
        ">   analysis that seek to assess the validity of a model in any of a number of\n",
        ">   different ways. This assessment may be an exploration of the model's\n",
        ">   underlying statistical assumptions, an examination of the structure of the\n",
        ">   model by considering formulations that have fewer, more or different\n",
        ">   explanatory variables, or a study of subgroups of observations, looking for\n",
        ">   those that are either poorly represented by the model (outliers) or that\n",
        ">   have a relatively large effect on the regression model's predictions.*\n",
        ">   [Wiki](https://en.wikipedia.org/wiki/Regression_diagnostic)"
      ]
    },
    {
      "metadata": {
        "id": "z6YFE_xCw3I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q-Q Plots to check normality (also called normal density plots when used with standard normal quantiles)\n",
        "\n",
        "- These plots are good way to inspect the distribution of model errors."
      ]
    },
    {
      "metadata": {
        "id": "ecuBP1Uvw3I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.api as sms\n",
        "import statsmodels.formula.api as smf\n",
        "import scipy.stats as stats\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "data = pd.read_csv('Advertising.csv', index_col=0)\n",
        "f = 'sales\\~TV' \n",
        "f2 = 'sales\\~radio' \n",
        "model = smf.ols(formula=f, data=data).fit() \n",
        "model2 = smf.ols(formula=f2, data=data).fit() \n",
        "resid1 = model.resid \n",
        "resid2 = model2.resid \n",
        "\n",
        "fig = sm.graphics.qqplot(resid2, dist=stats.norm, line='45', fit=True) \n",
        "fig.show() \n",
        "```\n",
        "~~img src=\"media/9707e080f47e37b45f414bc7adcf1ad0.png\" width=400>~~"
      ]
    },
    {
      "metadata": {
        "id": "Titc7cdew3I8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normal Q-Q Plots are a direct visual assessment of how well our residuals\n",
        "match what we would expect from a normal distribution.**\n",
        "\n",
        "In terms of Q-Q plots above, we can see that residuals are better normally\n",
        "distributed in the case of TV than that of radio. We can also spot an outlier in\n",
        "the left tail of radio residuals, dealing with this might help improve the\n",
        "fitness of the model. Outliers, skew, heavy and light-tailed aspects of\n",
        "distributions (all violations of normality) can be assessed from Q-Q plots\n",
        "\n",
        "-   Example Q-Q plots vs histogram/density plot (to help learn what Q-Q plot is\n",
        "    saying:\n",
        "<img src=\"media/bea1c75ce827d7327861c28b229667b2.png\" width=600>\n"
      ]
    },
    {
      "metadata": {
        "id": "8mzckl1uw3I9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression*\n",
        "\n",
        "\n",
        "### HOW TO: BLOG POST ON LINEAR REGRESSION IN PYTHON:\n",
        "\n",
        "<https://www.dropbox.com/s/bzg4o8ndtu70byg/Linear%20Regression%20in%20Python%20-%20Blog%20Post.pdf?dl.0=0>\n",
        "\n",
        "- Step 1: visualization\n",
        "    1.  Look for linear relationship – use Seaborn’s pairplot sns.pairplot(data, x_vars = [b1,b2,b3], y_vars=’Sales’,kind=’reg’)  \n",
        "        \\# Note, can also pass ‘size= “ for change plot size.  \n",
        "        \\# kind = ‘reg’ attempts to add line of best fit and 95% confidence interval (will aim to minimize the sum of squared error)\n",
        "\n",
        "- Step 2: SK Learn – Setting Variables\n",
        "    1.  Scikit-Learn expects X to be a ‘feature matrix’ (Pandas DataFrame) and y to be a ‘response vector’\n",
        "    2.  X=dataframe. y = y from the dataframe\n",
        "    \n",
        "- Step 3: SK Learn – Splitting our data\n",
        "```python\n",
        "from sklearn.cross_validation import test_train_split  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "```\n",
        "- Step 4: SK Learn – Training our model\n",
        "\n",
        "```python \n",
        "# Import linear regression and instantiate  \n",
        "from sklearn.linear_model import LinearRegression  \n",
        "linreg = LinearRegression()  \n",
        "\n",
        "# Fit model to training data  \n",
        "linrg.fit(X_train, y_train)\n",
        "```\n",
        "- Step 5: Interpreting Coefficients\n",
        "```python \n",
        "print(lingreg.intercept_) \\# prints y-intercept, BO  \n",
        "print(linreg.coef_) \\# prints beta coeffiicents in same order as passed  \n",
        "zip(feature_cols, linreg.coef_) \\# Pair feature names and coefficients\n",
        "```\n",
        "- Step 6: Making predictions  \n",
        "```python\n",
        "y_pred = linreg.predict(X_test)\n",
        "```\n",
        "- Step 7: Model Evaluation  \n",
        "```python \n",
        "from sklearn import metrics  \n",
        "\\# Most popular metric to use is root-mean-square-error (RMSE)  \n",
        "print(np.sqrt(metrics.mean_squared_error(y_true, y_pred)))  \n",
        "\\#People also use Mean Absolute Error or Mean-Squared Error, but harder to interpret\n",
        "```\n",
        "- Step 8: Feature selection:\n",
        "\n",
        "    1.  Once have error metric, take note which X’s have minimal impact on y.\n",
        "        1.  Removing some of these may increase the accuracy of the model\n",
        "    2.  Now, process of trial and error, starting over again (dropping columns) until reach a satisfactory model\n",
        "    3.  Recommended Steps:\n",
        "        1.  Replace feature_cols & X\n",
        "        2.  Train_test_split your data\n",
        "        3.  Fit the model to linreg again using linreg.fit\n",
        "        4.  Make predictions using (y_pred = linreg.predict(X_test))\n",
        "        5.  Compute RMSE\n",
        "        6.  Repeat until RMSE satisfactory"
      ]
    },
    {
      "metadata": {
        "id": "NHvNraTZw3I9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Code from: FEATURE SCALING AND NORMALIZATION LAB:\n",
        "\n",
        "1.  Performing binning / as categories for numerical categorical variables for\n",
        "    regression, create dummy variables ( and replace orig):\n",
        "    \n",
        "```python\n",
        "# first, create bins for based on the values observed. 5 values will result\n",
        "in 4 bins\n",
        "\n",
        "bins = [0, 3, 4 , 5, 24]\n",
        "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
        "bins_rad = bins_rad.cat.as_unordered()\n",
        "\n",
        "# first, create bins for based on the values observed. 5 values will result in 4 bins\n",
        "\n",
        "bins = [0, 250, 300, 360, 460, 712]\n",
        "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
        "bins_tax = bins_tax.cat.as_unordered()\n",
        "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\")\n",
        "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\")\n",
        "\n",
        "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n",
        "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
        "boston_features = boston_features.drop(\"NOX\",axis=1)\n",
        "```\n",
        "\n",
        "2.  Filtering out the columns of a dataframe using drop, filter, and regex :\n",
        "\n",
        "```python \n",
        "df= boston_features\n",
        "boston_cont = df[df.columns.drop(list(df.filter(regex='TAX')))]\n",
        "boston_cont = boston_cont[boston_cont.columns.drop(list(boston_cont.filter(regex='RAD')))]\n",
        "boston_cont= boston_cont.drop(['CHAS'], axis=1)\n",
        "```\n",
        "\n",
        "3.  Different Tpes of transformations on the dataframe:\n",
        "\n",
        "```python\n",
        "data_log = df_log\n",
        "age = boston_cont[\"AGE\"]\n",
        "b = boston_cont[\"B\"]\n",
        "rm = boston_cont[\"RM\"]\n",
        "logcrim = data_log[\"CRIM\"]\n",
        "logdis = data_log[\"DIS\"]\n",
        "logindus = data_log[\"INDUS\"]\n",
        "loglstat = data_log[\"LSTAT\"]\n",
        "logptratio = data_log[\"PTRATIO\"]\n",
        "features_final= pd.DataFrame([])\n",
        "\n",
        "features_final[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
        "features_final[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
        "features_final[\"RM\"] = (rm-min(rm))/(max(rm)-min(rm))\n",
        "features_final[\"DIS\"] = (logdis-np.mean(logdis))/np.sqrt(np.var(logdis))\n",
        "features_final[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
        "features_final[\"LSTAT\"] = (loglstat-np.mean(loglstat))/(max(loglstat)-min(loglstat))\n",
        "features_final[\"AGE\"] = (age-np.mean(age))/(max(age)-min(age))\n",
        "features_final[\"PTRATIO\"] = (logptratio)/(np.linalg.norm(logptratio))\n",
        "```\n",
        "### Code from: Regression modeling with Boston Housing Dataset\n",
        "\n",
        "![](media/05194d71a28f0a54e57e63ea704f485b.png)\n",
        "\n",
        "```python\n",
        "\\# Your code here\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import scipy.stats as stats\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "# The results will be saved in results list\n",
        "results = [['ind_var','r_sqared','intercept','slope','p-value','norm_JB']]\n",
        "\n",
        "# TO LOOP THROUGH LIST OF DATACOLUMNS TO RUN OLS REGRESSION + PRINT/SAVE RESULTS*\n",
        "for idx, val in enumerate(['crim','dis','rm','zn','age']):\n",
        "    print (\"Boston Housing DataSet - Regression Analysis and Diagnostics for\n",
        "    formula: medv\\~\" + val)\n",
        "\n",
        "    print\n",
        "    (\"-------------------------------------------------------------------------------------\")\n",
        "\n",
        "    f = 'medv\\~' + val\n",
        "    model = smf.ols(formula=f,data=data).fit()\n",
        "    X_new = pd.DataFrame({val: [data[val].min(),data[val].max()]}\n",
        "    preds= model.predict(X_new)\n",
        "\n",
        "    data.plot(kind='scatter',x=val,y='medv')\n",
        "    plt.plot(X_new,preds,c='red',linewidth=2)\n",
        "    plt.show()\n",
        "\n",
        "    fig=plt.figure(figsize=(15,8))\n",
        "    fig = sm.graphics.plot_regress_exog(model, val, fig=fig)\n",
        "    fig = sm.graphics.qqplot(model.resid,dist=stats.norm, line='45',fit=True )\n",
        "    plt.show\n",
        "                         \n",
        "    results.append([val,model.rsquared,model.params[0],model.params[1],model.pvalues[1],sms.jarque_bera(model.resid)[0]])\n",
        "    input('Press Enter to continue...')\n",
        "```\n",
        "### Code from: Dealing with categorical variables lab\n",
        "```python\n",
        "# Get list of column names (to use for plotting from df)*\n",
        "names = boston_df.columns\n",
        "nameList = [str(x) for x in names]\n",
        "col_names = nameList[1:]\n",
        "print(col_names)\n",
        "\n",
        "# Loop through each column to plot\n",
        "for col in col_names:\n",
        "plt.figure()\n",
        "plt.scatter(boston_df[col],boston_df['MEDV'],label=col,marker='.')\n",
        "plt.legend()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "o7U20CLWw3I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### REGRESSION MODEL VALIDATION\n",
        "\n",
        "- using train-test-split\n",
        "\n",
        "![](media/480152d587e701dde0f1599c9d684426.png)"
      ]
    },
    {
      "metadata": {
        "id": "1dN0DugIw3I_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Using train-test-split from sklearn*\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression  \n",
        "lingreg=LinearRegression(X_train, y_train)\n",
        "\n",
        "y_hat_train = linreg.predict(X_train)  \n",
        "y_hat_test = linreg.predict(X_test)\n",
        "\n",
        "train_residuals = y_hat_train – y_train  \n",
        "test_residuals = y_hat_test – y_test\n",
        "\n",
        "mse_train = np.sum((y_train – y_hat_train)\\*\\*2/len(y_train)  \n",
        "mse_test = np.sum((y_test – y_hat_test)\\*\\*2/len(y_test)\n",
        "```\n",
        "\n",
        "**Select columns using regex**\n",
        "```python\n",
        "df.filter(regex=('Mark'),axis=1).describe()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Bj5Y_43tw3I_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## OUR FIRST EXAMPLE COMPLETE PROJECT (Section 12)\n",
        "\n",
        "### Modeling Our Data Lab/Lesson:\n",
        "\n",
        "-   Load in pre-cleaned file\n",
        "    -   This is after having cleaned the dataset and made dummy variables.\n",
        "    -   Must re-cast categories as categories when reloading data\n",
        "\n",
        "-   If there are a lot of possible predictors, should try starting with single\n",
        "    linear regressions (on CONTINUOUS)\n",
        "    -   Using statsmodels.formula.api as smf\n",
        "    \n",
        "```python\n",
        "\n",
        "import statsmodels.formula.api as smf  \n",
        "# .describe used to select non-categorical values, then drop target var\n",
        "col_names = dataframe.describe().columns.drop(['Target_Var'])                                             \n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]                                               \n",
        "                                               \n",
        "# Use loop to run ols model with f=’Target_Variable\\~’+val\n",
        "for idx, val in enumerate(col_names):\n",
        "\n",
        "    print (\"Walmart: Weekly_Sales\\~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'Weekly_Sales\\~' + val\n",
        "    model = smf.ols(formula=f, data=walmart).fit()\n",
        "\n",
        "    X_new = pd.DataFrame({val: [walmart[val].min(), walmart[val].max()]})\n",
        "    preds = model.predict(X_new)\n",
        "\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])                    \n",
        "                                               \n",
        "pd.DataFrame(results)\n",
        "                                               \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "pqLDDq3Rw3JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- **Examine outputs:**\n",
        "\n",
        "        -   What do the parameter estimates mean? Do they make sense?\n",
        "        -   What do the p-values tell us?\n",
        "        -   What does the R-squared tell us?\n",
        "\n",
        "    -   If poor R-squared, re-examine distributions\n",
        "        -   Dataframe.hist()\n",
        "        \n",
        "    -   If skewed data can log transform:\n",
        "        -   If negative data:\n",
        "        ```python\n",
        "            -   walmart_log= walmart[walmart[\"Weekly_Sales\"]\\ 0]\n",
        "            -   walmart_log[\"Weekly_Sales\"]= np.log(walmart_log[\"Weekly_Sales\"])\n",
        "        ```\n",
        "-   **Re-run loop from earlier:**\n",
        "\n",
        "    -   compare and constrast the results with the results obtained when we did not take the log(sales)\n",
        "        -   Which one would you want to proceed with based on this?\n",
        "\n",
        "-   Build a model with each category variable as a predictor (can re-run data vs data-log, re-examine the R-square output)\n",
        "    -   Put all categories for one categorical variable in 1 model (so 4 models if 4 different categorical variables\n",
        "        -   IF USED DUMMY CODES, MUST DROP 1 FOR BETTER RESULTS (not explained)\n",
        "    -   Use output to judge choice of data vs data_log.\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "26yQIuG2w3JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "-   **Use the model results to identify variables that we can drop from the\n",
        "    model.**\n",
        "\n",
        "    -   Can do manually (drop from dataframe and re-run)\n",
        "    -   **Can Use RECURSIVE FEATURE ELIMINATION FOR X NUMBER OF FEATURES**\n",
        "\n",
        "        -   Create a for loop (below is 5-\\ 85 by 10’s)\n",
        "        \n",
        "```python\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "r_list = []\n",
        "adj_r_list = []\n",
        "list_n = list(range(5,86,10))\n",
        "for n in list_n:\n",
        "    select_n = RFE(linreg, n_features_to_select = n)\n",
        "    select_n = select_n.fit(X, np.ravel(y))\n",
        "    selected_columns = X.columns[select_n.support\\_ ]\n",
        "\n",
        "    linreg.fit(X[selected_columns],y)\n",
        "    yhat = linreg.predict(X[selected_columns])\n",
        "\n",
        "    SS_Residual = np.sum((y-yhat)\\*\\*2)\n",
        "    SS_Total = np.sum((y-np.mean(y))\\*\\*2)\n",
        "\n",
        "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
        "    print(r_squared)\n",
        "\n",
        "    adjusted_r_squared = 1 - (1-r_squared)\\*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
        "    print(adjusted_r_squared)\n",
        "    r_list.append(r_squared)\n",
        "    adj_r_list.append(adjusted_r_squared)\n",
        "```\n",
        "\n",
        "> “What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!”\n",
        "\n",
        "-   Can do a 10-fold cross validation with the final model.\n",
        "```python\n",
        "        from sklearn.metrics import mean_squared_error\n",
        "        from sklearn.model_selection import cross_val_score\n",
        "        # select 85 best predictors\n",
        "        select_85 = RFE(linreg, n_features_to_select = 85)\n",
        "        select_85 = select_n.fit(X, np.ravel(y))\n",
        "        selected_columns = X.columns[select_n.support_]\n",
        "        cv_10_results = cross_val_score(linreg, X[selected_columns], y, cv=10,\n",
        "        scoring=\"neg_mean_squared_error\")\n",
        "        cv_10_results\n",
        "```\n",
        "> “Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might\n",
        "cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!”"
      ]
    },
    {
      "metadata": {
        "id": "Fd5Spg6Iw3JB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MOD 1 FINAL PROJECT Workflow Notes (section12)\n",
        "\n",
        "### Order of Processing (using OSEMN model)\n",
        "1.  **OBTAIN: Import data, inspect, check for datatypes to convert and null\n",
        "    values**\n",
        "\n",
        "    -   Display header and info\n",
        "\n",
        "    -   Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
        "\n",
        "2.  **SCRUB: cast data types, identify outliers, check for multicollinearity,\n",
        "    normalize data**\n",
        "\n",
        "    -   Check and cast data types\n",
        "\n",
        "        -    Check for \\#'s that are store as objects (df.info())\n",
        "\n",
        "            -   when converting to \\#'s, look for odd values (like many 0's), or\n",
        "                strings that can't be converted\n",
        "\n",
        "            -   Decide how to deal weird/null values (df.unique(),\n",
        "                df.isna().sum(), df.describe()-min/max, etc\n",
        "\n",
        "        -    Check for categorical variables stored as integers (for now cast as\n",
        "            strings)\n",
        "\n",
        "    -   Check for missing values (df.isna().sum())\n",
        "\n",
        "        -   Can drop rows or colums\n",
        "\n",
        "        -   For missing numeric data with median or bin/convert to categorical\n",
        "\n",
        "        -   For missing categorical data: make NaN own category OR replace with\n",
        "            most common category\n",
        "\n",
        "    -   Check for multicollinearity\n",
        "\n",
        "        -   use seaborn to make correlation matrix plot [Evernote\n",
        "            Link](https://www.evernote.com/l/AArNyaEwjA5JUL6I9PazHs_ts_hU-m7ja1I/)\n",
        "\n",
        "            -   Good rule of thumb is anything over 0.75 corr is high, remove\n",
        "                the variable that has the most correl with the largest \\# of\n",
        "                variables\n",
        "\n",
        "    -   Normalize data (may want to do after some exploring)\n",
        "\n",
        "        -   Most popular is Z-scoring (but won't fix skew)\n",
        "\n",
        "        -   Can log-transform to fix skewed data\n",
        "\n",
        "3.  **EXPLORE: Check distributions, outliers, etc**\n",
        "\n",
        "    -   Check scales, ranges (df.describe())\n",
        "\n",
        "    -   Use histograms to get an idea of distribut(df.hist())\n",
        "\n",
        "        -   Can also do kernel density estimates\n",
        "\n",
        "    -    use scatterplots to check for linearity and possible categorical\n",
        "        variables (df.plot(kind-'scatter')\n",
        "\n",
        "        -   categoricals will look like vertical lines\n",
        "\n",
        "    -    Use pd.plotting.scatter_matrix to visualize possible relationships\n",
        "\n",
        "    -   ADVANCED pair-wise comparison\n",
        "        via [joint-plots](https://seaborn.pydata.org/generated/seaborn.jointplot.html)\n",
        "\n",
        "        -   ns.jointplot(x= \\<column\\>, y= \\<column\\>, data=\\<dataset\\>,\n",
        "            kind='reg')\n",
        "\n",
        "    -   **Check for linearity**\n",
        "\n",
        "4.  **Fit an intiial model**\n",
        "\n",
        "    -   Various forms, detail later...\n",
        "\n",
        "    -   **Assessing the model:**\n",
        "\n",
        "        -   Assess parameters (slope,intercept)\n",
        "\n",
        "        -   Check if the model explains the variation in the data (RMSE, F,\n",
        "            R_square)\n",
        "\n",
        "        -   *Are the coeffs, slopes, intercepts in appropriate units?*\n",
        "\n",
        "        -   *Whats the impact of collinearity? Can we ignore?*\n",
        "\n",
        "5.  **Revise the fitted model**\n",
        "\n",
        "    -   Multicollinearity is big issue for lin regression and cannot fully\n",
        "        remove it\n",
        "\n",
        "    -   Use the predictive ability of model to test it (like R2 and RMSE)\n",
        "\n",
        "    -   Check for missed non-linearity\n",
        "\n",
        "6.  **Holdout validation / Train/test split**\n",
        "\n",
        "    -   use sklearn train_test_split"
      ]
    },
    {
      "metadata": {
        "id": "JBmYRi5aw3JB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regular Expression in Beautiful Soup\n",
        "```python\n",
        "# Import required packages\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas\n",
        "import requests\n",
        "import re\n",
        "\n",
        "\\# Use beautiful soup to get declared url\n",
        "url = 'https://www.azlyrics.com/p/panicatthedisco.html' \\#Put the URL of\n",
        "your AZLyrics Artist Page here!\n",
        "\n",
        "html_page = requests.get(url) \\#Make a get request to retrieve the page\n",
        "soup = BeautifulSoup(html_page.content, 'html.parser') \\#Pass the page contents to beautiful soup for parsing\n",
        "\n",
        "# Print html-nested structured result\n",
        "print(soup.prettify()[:1000])\n",
        "\n",
        "# Get all links that have 'panic'\n",
        "def get_links(soup,str='panic'):\n",
        "link_list=[]\n",
        "for link in soup.find_all('a'):\n",
        "\ttest_link = link.get('href')\n",
        "\n",
        "\tif str in test_link:\n",
        "        link_list.append(test_link)\n",
        "    return link_list\n",
        "\n",
        "# Use function\n",
        "panic_links = get_links(soup,’panic’)\n",
        "\n",
        "# Constructing reg exp to find the last 2 branches of web address (using / ... /... .html), and saves the band and song strings\n",
        "pattern = **r**'\\\\/(?P\\<band\\\\\\w\\*)\\\\/(?P\\<song\\\\\\w\\*).html'\n",
        "exp = re.compile(pattern) \\# the exp is a re object and can be used in methods OR functions.\n",
        "\n",
        "# save a list of the captured band and song tokens O\n",
        "result = []\n",
        "[result.append(exp.findall(x)) for x in panic_links]\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "p8Hkw-0YQuR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Testing "
      ]
    },
    {
      "metadata": {
        "id": "L3EDboKNQx01",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Scientific Method\n",
        "<img src=\"https://www.dropbox.com/s/xcd5832r97ubxs9/The%2BScientific%2BMethod.jpg?raw=1\"  width=400>\n",
        "\n",
        "1. Make an Observation\n",
        "2. Examine the Research\n",
        "3. Form a hypothesis\n",
        "4. Conduct an Experiment\n",
        "5. Analyze Experimental Results\n",
        "6. Draw Conclusions \n",
        "\n",
        "### Foundations of a Sound Experiment\n",
        "1. Control group / random controlled \n",
        "2. Appropriate sample sizes\n",
        "3. Reproducibility\n",
        "\n",
        "### P - Values and Null Hypothesis \n",
        "- Null hypothesis ($H_0$):  There is no relatinship between A and B\n",
        "- Alternative hypothesis ($H_0$): There is a ____ kind of relationship between A & B\n"
      ]
    },
    {
      "metadata": {
        "id": "Ndy04LvyTVk-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://www.dropbox.com/s/wsukib2gmsm5fea/one-sample-discrete-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/vd8j1jtshj5wrj0/two-sample-discrete-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/manaq0po9s7dyho/one-sample-continuous-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/q1dgponudr11tz5/two-sample-continuous-data.png?raw=1\">\n"
      ]
    },
    {
      "metadata": {
        "id": "UOM2QLiWUB7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Effect Sizes\n",
        "- P value = probability sample Means are the same.\n",
        "- (1 – P) or C.L. = probability sample Means are different.\n",
        "- Effect Size = how different sample Means are.\n",
        "    - Large effect sizes are visible even with small samples\n",
        "    - Ideally measured in standardized units\n",
        "\n",
        "\n",
        "### Cohen's $d$/ Hedge's $g$\n",
        "- Cohen's $d$ is the effect size\n",
        "Cohen's $$d = \\frac{(Mean_A - Mean_B)}{Pooedl StDev}$$\n",
        "- Hedge's $g$ is the _corrected effect size_  [See article](https://www.statisticshowto.datasciencecentral.com/hedges-g/)\n",
        "$$Hedges'  g = d \\times (\\frac{N-3}{N-2.25})\\times \\sqrt{ \\frac{N-2}{N}}$$\n",
        " - At small sample sizes (N<20) Hedge's is JUST Cohen's $d$\n",
        " - With large sample sizes (N>20), Hedge's adds the correction.\n",
        " \n",
        "- Interpretation: Rules of Thumb\n",
        "    - Small effect = 0.2 ( cannot be seen by naked eye)\n",
        "    - Medium effect  = 0.5\n",
        "    - Large Effect = 0.8 (can be seen by naked eye)\n",
        "    ___\n",
        "    \n",
        "<img src=\"https://www.dropbox.com/s/bdxp1li38lsqcoy/Effect%20size%20graph.png?raw=1\" width=600>\n",
        "\n",
        "### Power Analysis to Determine Required Sample Size from Effect SIze\n",
        "\n",
        "$$n = (\\frac{Z \\times Group S.D.}{Effect Size})^2 $$\n",
        "\n",
        "- where t-stat or Z Value = Difference in Means/Group Standard Error\n",
        "\n",
        "#### Unstandardized Effect Sizes\n",
        "- **Relative DIfference of means(%):**\n",
        "\n",
        "$\\frac{ M_1 - M_2}{M_1} \\times 100$ \n",
        "\n",
        "\n",
        "- **Simple Overlap Threshold**\n",
        "\n",
        "threshold = $\\frac{M_1+M_2}{2}$\n",
        "___\n",
        "\n",
        "### Overlap Threshold of Prob. Density Functions:** [Use this]\n",
        "\n",
        "$ thresh  = \\frac{(std_1\\times M_2 + std_2\\times M_1)}{(std_1+std_2)}$\n",
        "\n",
        "- Overlap is total **Area Under the Curves** of overlap\n",
        "\n",
        "$overlap = \\frac{(M_1 < T)}{n_1} + \\frac{M_2 >T}{n_2}$\n",
        "\n",
        "where $T$ = threshold\n",
        "    \n",
        "- Missclassification rate = $\\frac{overlap}{2}$\n",
        "\n",
        "### Probability of Superiority\n",
        "-  \"non-parametric\" way to quantify the difference between distributions. The probability that \"a randomly-chosen man is taller than a randomly-chosen woman\"\n",
        "\n",
        "-Overlap (or misclassification rate) and \"probability of superiority\" have two good properties:\n",
        "\n",
        "    - As probabilities, they don't depend on units of measure, so they are comparable between studies.\n",
        "\n",
        "    - They are expressed in operational terms, so a reader has a sense of what practical effect the difference makes.\n",
        "```python    \n",
        "def overlap_superiority(group1, group2, n=1000):\n",
        "\"\"\"Estimates overlap and superiority based on a sample.\n",
        "\n",
        "group1: scipy.stats rv object\n",
        "group2: scipy.stats rv object\n",
        "n: sample size\n",
        "\"\"\"\n",
        "\n",
        "# Get a sample of size n from both groups\n",
        "group1_sample = group1.rvs(n)\n",
        "group2_sample = group2.rvs(n)\n",
        "\n",
        "# Identify the threshold between samples\n",
        "thresh = (group1.mean() + group2.mean()) / 2\n",
        "print(thresh)\n",
        "\n",
        "# Calculate no. of values above and below for group 1 and group 2 respectively\n",
        "above = sum(group1_sample < thresh)\n",
        "below = sum(group2_sample > thresh)\n",
        "\n",
        "# Calculate the overlap\n",
        "overlap = (above + below) / n\n",
        "\n",
        "# Calculate probability of superiority\n",
        "superiority = sum(x > y for x, y in zip(group1_sample, group2_sample)) / n\n",
        "\n",
        "return overlap, superiority\n",
        "```\n",
        "___\n",
        "\n",
        "#### Cohen's d\n",
        "```python\n",
        "def Cohen_d(group1, group2):\n",
        "    # Compute Cohen's d.\n",
        "    # group1: Series or NumPy array\n",
        "    # group2: Series or NumPy array\n",
        "    # returns a floating point number \n",
        "    diff = group1.mean() - group2.mean()\n",
        "\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1 = group1.var()\n",
        "    var2 = group2.var()\n",
        "\n",
        "    # Calculate the pooled threshold as shown earlier\n",
        "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
        "    \n",
        "    # Calculate Cohen's d statistic\n",
        "    d = diff / np.sqrt(pooled_var)\n",
        "    \n",
        "    return d\n",
        "\n",
        "\n",
        "def plot_pdfs(cohen_d=2):\n",
        "    \"\"\"Plot PDFs for distributions that differ by some number of stds.\n",
        "    \n",
        "    cohen_d: number of standard deviations between the means\n",
        "    \"\"\"\n",
        "    group1 = scipy.stats.norm(0, 1)\n",
        "    group2 = scipy.stats.norm(cohen_d, 1)\n",
        "    xs, ys = evaluate_PDF(group1)\n",
        "    pyplot.fill_between(xs, ys, label='Group1', color='#ff2289', alpha=0.7)\n",
        "\n",
        "    xs, ys = evaluate_PDF(group2)\n",
        "    pyplot.fill_between(xs, ys, label='Group2', color='#376cb0', alpha=0.7)\n",
        "    \n",
        "    o, s = overlap_superiority(group1, group2)\n",
        "    print('overlap', o)\n",
        "    print('superiority', s)\n",
        "   \n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/folsno68jidkroj/output_61_1.png?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "fkIrbGw-lAXW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Statistical Power\n",
        "Power = 1 - P (Type II error) = probability of finding an effect that is there\n",
        " - Same as $ \\beta = (1 - \\alpha)$"
      ]
    },
    {
      "metadata": {
        "id": "YywI36W1IRs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Module 3\n",
        "\n",
        "## Time Series \n",
        "- Converting to datetime, setting index\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.core import datetools\n",
        "\n",
        "temp_data.Date = pd.to_datetime(temp_data.Date, format='%d/%m/%y')\n",
        "temp_data.set_index('Date', inplace = True)\n",
        "```\n",
        "- Downsampling or upsampling time series\n",
        "\n",
        "```python\n",
        "# Downsampling (to larger time unit):\n",
        "temp_monthly= temp_data.resample('MS') # MS = month start\n",
        "\n",
        "# Upsampling (to smaller time unit, may cause NaN\n",
        "temp_bidaily= temp_data.resample('12H').asfreq()\n",
        "\n",
        "# Fill in emppty time indices:\n",
        "temp_bidaily_fill= temp_data.resample('12H').ffill() # Forwards fill\n",
        "temp_bidaily_fill= temp_data.resample('12H').bfill() #Backwards fill\n",
        "```\n",
        "- Slicing time series\n",
        "\n",
        "```python\n",
        "temp_1985_onwards = temp_data['1985':]\n",
        "```\n",
        "\n",
        "- Plotting time series: (ts=time series dataframe)\n",
        "```python\n",
        "# Line plot\n",
        "ts.plot(subplots=True/False)\n",
        "# Dot plot\n",
        "ts.plot(style='.b')\n",
        "# Histogram\n",
        "ts.hist()\n",
        "# KDE\n",
        "ts.plot(kind='kde')\n",
        "# Box & Whiskers\n",
        "ts.boxplot()\n",
        "# Heat maps\n",
        "year_matrix = nyse_annual.T  # First must transpose.\n",
        "plt.matshow(year_matrix, interpolation=None, aspect='auto', cmap=plt.cm.Spectral_r)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Types of Time Series Trends\n",
        "\n",
        "- Stationary vs Non-Stationary \n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/utn0m1ry9raefx0/Mean_nonstationary.png?raw=1\" width=400>\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/d5o899hhus5ppxx/Var_nonstationary.png?raw=1\" width=400>\n",
        "\n",
        "- Trends can be:\n",
        "    - Linear\n",
        "    - Exponential\n",
        "    - Periodic/seasonal\n",
        "    - Trends with Increasing/Decreasing Variance\n",
        "    \n",
        "<img src=\"https://www.dropbox.com/s/pfpygr22gnrdz6m/trendseasonal.png?raw=1\" width=500>\n",
        "\n",
        "#### Trend detection: Rolling statistics:\n",
        "\n",
        "    - Moving average/variance calculations using ```.rolling()```\n",
        "\n",
        "```python\n",
        "rolmean = ts.rolling(window = 8, center = False).mean()\n",
        "rolstd = ts.rolling(window = 8, center = False).std()\n",
        "fig = plt.figure(figsize=(12,7))\n",
        "orig = plt.plot(ts, color='blue',label='Original')\n",
        "mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/n6pfycjt0jntk1l/index_38_0.png?raw=1\" width=400>\n",
        "\n",
        "#### Trend detection: Dickey Fuller Test\n",
        "- [adfuller from statsmodels.tsa.statstools](http://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html)\n",
        "- The Dickey Fuller Test null hypothesis is that the series is NOT stationary, so a significant result means that it IS stationary. \n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "dftest = adfuller(ts)\n",
        "\n",
        "# Extract and display test results in a user friendly manner\n",
        "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "for key,value in dftest[4].items():\n",
        "    dfoutput['Critical Value (%s)'%key] = value\n",
        "print(dftest)\n",
        "\n",
        "```\n",
        "\n",
        "#### def stationarity_check(): from lessons\n",
        "```python\n",
        "def stationarity_check(TS):\n",
        "    \n",
        "    # Import adfuller\n",
        "    from statsmodels.tsa.stattools import adfuller\n",
        "    \n",
        "    # Calculate rolling statistics\n",
        "    rolmean = TS.rolling(window = 8, center = False).mean()\n",
        "    rolstd = TS.rolling(window = 8, center = False).std()\n",
        "    \n",
        "    # Perform the Dickey Fuller Test\n",
        "    dftest = adfuller(TS['#Passengers']) # change the passengers column as required \n",
        "    \n",
        "    #Plot rolling statistics:\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    orig = plt.plot(TS, color='blue',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean & Standard Deviation')\n",
        "    plt.show(block=False)\n",
        "    \n",
        "    # Print Dickey-Fuller test results\n",
        "    print ('Results of Dickey-Fuller Test:')\n",
        "\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print (dfoutput)\n",
        "    \n",
        "    return None\n",
        "```\n",
        "- [Article on testing for non-stationary](https://machinelearningmastery.com/time-series-data-stationary-python/)\n",
        "\n",
        "#### Eliminating trends\n",
        "Have several methods for elimianting different trends:\n",
        "\n",
        "- **Taking the log transformation (or square root, cube root)**\n",
        "        - ```np.log(ts) or np.sqrt(ts) ```\n",
        "    - Will make time series more \"uniform\" over time. \n",
        "    - Higher values are penalized more than lower ones. \n",
        "- **Subtracting the rolling mean**\n",
        "    - Calculate the rolling mean ( using.rolling() ) and subtract it from the ts.\n",
        "\n",
        "```python\n",
        "\n",
        "rolmean = ts.rolling(window = 4).mean()\n",
        "ts_diff = ts - rolmean\n",
        "\n",
        "```\n",
        "        \n",
        "- **Weighted rolling mean.**\n",
        "    - Pandas has Exponentially Weighted Moving Average (ts.ewm())\n",
        "    - Halflife parameter determines exponentail decay. Can use other parameters like span and center of mass to define decay. \n",
        "        - Discussed in [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html)\n",
        "        \n",
        "```python\n",
        "# Use Pandas ewma() to calculate Weighted Moving Average of ts_log\n",
        "exp_rolmean = ts.ewm(halflife = 2).mean()\n",
        "data_minus_exp_rolmean = ts - exp_rolmean\n",
        "\n",
        "```\n",
        "\n",
        "- **Differencing**\n",
        "    - Common way dealing with both trends and seasonality is differencing.\n",
        "    - Take the difference between one instant and the previous instant (1-period /first order lag). # of time periods lag = the 'order' of diff. First, second, third, etc. \n",
        "    \n",
        "```python\n",
        "data_diff = data.diff(periods=365)\n",
        "```\n",
        "\n",
        "### Time Series Decomposition\n",
        "- Turns a time series into multiple different time series. Most often in 3 parts:\n",
        "    1. Seasonal \n",
        "    2. Trend\n",
        "    3. Random (noise/irregular/remainder/residuals)\n",
        "    \n",
        "- Must pick between addititve or multiplicative decomposition:\n",
        "    - Must analzye time series to help decide:\n",
        "        - Does the magnitude of seasonality increase or decrease when the time series increases?\n",
        "    - Statsmodels has seasonal_decompose function. \n",
        "\n",
        "```python\n",
        "# import seasonal_decompose\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "decomposition = seasonal_decompose(np.log(ts))\n",
        "\n",
        "# Gather the trend, seasonality and noise of decomposed object\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "# Plot gathered statistics\n",
        " plt.plot(np.log(ts), label='Original', color=\"blue\")\n",
        "plt.plot(trend, label='Trend', color=\"blue\")\n",
        "plt.plot(seasonal,label='Seasonality', color=\"blue\")\n",
        "plt.plot(residual, label='Residuals', color=\"blue\")\n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/6dh8ogkytzjreky/index_4_0.png?raw=1\" width=500>\n",
        "\n",
        "\n",
        "- Article on [decomposing time series](https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/)\n",
        "\n",
        "\n",
        "### Section 25 Recap\n",
        "The key takeaways from this section include:\n",
        "* When you import time series data into Pandas, make sure to use the time/date information as index values using either a Pandas Timestamp or Python DateTime data type\n",
        "* There are a range of built in functions in Pandas for easily downsampling or upsampling time series data\n",
        "* Line plots and dot plots can be useful for getting a sense of how a time series data set has changed over time\n",
        "* Histograms and density plots can be useful for getting a sense of the time independent distribution of a time series data set\n",
        "* Box and whisker plots per year (or other seasonality period - day, week, month, etc) can be a great way to easily see trends in the distribution of time series data over time\n",
        "* Heat maps can also be useful for comparing changes of time series data across a couple of dimensions. For example, with months on one axis and years on another they can be a great way to see both seasonality and year on year trends\n",
        "* A time series is said to be stationary if its statistical properties such as mean and variance remain constant over time\n",
        "* Most time series models work on the assumption that the time series are stationary (assumption of homoscedasticity)\n",
        "* Many time series data sets *do* have trends, violating the assumption of homoscedasticity\n",
        "* Common examples are trends include linear (straight line over time), exponential and periodic. Some data sets also have increasing (or decreasing) variance over time\n",
        "* Any given data set may exhibit multiple trends (e.g. linear, periodic and reduction in variance)\n",
        "* Rolling statistics can be used to test for trends to see whether the centrality and/or dispersion of the data set changes over time\n",
        "* The Dickey Fuller Test is a common test for determining whether a data set contains trends\n",
        "* Common approaches for removing trends and seasonality include taking a log transform,. subtracting the rolling mean and differencing\n",
        "* Decomposing allows you to separately view seasonality (which could be daily, weekly, annual, etc), trend and \"random\" which is the variability in the data set after removing the effects of the seasonality and trend\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "V96juU_9NarQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Time Series Models\n",
        "- Note: for almost all models you need to make time series stationary first.\n",
        "### White Noise Model\n",
        "- The white noise model has three properties:\n",
        "    - Fixed and constant mean\n",
        "    - Fixed and constant variance\n",
        "    - No correlation over time \n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/jk1pf891qfs2l4d/index_10_0.png?raw=1\" width=400>\n",
        "    \n",
        "- Special case is Gaussian White Noise\n",
        "    - Constant mean = 0\n",
        "    - Constant variance =1\n",
        "- [Article on white noise series in python](https://machinelearningmastery.com/white-noise-time-series-python/)\n",
        "\n",
        "### Random walk model\n",
        "- Very common in finance (i.e. exchange rates) \n",
        "    - Tomorrow's rate is heavily influenced by today's\n",
        "- Contrary to the white noise model, random walk has:\n",
        "    - No specific mean or variance.\n",
        "    - A strong dependence over time. \n",
        "\n",
        "- the changes over time are basically a white noise model \n",
        "\n",
        "$$Y_t = Y_{t-1} + \\epsilon_t$$\n",
        "where $\\epsilon_t$ is a *mean zero* white noise model!\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/cnlyxoos54ztlbx/index_12_0.png?raw=1\" width=400>\n",
        "\n",
        "\n",
        "#### Random Walk with a drift\n",
        "- The drift (c) steers the model in a certain direction.\n",
        "$$Y_t = c+ Y_{t-1} + \\epsilon_t$$\n",
        "\n",
        "\n",
        "### Correlation & Autocorrelation\n",
        "\n",
        "- [Article: \"A Gentle Introduction to Autocorrelation and Partial Autocorrelations\"](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/\n",
        ")\n",
        "#### Autocorrelation Function (ACF)\n",
        "- Autocorrelation exmaines a time series against itself over increasing values of lag.\n",
        "- Pandas has autocorrelation_plot\n",
        "\n",
        "```\n",
        "pd.plotting.autocorrelation_plot(diet)\n",
        "```\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/e2uknvwydcijqnl/index_33_0%20%282%29.png?raw=1\" width=500 >\n",
        "\n",
        "- Same data, but after removing trends with differencing:\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/88u9r2cvnqrob2n/index_37_1.png?raw=1\" width=500>\n",
        "\n",
        "- Can also plot with statsmodels:.\n",
        "```python\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "plot_acf(diet, lags = 100);\n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/33llhqo96t8sh3j/index_45_0.png?raw=1\" width=500>\n",
        "#### Partial Autocorrelation Function (PACF)\n",
        "\n",
        "- Similar to ACF, but it controls for values at shorter labs (which ACF does not).\n",
        "    - \"Summary of tge relationship between a time series element and observations at a lab, _with the relationships of intervening observations removed_.\"\n",
        "    - Can be interpreted as a regression of the series against its PAST lags. \n",
        "    - Can use to help pick what order of ARF to use in modeling.\n",
        "\n",
        "Plotted from statsmodels tsaplots:\n",
        "\n",
        "```python\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from matplotlib.pylab import rcParams\n",
        "plot_pacf(diet, lags = 100);\n",
        "\n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/cr7p0o3prwnmqrs/index_42_0.png?raw=1\" width=500>"
      ]
    },
    {
      "metadata": {
        "id": "hVHH24Z9IthJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ARMA Models\n",
        "- Combination of Autoregressive (AR) model and Moving Average (MA) model.\n",
        "    - AR: $Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$\n",
        "    - MA: $Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$\n",
        "\n",
        "#### The Autoregressive Model\n",
        "- A value from a time series is regressed on preivous values from same time series.\n",
        "\n",
        "$$ \\text{Today = constant + slope} \\times \\text{yesterday + noise} $$\n",
        "\n",
        "Or, mathematically:\n",
        "$$Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$$\n",
        "\n",
        "$\\phi$ is slope. \n",
        "\n",
        "\n",
        "- Notes on this formula:\n",
        "    - If the slope is 0, the ts is a white noise model with mean $\\mu$\n",
        "    - If slope is not 0, the ts is autocorrelated.\n",
        "    - Bigger slop means bigger autocorrelation\n",
        "    - Negative slope =  time series follows oscillatory process. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VzZ0jE6_hdSI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### AR Model Time Series (at varying $\\phi$)\n",
        "**AR time series:**\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/k9mnam1wv4eltp2/AR_model.png?raw=1\" width =500>\n",
        "\n",
        "**AR series' ACF:**\n",
        "\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/5ucfnsrlxjev7k8/AR_ACF.png?raw=1\" width =500>\n",
        "> The oscillatory process of the time series with $\\phi=0.9$ is clearly reflected in the autocorrelation function, returning an oscillatory autocorrelation function as well. $\\phi=0.2$ leads to a very low, insignificant,  autocorrelation. $\\phi=0.8$ leads to a strong autocorrelation for the first few lags, and then incurs a steep decline. Having a $\\phi=1.02$ (just slightly bigger than 1) leads to strong and longlasting autocorrelation.\n",
        "\n",
        "\n",
        "**AR series' PACF:**\n",
        "\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/joazuyts1xmqhzh/AR_PACF.png?raw=1\" width=500>\n",
        "\n",
        "\n",
        "> For each of these PACFs, we notice a high value for 1 lag, then autocorrelations of 0, except for the second one. This is no big surprise, as the slope parameter is fairly small, so the relationship between a value and the next one is fairly limited."
      ]
    },
    {
      "metadata": {
        "id": "2Z4XoRF0i8wj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The Moving Average Model\n",
        "- The weighted sum of today's and yesterday's noise \n",
        "\n",
        "$$ \\text{Today = Mean + Noise + Slope} \\times \\text{yesterday's noise} $$\n",
        "\n",
        "Or, mathematically:\n",
        "$$Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$$\n",
        "\n",
        "- Some notes based on this formula:\n",
        "    - If the slope is 0, the time series is a white noise model with mean $\\mu$\n",
        "    - If the slope is not 0, the time series is autocorrelated and depends on the previous white noise process\n",
        "    - Bigger slope means bigger autocorrelation\n",
        "    - When there is a negative slope, the time series follow an oscillatory process\n",
        "\n",
        "##### MA Model Time Series (at varying $\\phi$)\n",
        "**MA time series:**\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/ic7uzmgtuhdoqu4/MA_model.png?raw=1\"  width=500>\n",
        "\n",
        ">When there is a posivite $\\theta$ there is a certain persistence in level, meaning that each observation is generally close to its neighbors. This is more pronounced for higher . values of $\\theta$. MA series with negative coefficients, however, show oscillatory patterns. Recall that when $\\theta=0$, the process is a true White Noise Process! \n",
        "\n",
        "\n",
        "**MA ACF:**\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/fv7sryfxyazve82/MA_ACF.png?raw=1\" width=500>\n",
        "\n",
        "> MA processes have autocorrelations, but because of the structure of the MA formula (regressing it on the noise term of the previous observation) there is **only a dependence for one period, and the autocorrelation is zero for lags 2 and higher.**\n",
        "\n",
        "> If $\\theta >0$ the lag one autocorrelation is positive, if $\\theta <0$ the lag one autocorrelation is negative.\n",
        "\n",
        "\n",
        "**MA PACF:**\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/fsijauyvae9hj2v/MA_PACF.png?raw=1\" width=500>\n",
        "\n",
        "> Typically a strong correlation with the 1-period lag (strength depending in theta), and then the PACF gradually tails off. "
      ]
    },
    {
      "metadata": {
        "id": "yWGCsXhQkVlP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Higher Order AR(p) and MA(q) Models \n",
        "- First order:\n",
        "    - AR: $Y_t = \\mu + \\phi * Y_{t-1}+\\epsilon_t$\n",
        "    - MA: $Y_t = \\mu +\\epsilon_t + \\theta * \\epsilon_{t-1}$\n",
        "- Second order:\n",
        "    - AR(2): $Y_t = \\mu + \\phi_1 * Y_{t-1}+\\phi_2 * Y_{t-2}+\\epsilon_t$\n",
        "    - MA(2): $Y_t = \\mu +\\epsilon_t + \\theta_1 * \\epsilon_{t-1}+ \\theta_2 * \\epsilon_{t-2}$\n",
        "\n",
        "\n",
        "- AR(p):\n",
        "    - ACF for AR(p) would be strong until lag of p, then stagnant, then trail off. \n",
        "    - PACF for AR(p): Generally no correlation for lag values beyond p.\n",
        "- MA(q):\n",
        "    - ACF for MA(q) would show strong correlation up to a lag of q, the immedately delcine to minimal/no correction.\n",
        "    - PACF would show strong relationship to the lab and tailing off to no correlation afterwards.\n",
        "    \n",
        "    \n",
        "### ARMA Models:\n",
        "- In an ARMA model, is a regression on paste values (AR part) and the error term is modeled as a linear combo of error terms in the recent past (MA part). \n",
        "- Notation is generally ARMA(p,q)\n",
        "    - Example: ARMA(2,1) model equation\n",
        "     $$Y_t = \\mu + \\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+ \\theta \\epsilon_{t-1}+\\epsilon_t$$\n",
        "\n",
        "| | AR(p)   |   MA(q)  | ARMA(p,q)|\n",
        "|------|------|------|------|\n",
        "|   ACF | Tails off   |  Cuts off after lag q |  Tails off   |\n",
        "|   PACF | Cuts off after lag p  |   Tails off  |  Tails off  |\n",
        "\n",
        "\n",
        " #### General process when modeling with a time series:\n",
        "\n",
        "- Detrend your time series using differencing. ARMA models represent stationary processes, so we have to make sure there are no trends in our time series\n",
        "- Look at ACF and PACF of the time series\n",
        "- Decide on the AR, MA and order of these models\n",
        "- Fit the model to get the correct parameters and use for prediction\n",
        "\n",
        "\n",
        "[Additional Information on ARMA can be found here  in lessons 1 and 2.](https://newonlinecourses.science.psu.edu/stat510/node/41/)\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "uVcxyBkymKe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### sARIMA Models [TBD]\n",
        "- Integrated ARMA models. "
      ]
    },
    {
      "metadata": {
        "id": "eFY0lj9Um_MR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "4B9BvEY_m_nY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Section 26: Key Takeaways\n",
        "\n",
        "The key takeaways from this section include:\n",
        "* A White Noise model has a fixed and constant mean and variance, and no correlation over time\n",
        "* A Random Walk model has no specified mean or variance, but has a strong dependance over time\n",
        "* The Pandas `corr()` function can be used to return the correlation between various time series data sets\n",
        "* Autocorrelation allows us to identify how strongly each time serties observation is related to previous observations\n",
        "*  The autocorrelation function (ACF) is a function that represents autocorrelation of a time series as a function of the time lag\n",
        "* The Partial Autocorrelation Function (or PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags\n",
        "* ARMA (AutoRegressive and Moving Average) modeling is a tool for forecasting time series values by regressing the variable on its own lagged (past) values\n",
        "* ARMA models assume that you've already detrended your data and that there is no seasonality\n",
        "* ARIMA (Integrated ARMA) models allow for detrending as part of the modeling process and work well for data sets with trends but no seasonality\n",
        "* SARIMA (Seasonal ARIMA) models allow for both detrending and seasonality as part of the modeling process\n",
        "* Fracebook Prophet enables data analysts and developers alike to perform forecasting at scale in Python\n",
        "* Prophet uses Additive Synthesis for time series forecasting\n"
      ]
    },
    {
      "metadata": {
        "id": "_L67aVcrnFEw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distance Metrics & k-Nearest Neighbors\n",
        "### Distance Metrics:\n",
        "Distance helps us quantity similarity.\n",
        "Distance can be measured in different metrics.\n",
        "1. Manhattan Distance\n",
        "    - Movement by X/Y blocks.\n",
        "    - $d(x,y) =  \\sum_{k=1}^n |x_k - y_k|$\n",
        "        \n",
        "    <img src=\"https://www.dropbox.com/s/0q217qlbc9xtb7t/manhattan-distance.png?raw=1\" width=200>\n",
        "2. Euclidian/Pythagorean Distance\n",
        "    - Straight line (as-the-bird flies)\n",
        "    - $d(x,y) = \\sqrt{ \\sum_{k=1}^n  (x_k - y_k)^2)}$\n",
        "    \n",
        "    <img src=\"https://www.dropbox.com/s/h3ogtkukgp6pwin/euclidean-distance.png?raw=1\" width=250>\n",
        "    \n",
        "3. Minkowski distance\n",
        "    - Generalized distance metric across a _Normed Vector Space_. \n",
        "        - Meaning each point has been through the same function.  Can be any function as long as:\n",
        "            - A zero vector(just a vecotr of zeros) will output length=0\n",
        "            - Every other vector has positive length.\n",
        "        - Both Manhattan and Euclidian are actually special cases of Minkowski\n",
        "    - $d(p,q) = (\\sum_{i=1}^n (|p_i - q_i|)^c)^{1/c}$\n",
        "    \n",
        "    \n",
        "    \n",
        "```python \n",
        "# Manhattan Distance is the sum of all side lengths to the first power\n",
        "manhattan_distance = (length_side_1 + length_side2 + ... length_side_n)**1  \n",
        "\n",
        "# Euclidean Distance is the square root of the sum of all side lengths to the second power\n",
        "euclidean_distance = np.sqrt((length_side_1 + length_side2 + ... length_side_n)*2)\n",
        "\n",
        "# Minkowski Distance with a value of 3 would be the cube root of the sum of all side lengths to the third power\n",
        "minkowski_distance_3 = np.cbrt((length_side_1 + length_side2 + ... length_side_n)**3)\n",
        "\n",
        "# Minkowski Distance with a value of 5\n",
        "mink_distance_5 = np.power((length_side_1 + length_side2 + ... length_side_n)**5, 1./5)\n",
        "```\n",
        "\n",
        "\n",
        "### K-Nearest Neighbors (KNN)\n",
        "<img src=\"https://www.dropbox.com/s/77747858h369yzx/knn.gif?raw=1\" width=500>\n",
        "- **KNN is a supervised learning algorithm that can be used for both classification and regression.**\n",
        "    - Distance-based, looks for the smaller distance between 2 points to identify similarity. \n",
        "        - Each column acts as a dimension. \n",
        "        - Can use any of the distance metrics discussed\n",
        "    - since its supervised, must give it labeled training data. \n",
        "    \n",
        "- **Fitting**\n",
        "    - KNN does very little during the fit step, just stores the data and labels.\n",
        "- **Predicting**\n",
        "    - For each point, KNN calculates the distances to _every single point_ int he training set. \n",
        "    - It then finds the ```k``` closest neighbors, and examines their labels.\n",
        "        - its 'democratic', in that each of the nearest points submits a vote as to which group it should belong to.\n",
        "        - the group with the largest # of votes win. \n",
        "- **Evaluating Model Performance**\n",
        "    - Evaluation is different depending on if using for classification or regression task.\n",
        "    - Need a test set of data to compare its predicitons against to calc:\n",
        "        - Precision\n",
        "        - Recall\n",
        "        - Accuracy\n",
        "        - F1-Score"
      ]
    },
    {
      "metadata": {
        "id": "fagDue4O1_gC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrices - to Evaluate Classification\n",
        "For Example, using simply binary classification 0 or 1. \n",
        "<img src=\"https://www.dropbox.com/s/1kt3vniy7h1vodw/rf-conf-matrix.png?raw=1\" width=300>\n",
        "\n",
        "    \n",
        "- **Confusion Matrices tell us 4 things:**\n",
        "    - True Positives (TP): The model predicted the person has the disease (1), and they actually have the disease (1).\n",
        "\n",
        "    - True Negatives (TN): The model predicted the person is healthy (0), and they are actually healthy (0).\n",
        "\n",
        "    - False Positives (FP): The model predicted the person has the disease (1), but they are actually healthy (0). \n",
        "\n",
        "    - False Negatives (FN): The model predicted the person is healthy (0), but they actually have the disease (1).\n",
        "\n",
        "- **To construct a confusion matrix, we need:**\n",
        "    -  Predicitons for each data point in training or test set\n",
        "    - Labels for same data points in that test set.\n",
        "    \n",
        "- To create a Confusion Matrix from scratch, we:\n",
        "    1. Iterate through both lists and grab the item at the same the label and corresponding prediction.  \n",
        "        - Note that `enumerate` is great here, since it gives us both an item and the index of that item from a list. \n",
        "    2. Use some control flow to determine if its a TP, TN, FP, or FN. \n",
        "    3. Store our results in a dictionary or 2-dimensional array. \n",
        "    4. Return our results once we've checked every prediction against its corresponding label. \n",
        "    \n",
        "```python\n",
        "def confusion_matrix(labels, predictions):\n",
        "    conf_matrix = {\"TP\": 0, \"FP\": 0, \"TN\": 0, \"FN\": 0}\n",
        "    for ind, label in enumerate(labels):\n",
        "        pred = predictions[ind]\n",
        "        if label == 1:\n",
        "            # CASE: True Positive\n",
        "            if label == pred:\n",
        "                conf_matrix['TP'] += 1\n",
        "            # CASE: False Negative \n",
        "            else:\n",
        "                conf_matrix['FN'] += 1\n",
        "        else:\n",
        "            # CASE: True Negative\n",
        "            if label == pred:\n",
        "                conf_matrix['TN'] += 1\n",
        "            # CASE: False Positive\n",
        "            else:\n",
        "                conf_matrix['FP'] += 1\n",
        "    \n",
        "    return conf_matrix\n",
        "```\n",
        "\n",
        "- **Confusion Matrices for Multi-Categorical Classificaitons:**\n",
        "    - Diagonal represents true positives\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/qgy3t90fyxztjni/cm2.png?raw=1\" width=400>\n",
        "\n",
        "\n",
        "#### Confusion Matrices with sklearn\n",
        "- A nice positive of sklearn's implementation:\n",
        "    - it automatically adjusts to the# of categories present in the labels.\n",
        "    \n",
        "```python\n",
        "# Calcualate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cf = confusion_matrix(example_labels, example_preds)\n",
        "\n",
        "# Plot confusion matrix with matplotlib\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "def show_cf(y_true, y_pred, class_names=None, model_name=None):\n",
        "    cf = confusion_matrix(y_true, y_pred)\n",
        "    plt.imshow(cf, cmap=plt.cm.Blues)\n",
        "    \n",
        "    if model_name:\n",
        "        plt.title(\"Confusion Matrix: {}\".format(model_name))\n",
        "    else:\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    \n",
        "    class_names = set(y_true)\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    if class_names:\n",
        "        plt.xticks(tick_marks, class_names)\n",
        "        plt.yticks(tick_marks, class_names)\n",
        "    \n",
        "    thresh = cf.max() / 2.\n",
        "    \n",
        "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
        "        plt.text(j, i, cf[i, j], horizontalalignment='center', color='white' if cf[i, j] > thresh else 'black')\n",
        "\n",
        "    plt.colorbar()\n",
        "\n",
        "show_cf(example_labels, example_preds)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nKjAFwz12Oeb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics\n",
        "- **Precision**\n",
        "$$Precision = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}}$$\n",
        "\n",
        "- **Recall**\n",
        "$$Recall = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}}$$ \n",
        "\n",
        " Precision and Recall have an inverse relationship.  As our recall goes up, our precision will go down, and vice versa. If this doesn't seem intuitive, let's examine this.\n",
        " \n",
        "<img src=\"https://www.dropbox.com/s/p7yy1t34lx9k82j/Precisionrecall.png?raw=1\" width=400>\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/ij75yic63m32x5z/performance-comparisons.png?raw=1\" width =400>\n",
        "\n",
        "\n",
        "- **Accuracy**\n",
        "\n",
        "$$Accuracy = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}}$$\n",
        "\n",
        "- **F-1 Score**\n",
        "\n",
        "$$F1-Score = 2\\ \\frac{Precision\\ x\\ Recall}{Precision + Recall}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "RqNKY67U2RiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}