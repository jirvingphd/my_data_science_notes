{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My Flatiron Bootcamp Notes - Mod 1 & 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cn1OSOHfw3IF",
        "o-k1Ccyxw3IG",
        "zC6EHN0Tw3II",
        "jhAy_v9uw3IJ",
        "y5Gy431nw3IK",
        "pftDkY-Dw3IL",
        "b5TGEzlDw3IM",
        "p-ehdf4Tw3IN",
        "_UOFVo8tw3IO",
        "mrf7MwCxw3IP",
        "5kFGfU5Ww3IR",
        "tjWBMjYPw3IR",
        "jHB8gF-Qw3IT",
        "ikNZptfLw3IU",
        "z_ubqwvbw3IW",
        "tRJOMZpjw3IW",
        "rPAYDUHkw3IX",
        "ydclwM1Yw3IX",
        "2yqWh1lBw3IY",
        "-eVvlckzw3IZ",
        "90uxhG0jw3IZ",
        "t4afuY15w3Ia",
        "LbEnK7DMw3Ib",
        "LBdDjOWJw3Ic",
        "R4xed8CZw3Ic",
        "cvpxcVhWw3Id",
        "hdzJUmM7w3Id",
        "YyPLU2fow3Ie",
        "rNLT8dc0w3If",
        "I8np5K5-w3Ik",
        "rhPYaRHLw3Il",
        "k64fB1ERw3Il",
        "dqBG210rw3Iq",
        "kfcCbLb7w3It",
        "CnuN9U_Dw3Iw",
        "XtsXDMrHw3Iw",
        "NbrX3dQtw3Ix",
        "xPqhsqWpw3Iy",
        "-G7_Rvf_w3Iz",
        "vZXrNZA_w3I3",
        "czs6nSt4w3I6",
        "z6YFE_xCw3I7",
        "8mzckl1uw3I9",
        "NHvNraTZw3I9",
        "o7U20CLWw3I-",
        "Fd5Spg6Iw3JB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jirvingphd/my_data_science_notes/blob/master/My_Flatiron_Bootcamp_Notes_Mod_1_%26_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2XheM8K-w3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.dropbox.com/s/fchpltm5rnwd5ce/Flatiron%20Logo%202Wordmark.png?raw=1\" width=100 >\n",
        "\n",
        "# My Flatiron Bootcap Notes - Mod 1 & 2\n",
        "- James M. Irving, Ph.D.\n",
        "- james.irving.phd@gmail.com\n",
        "- Repo: https://github.com/jirvingphd/my_data_science_notes \n",
        "- Next Notebook:\n",
        "    - [My Flatiron Bootcamp Notebook - Mod 3.ipynb](https://colab.research.google.com/drive/1DE6VT590W3xlZGXVf0Vye14stdBMddPd)\n"
      ]
    },
    {
      "metadata": {
        "id": "OioV1NqGw3H9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting started \n",
        "\n",
        "### Git Bash Terminal\n",
        "* Launch Git Bash on Windows\n",
        "    * Can right click inside a folder in Windows and select GitBash to start in current folder\n",
        "```python      \n",
        "      source activate learn-env # Make sure to use learn-env \n",
        "```\n",
        "* [!] New Conda Warning / Updating Your Learn-Env Packages\n",
        "   * If you see a message that states “WARNING: A newer version of conda exists” run :\n",
        "```python\n",
        "    conda update -n base conda # and then try again to create the environment using:\n",
        "    conda env create -f environment.yml.\n",
        "```\n",
        "#### [!] if Jupyter Notebook doesn’t have the Learn-env kernel as an option:\n",
        "```bash\n",
        " python -m ipykernel install --user --name=learn-env\n",
        "```\n",
        "#### General terminal commands\n",
        "\n",
        "cd d: # change to d drive before calling folders\n",
        "cd('D:/Users/My Name/My Flatiron Files') # in quote\n",
        "cd .. # move up one level \n",
        "\n",
        "ls # list folders in current directory\n",
        "pwd # print working directory\n",
        "mkdir #new folder\t\t\n",
        "\n",
        "Ctrl + C # to interrupt kernel\n",
        "Ctrl + Shift + Insert # to paste\n",
        "\n",
        "Up Arrow / Down Arrow # cycles through previous commands \n",
        "        \n",
        "#### Cloning Git, Loading Jupyter Notebook\n",
        "```bash\n",
        "source activate learn-env #gitbash\n",
        "git clone <URL> # control+shift+insert to paste\n",
        "cd(''D:/Users/My Name/My Flatiron Files'/new-cloned-git-learn-lesson/) \n",
        "\n",
        "jupyter notebook #launches notebook in current dir         \n",
        "```\n",
        "- Click on index.ipnb # Lessons are containeed in index.ipnb*\n",
        "- Click Kernel > Change Kernel > learn-env\n",
        "    \n",
        "#### Pushing notebooks back to git\n",
        "git add .\n",
        "git commit -m \"Comments go here\"\n",
        "git push       \n",
        "\n",
        "### Jupyter Notebook Hotkeys & Mouse Tricks\n",
        "\n",
        "* Shift + Tab # inside method/function () for help\n",
        "\n",
        "* % matplotlib inline #for graphs in notebook\n",
        "\n",
        "* ctrl+/  # comment / uncomment selection\n",
        "* shift + enter  #run cell, select below.\n",
        "* ctrl + enter # run cell.\n",
        "* alt + enter #run cell, insert below.\n",
        "  \n",
        "* A # insert cell above.\n",
        "* B # insert cell below.\n",
        "\n",
        "* C # copy cell.\n",
        "* V # paste cell.\n",
        "\n",
        "* X # delete selected cell.\n",
        "* Y # change cell to code\n",
        "* M # change cell to markdown\n",
        "\n",
        "* Ctrl +Click # create multiple cursors at once (edit simultaneously)\n",
        "\n",
        "#### [!] if Jupyter Notebook doesn't have the Learn-env kernel as an option:\n",
        "```python\n",
        "         *python -m ipykernel install --user --name=learn-env*\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Z7xlg-kzw3H-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## BASIC PYTHON FUNCTIONS/METHODS/INDEXING\n",
        "```python\n",
        "\tlen(), type()\n",
        "    var+=1 # can add / sub \n",
        "\tset(list) # returns unique values\n",
        "\tlist(range(0,len(variable))) # create numerical index for variable length\n",
        "\tround(result,num_decimals) # Display only 2 decimal places\n",
        "```\n",
        "### List Indexing:\n",
        "```python\n",
        "\t\tlist=['str','str']\n",
        "\t\tdata[0:5] # select data elements 1-4\n",
        "\t\tdata[5:] # select 5 to the end\n",
        "\t\tdata[0:end:2] #Select every other ek\n",
        "\t\tdata[-1] #last element\n",
        "```\n",
        "### List Methods \n",
        "```python\n",
        "    list.append()\n",
        "    list.pop()\n",
        "    list.extend() #joins 2 list\n",
        "    list.insert()\n",
        "    list.remove()\n",
        "    list.count()\n",
        "    \n",
        "    list.reverse()\n",
        "    list.sort() # doesn't return a value \n",
        "    s=sorted(list,key_func,reverse=True)\n",
        "    \n",
        "    filtered_list = filter(func_that_filters, orignal_long_list )\n",
        "```\n",
        "\n",
        "### String methods\n",
        "```python\n",
        "\n",
        "    str.upper()\n",
        "\tstr.lower()\n",
        "\tstr.capitalize() \n",
        "\tstr.title() \n",
        "\n",
        "\tstr.strip()\n",
        "\tstr.endswith(txt)\n",
        "\tstr.startswith(txt)\n",
        "\tstr.split('_')\n",
        "\tstr=f'This string references my {variable} named variable.'\n",
        "    \n",
        "     # Print vars inside of strings with f-string formatting\n",
        "    print(f'My str will have {variable_names} inserted into it.')\n",
        "```\n",
        "\n",
        "### Dictionary Indexing:\n",
        "```python\n",
        "    new_dict=dict()\n",
        "    ex_dict  = {'key1' : value1 , 'key2' : value2}\n",
        "    \n",
        "\tex_dict['key1'] [element_index]# returns element from value1\n",
        "    \n",
        "    key_to_add='Name'\n",
        "    ex_dict[key_to_add]= 2 \n",
        "    \n",
        "    ex_dict.keys() # returns all keys\n",
        "\tex_dict.values() # returns all values\n",
        "\tex_dict.items() # returns all items\n",
        "\n",
        "\tex_dict.get(var, value_if_DNE) #DNE=does not exist \n",
        "    \n",
        "```\n",
        "#### Ex: Updating a dictionary value (if it exists) by  looping through an iterable\n",
        "```python\n",
        "\t\twords=txt.split() # A long list of strings\n",
        "\t\tword_counts={} # Empty dictionary\n",
        "    \n",
        "        #Loop through words list \n",
        "\t\tfor word in words:\n",
        "\t\t\tword_counts[word] = word_counts.get(word, 0_ ) #dict.get(key, default_value)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "sJbyRo5uw3H_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Flow control (conditionals and loops)\n",
        "#### If, elif, else\n",
        "```python\n",
        "if <condition>:\n",
        "\t\tcode_to_run\n",
        "\telif other_condition:\n",
        "\t\tother_code_to_run\n",
        "\telse:\n",
        "\t\totherwise_run_code\n",
        "# Ends via indentation\n",
        "```    \n",
        "#### Conditional statement to chceck of variable exists inside of the list/iterable var \n",
        "\n",
        "##### try, except \n",
        "```python\n",
        "try:\n",
        "    df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "```\n",
        "#### For loops \n",
        "```python\n",
        "\tfor element in iterable:\n",
        "\t\t'run this code'\n",
        "\n",
        "\t*for key, value in exampl_dictionary.items()*\n",
        "\t\t'run this code'\n",
        "```\n",
        "#### While loops"
      ]
    },
    {
      "metadata": {
        "id": "YE2RYQUfw3IA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Defining functions\n",
        "```python\n",
        "\tdef function_name(parameters_in=default_value:  #can do (), but variables must already exist\n",
        "\t\tstr='run this code'\n",
        "\t\treturn value_to_send_back\n",
        "```\n",
        "\n",
        "### Lambda functions\n",
        "```python\n",
        "    df['column'] = df.column_to_operate_on.map(lambda x:  'N' in x)\n",
        "```\n",
        "### List Comprehensions\n",
        "..."
      ]
    },
    {
      "metadata": {
        "id": "51gIHKdIw3IB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GRAPHING WITH MATPLOTLIB\n",
        "```python\n",
        "    import matplotlib.pyplot as plt\n",
        "\t%matplotlib inline # onlu jupyter notebooks\n",
        "    \n",
        "\tplt.figure(figsize=(x,y))\n",
        "\n",
        "\tdata_to_graph.plot(kind='barh') # default is line\n",
        "```    \n",
        "   Can call plotting *functions:*  \n",
        "```python\n",
        "    plt.scatter(x,y)\n",
        "    plt.hist(x,bins=num)\n",
        "\n",
        "\tplt.title('Top 5 Lego Themes', fontsize=16) #fontsize is optional\n",
        "\tplt.xlabel('Number of Lego Sets') #you could also pass in fontsize if you wanted here\n",
        "\tplt.ylabel('Theme') #you could also rotate text if you wanted\n",
        "\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "```\n",
        "\n",
        "#### Matplotlib from lesson - two subplots:\n",
        "```python\n",
        "\t# Define a new figure with matplotlib's .plot() function. Set the size of figure space\n",
        "\tnew_figure = plt.figure(figsize=(10,4))\n",
        "\t# Add a subplot to the figure - a new axes\n",
        "\tax = new_figure.add_subplot(121)\n",
        "\t# Add a second subplot to the figure - a new axes\n",
        "\tax2 = new_figure.add_subplot(122)\n",
        "\t# Generate a line plot on first axes\n",
        "\tax.plot([1, 4, 6, 8], [10, 15, 27, 32], color='lightblue', linewidth=3, linestyle = '-.')\n",
        "\t# Draw a scatter plot on 2nd axes\n",
        "\tax2.scatter([0.5, 2.2, 4.2, 6.5], [21, 19, 9, 26], color='red', marker='o')\n",
        "\t# Set the limits of x and y for first axes\n",
        "\tax.set_xlim(0, 9), ax.set_ylim(5,35)\n",
        "\t# Set the limits of x and y for 2nd axes\n",
        "\tax2.set_xlim(0, 9), ax2.set_ylim(5,35)\n",
        "\t# Show the plot\n",
        "\tplt.show()\n",
        "\n",
        "```\n",
        "#### Matplotlib from lesson - inset subplot\n",
        "```python\n",
        "\t# Generate sample data \n",
        "\tx = np.linspace(0, 5, 11)\n",
        "\ty = x ** 3\n",
        "\n",
        "\t# Creates blank canvas\n",
        "\tfigure = plt.figure()\n",
        "\n",
        "\t# Add new axes to the figure with absolute positions\n",
        "\tax1 = figure.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "\tax2 = figure.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes\n",
        "\n",
        "\t# Larger Figure Axes 1\n",
        "\tax1.plot(x, y, color = 'blue', linestyle = '-.')\n",
        "\tax1.set_xlabel('X_label on axes1')\n",
        "\tax1.set_ylabel('Y_label on axes1')\n",
        "\tax1.set_title('Axes 1 Title')\n",
        "\n",
        "\t# Insert Figure Axes 2\n",
        "\tax2.plot(y, x, color = 'green', linestyle = '--')\n",
        "\tax2.set_xlabel('X_label on axes2')\n",
        "\tax2.set_ylabel('Y_label on axes2')\n",
        "\tax2.set_title('Axes 2 Title')\n",
        "\n",
        "\tplt.show()\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Vgd2G7rjw3IB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Stem & leaf plots\n",
        "\n",
        "The last major digit is convertd to category on x-axis, the ones-digits are then\n",
        "plotted as Y-values (cannot see multiple instances of same value)\n",
        "\n",
        "![](media/2a56e9788cee9b0d83f8b81a87a8ccb7.emf)\n",
        "```python\n",
        "Import matplotlib.pyplot as plt  \n",
        "%matplotlib inline  \n",
        "plt.style.use(‘ggplot’)  \n",
        "\\# Create a stem and leaf plot including the above styling\n",
        "plt.figure(figsize=(12,8))\n",
        "\\# markerline, stemlines, baseline =\n",
        "plt.stem(stems, leafs, '-.', 'o' )\n",
        "plt.title('Stem and Leaf Plot for Student Marks', fontsize = 30 )\n",
        "plt.ylabel('Leafs', fontsize = 20)\n",
        "plt.xlabel('Stems', fontsize = 20)\n",
        "plt.show()\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "XygYZ8uHw3ID",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### My Histograms from PDF lab\n",
        "\n",
        "```python\n",
        "fig2=plt.figure()\n",
        "male_df['Height'].plot(kind='hist',color='blue',edgecolor='pink',label='Male',density=True,alpha=0.7)\n",
        "\n",
        "female_df['Height'].plot(kind='hist',color='pink',edgecolor='blue',label='Female',density=True,alpha=0.7)\n",
        "\n",
        "plt.xlabel('Height (inches)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "\\# You code here\n",
        "x_male,y_male=density(male_df['Height'])\n",
        "plt.plot(x_male,y_male,':',color='cyan',linewidth=3)\n",
        "x_female,y_female=density(female_df['Height'])\n",
        "plt.plot(x_female,y_female,'--',color='magenta',linewidth=3)\n",
        "plt.show()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "cn1OSOHfw3IF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PANDAS AND DATAFRAMES\n",
        "```python\n",
        "\timport pandas as pd\n",
        "\tdataframe= pd.read_csv('filename.csv',header=1, encoding='latin-1',usecols=[1,2,3])\n",
        "\tdf=pd.read_excel('filename.xlsx',sheet_name='sheet name')\n",
        "\t\n",
        "\tworkbook = pd.ExcelFile('filename.xlsx')\n",
        "\tworkbook.sheet_names\n",
        "\tdf = workbook.parse(sheet_name=1)\n",
        "\n",
        "\tdf.to_csv('file.csv',index=False) #create csv file\n",
        "\tdf.to_excel() #excel \n",
        "\tdf.to_dict()\n",
        "```\n",
        "\n",
        "\n",
        "### Pandas methods and functions\n",
        "```python\n",
        "\tdf.head() # display first few rows ; can do df.column.head()\n",
        "\tdf.tail()\n",
        "\tdf.info() #\n",
        "\tdf.shape() # rows and columns-\n",
        "\tdf.describe() # quick statistics for all of dataframe\n",
        "\tdf.dtypes()\n",
        "\tdf.index()\n",
        "\tdf.columns()\n",
        "\tdf.drop() \n",
        "\tdf.set_index('column')\n",
        "\tdf.reset_index()\n",
        "```\n",
        "#### Dataframe Indexing  \n",
        "```python\n",
        "# For series/column\n",
        "    df['col_ name'] # OR:\n",
        "    df.col_Name\n",
        "# For rows ..?\n",
        "    # []TBD!\n",
        "# Index data by position .iloc[ ]\n",
        "\tdf.iloc[row_idx_start : row_idx_exclusive, col_idx_start: col_idx_end] # slice row row_idx\n",
        "# Index data using .loc[]: \n",
        "    # Index based upon their labels (row index and column name)\n",
        "        df.loc[row1:rowEnd,'column_name' ]     \n",
        "    # Index based upon conditional (boolean) statements\n",
        "        df.loc[df['col_to_test'] < condition1 ]\n",
        "        singe_col_filtered = df.loc[df['col_to_test'] < condition1, ['column_name']]\n",
        "    # Index based upon two conditionals\n",
        "        df.loc[(df[\"col_to_test1\"] == condition1) & (df[\"col_to_test2\"]== condition2)]\n",
        "    # Changing values via .loc indexing\n",
        "        df.loc[df[\"color_intensity\"]>10, \"color_intensity\"] = 10\n",
        "    # Changing values if contain string\n",
        "        df.loc[df[\"Home Team Name\"].str.contains('Korea'), \"Home Team Name\" ]        \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "o-k1Ccyxw3IG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Useful pandas series methods:\n",
        "```python\n",
        "    df.col_name.value_counts() #[0:5]\n",
        "    df.col_name.astype()\n",
        "    series.mean() #Changing notation here: series refers to df.col_name (which is a series)!\n",
        "    series.median()\n",
        "    series.min()\n",
        "    series.max()\n",
        "    series.std()\n",
        "    series.unique()\n",
        "    series.nunique()\n",
        "    series.sample()\n",
        "    series.sort_values()\n",
        "    series.hist()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "zC6EHN0Tw3II",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Examples: using pandas \n",
        "##### Ex from lesson: conditional indexing\n",
        "```python\n",
        "    # Index based upon an  3 variables, var1/cond1 & (var2/cond2 | var3/cond3)} # / just means var+ condition \n",
        "\tUSA_home_and_away = df[(df.Year==2014)  & ((df['Home Team Name'] == 'USA') | (df['Away Team Name']=='USA'))\n",
        "```\n",
        "##### Ex from lesson: operating on dataframes (change names, cols)\n",
        "```python                           \n",
        "    # Drop a column of the df\n",
        "    df = df.drop('C/A', axis=1) #drop the COLUMN(axis=1) 'C/A'\n",
        "\n",
        "    # Rename columns\n",
        "    df = df.rename(columns={'DATE' : 'date'})\n",
        "\t\t\n",
        "    # Operate on columns names\n",
        "    new_cols = [col.lower() for col in df.columns]                       \n",
        "    df.columns = [my_function(col) for col in df.columns] \n",
        "```\n",
        "##### Ex from lessons: using datetime type \n",
        "```python\n",
        "    df.DATE = pd.to_datetime(df.DATE, format='%m/%d/%Y') # convert dates to datetime type\n",
        "    df.DATE.dt.day_name() #dt.day_name\n",
        "    df['Dayofweek'] = df.DATE.dt.dayofweek \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "jhAy_v9uw3IJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Groupby \n",
        "```python \n",
        "grouped = df.groupby('Dayofweek').sum()\n",
        "grouped.plot(kind='barh')\n",
        " # HMmm weird\n",
        "df['Num_Lines'] = df.LINENAME.map(lambda x: len(x))\n",
        "```\n",
        "#### Dataframe statistics methods\n",
        " (.mean(), .std(), .count(), .sum(), .mean(), .median(), .std(), .var() and .quantile())"
      ]
    },
    {
      "metadata": {
        "id": "y5Gy431nw3IK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Map/apply to operate on data frames\n",
        "```python\n",
        "df[‘column’].map(lambda x: len(x.split()).head()\n",
        "#LAMBDA + MAP FUNCTIONS WITH CONDITIONALS\n",
        "df['text'].map(\n",
        "    lambda x: 'Good' if any([word in x.lower() for word in ['awesome', 'love', 'great']]) else 'Bad').head()\n",
        " ```\n",
        " #### Using .applymap()\n",
        "```python\n",
        "string_df=df.applymap(lambda x: str(x))\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "pftDkY-Dw3IL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## HOW TO: cleaning a dataset and checking for missing values\n",
        "```python\n",
        "\tprint('   HEROES_DF INFORMATION:\\n')\n",
        "\tprint(heroes_df.info())\n",
        "\tprint('\\n')\n",
        "\t# print('heroes_df value counts (check for redundancy):')\n",
        "\t# print(heroes_df['name'].value_counts()[0:10])\n",
        "\t# print('\\n\\n')\n",
        "\n",
        "\tprint(f'NaN values in data? \\n {heroes_df.isna().any().any()}\\n')\n",
        "\n",
        "\t# print('heroes_df names - Number of Redundant:'.upper())\n",
        "\t# print(f'Num unique names: {len(heroes_df.name.unique())}')\n",
        "\t# print(f'Num of repeated names: {len(heroes_df.name)-len(heroes_df.name.unique())}')\n",
        "\t# print('\\n')\n",
        "\n",
        "\tprint('heroes_df -  Missing Publisher values:'.upper())\n",
        "\t#print(f'Num unique: {len(heroes_df.Publisher.unique())}')\n",
        "\tprint(f'Num missing: {heroes_df.Publisher.isna().sum()} out of {len(heroes_df.Publisher)}, ({round((heroes_df.Publisher.isna().sum() /len(heroes_df.Publisher) * 100),2) }%)')\n",
        "\t# print(f'{heroes_df.Publisher.isna().sum()/len(heroes_df.Publisher)*100}%')\n",
        "\tprint('\\n')\n",
        "\n",
        "\tprint('heroes_df - Missing Weight values:'.upper())\n",
        "\t# print(f'Num missing: {heroes_df.Weight.isna().sum()}')\n",
        "\tprint(f'Num missing: {heroes_df.Weight.isna().sum()} out of {len(heroes_df.Weight)}, ({round((heroes_df.Weight.isna().sum() /len(heroes_df.Weight) * 100),2) }%)')\n",
        "\tprint('\\n')\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "b5TGEzlDw3IM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## SQL (sect 05)\n",
        "\n",
        "### Using sqlite3 with SQL databases\n",
        "```python\n",
        "import sqlite3\n",
        "connection = sqlite3.connect('pet_database.db') # Creates pet_database, but empty until create a table    \n",
        "cursor = connection.cursor()\n",
        "\n",
        "# use the corsor to execute sql commands\n",
        "cursor.execute(''' \n",
        "CREATE TABLE cats (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    age INTEGER,\n",
        "    breed TEXT\n",
        ")\n",
        "''')\n",
        "\n",
        "# Insert into table\n",
        "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES ('Maru', 3, 'Scottish Fold');''')\n",
        "# Select from table\n",
        "cursor.execute('''SELECT name FROM cats;''').fetchall()\n",
        "\n",
        "# Select only distinct entries\n",
        "cursor.execute('''SELECT DISTINCT name FROM cats;''').fetchall()\n",
        "# Selecting by conditionals using WHERE\n",
        "cursor.execute('''SELECT * FROM [table name] WHERE [column name] = [some value];''').fetchall()\n",
        "\n",
        "# Altering a table \n",
        "cursor.execute('''ALTER TABLE cats ADD COLUMN notes text;''')\n",
        "# Updating data\n",
        "cursor.execute('''UPDATE [table name] SET [column name] = [new value] WHERE [column name] = [value];''')\n",
        "# Deleting data\n",
        "cursor.execute('''DELETE FROM [table name] WHERE [column name] = [value];''')\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "p-ehdf4Tw3IN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Some Notes on Displaying Query Outputs\n",
        "```python \n",
        "    import pandas as pd\n",
        "    #Demonstrating running a query and previewing results as pandas DataFrame\n",
        "    results = cursor.execute(\"\"\"select * from planets;\"\"\").fetchall()  \n",
        "    df = pd.DataFrame(results)\n",
        "    df. columns = [i[0] for i in cursor.description]\n",
        "    df.head()\n",
        "\n",
        "    # CAN MAKE A FUNCTION TO SIMPLIFY\n",
        "    def sql_select_to_df(SQL_COMMAND, cur=cursor):\n",
        "        results = cur.execute(SQL_COMMAND).fetchall()\n",
        "        df = pd.DataFrame(results)\n",
        "        df.columns = [i[0] for i in cur.description]\n",
        "        return df\n",
        "    \n",
        "    # Call function to select data\n",
        "    df = sql_select_to_df(\"\"\"select * from planets;\"\"\")\n",
        "    df.head()\n",
        "    \n",
        "    # Select with function + conditional\n",
        "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE mass > 1;\"\"\")\n",
        "    df.head()\n",
        "    \n",
        "    # Select with AND \n",
        "    df=sql_select_to_df(\"\"\"SELECT * FROM planets WHERE (num_of_moons>1 AND mass < 1);\"\"\")\n",
        "    df.head()```"
      ]
    },
    {
      "metadata": {
        "id": "_UOFVo8tw3IO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Filtering and Ordering\n",
        "```python\n",
        "# ORDER BY\n",
        "cursor.execute('''SELECT column_name FROM table_name ORDER BY column_name ASC|DESC;''').fetchall()\n",
        "# LIMIT\n",
        "cursor.execute('''SELECT * FROM cats ORDER BY age DESC LIMIT 3;''').fetchall() #Fetch top 3\n",
        "cursor.execute('''SELECT * FROM cats ORDER BY age DESC;''').fetchone() #returns the first \n",
        "# BETWEEN\n",
        "cursor.execute('''SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2;''').fetchall()\n",
        "# NULL - placeholder\n",
        "cursor.execute('''INSERT INTO cats (name, age, breed) VALUES (NULL, NULL, \"Tabby\");''')\n",
        "#SELECT BY NULL\n",
        "SELECT * FROM cats WHERE name IS NULL;\n",
        "# COUNT\n",
        "SELECT COUNT([column name]) FROM [table name] WHERE [column name] = [value];\n",
        "# GROUPBY\n",
        "SELECT breed, COUNT(breed) FROM cats GROUP BY breed;\n",
        "SELECT breed, owner_id, COUNT(breed) FROM cats GROUP BY breed, owner_id;\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "mrf7MwCxw3IP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Object-Oriented Programming (Sect 06-07)\n",
        "\n",
        "\n",
        "### Defining classes \n",
        "\n",
        "```python\n",
        "# Must define class NameConventionCase\n",
        "class MyNewClass: \n",
        "    pass # If no attributes, must pass\n",
        "# Instantiate an MyNewClass object\n",
        "new_instance = MyNewClass() \n",
        "\n",
        "```\n",
        "### Class Attributes & Methods \n",
        "* Instance methods are like attributes, but are *callable.*\n",
        "* When calling a object **.method()**, the object *implicitly* called\n",
        "    * Must use `self` to tell methods to expect input variable \n",
        "\n",
        "```python \n",
        "# Defining an instance method:\n",
        "class Dog():\n",
        "    def bark(self):\n",
        "        return \"Ruh-roh!\"\n",
        "    def needs_a_walk(self):\n",
        "        self.gotta_go = False \n",
        "        return 'Phew that was close!'\n",
        "    def whose_a_good_dog(self, name):\n",
        "        return f'Whos a good dog???\"\\n {name.title()} is!'  \n",
        "\n",
        "# Calling an instance method\n",
        "new_rex = Dog()\n",
        "new_rex.bark() # Ruh-roh!\n",
        "new_rex.whose_a_good_dog('Fido')\n",
        "\n",
        "```\n",
        "\n",
        "###  Instance Variables & Setters and Getters\n",
        "\n",
        "```python \n",
        "# _instance_ variables are protected from unwanted external edits\n",
        "# They have class.methods() defined to set and get the values.\n",
        "class BankAccount():\n",
        "    \n",
        "    def set_balance(self, amount):\n",
        "        self._balance += amount    \n",
        "    def get_balance(self):\n",
        "        return self._balance\n",
        "        \n",
        "    def make_withdrawal(self, amount_requested):\n",
        "        if (self.check_min_bal(amount_requested)):\n",
        "            return self.check_min_bal(amount_requested)\n",
        "        else: \n",
        "            self.set_balance(-amount_requested)\n",
        "            return print(f'$ {amount_requested}')\n",
        "\n",
        "        # ---- Note: some code cut -----\n",
        "[BOOKMARK TO RETURN TO LATER]                \n",
        "## Using Properties with Setters & Getters\n",
        "\n",
        "# ----------- HERE is where we are using the property() function ----------------------------------- #\n",
        "    balance = property(get_balance, set_balance)\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "jgdIJYDvw3IQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python        \n",
        "# Initializing Instance Objects Using _init_ \n",
        "class Business():\n",
        "    def __init__(name=None, biz_type=None, city=None, customers = {}):\n",
        "        business.name = name\n",
        "        business.biz_type = biz_type\n",
        "        business.city = city\n",
        "        business.customers = customers\n",
        "\n",
        "    # Normal function to instantiate a BankAccount\n",
        "    def make_account():\n",
        "        new_account = BankAccount()\n",
        "        new_account._balance = 0\n",
        "        new_account._minimum_balance = 250\n",
        "        new_account._max_withdrawal = 150 \n",
        "        return new_account\n",
        "```\n",
        "```python\n",
        "class Customer():\n",
        "    def __init__(self, name=None, orders=[], location=None):\n",
        "        self.name=name\n",
        "        self.orders = orders\n",
        "        self.location = location\n",
        "    def add_order(item_name, item_cost, quantity):\n",
        "        self.orders.append({'item_name': item_name, 'item_cost':item_cost, 'quantity':quantity})\n",
        "```\n",
        "\n",
        "```python\n",
        "\n",
        "# Simple / lazy way\n",
        "class Person:\n",
        "    def set_name(self, name):\n",
        "        self.name = name\n",
        "    def set_job(self, job):\n",
        "        self.job = job\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "5kFGfU5Ww3IR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using NumPy & Arrays (section 08)\n"
      ]
    },
    {
      "metadata": {
        "id": "tjWBMjYPw3IR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy & element-wise math operations"
      ]
    },
    {
      "metadata": {
        "id": "IkxjA1Gkw3IS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Intitialize a np array\n",
        "import numpy as np\n",
        "x=np.array([1,10,20,30]) \n",
        "print(x)\n",
        "\n",
        "#np  Array Math Operations\n",
        "print('x*3 =', x * 3 ) # Array .* (element-wise function)\n",
        "print('[1,2,3] * 3=' ,[1,2,3] * 3)\n",
        "print('x + 2=',x + 2) #Adds two to each element\n",
        "# But can't do element-wise addition\n",
        "[1,2,3] + 2 # Returns an error; different data types\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "jHB8gF-Qw3IT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Scalar Math\n",
        "Here arr = np array\n",
        "```python\n",
        "np.add(arr,1) # Add 1 to each array element\n",
        "np.subtract(arr,2) # Subtract 2 from each array element\n",
        "np.multiply(arr,3) # Multiply each array element by 3\n",
        "np.divide(arr,4) # Divide each array element by 4 (returns np.nan for division by zero)\n",
        "np.power(arr,5) # Raise each array element to the 5th power  \n",
        "```\n",
        "### Vector Math\n",
        "Here arr1, arr2 are both np arrays\n",
        "```python\n",
        "np.array_equal(arr1,arr2) # Returns True if the arrays have the same elements and shape\n",
        "\n",
        "np.add(arr1,arr2) # Elementwise add arr2 to arr1\n",
        "np.subtract(arr1,arr2) # Elementwise subtract arr2 from arr1\n",
        "np.multiply(arr1,arr2) # Elementwise multiply arr1 by arr2\n",
        "np.divide(arr1,arr2) # Elementwise divide arr1 by arr2\n",
        "\n",
        "np.power(arr1,arr2) # Elementwise raise arr1 raised to the power of arr2\n",
        "np.sqrt(arr) # Square root of each element in the array\n",
        "np.log(arr) # Natural log of each element in the array\n",
        "\n",
        "np.abs(arr) # Absolute value of each element in the array\n",
        "np.ceil(arr) # Rounds up to the nearest int\n",
        "np.floor(arr) # Rounds down to the nearest int\n",
        "np.round(arr) # Rounds to the nearest int\n",
        "\n",
        "np.sin(arr) # Sine of each element in the array\n",
        "```\n",
        "### Appending / adding elements\n",
        "```python\n",
        "[1,2,3] + [4,5,6] #Adding raw lists is just appending\n",
        "np.array([1,2,3]) + np.array([4,5,6]) #Adds elements\n",
        "\n",
        "#Same as above with built in method\n",
        "x = np.array([1,2,3])\n",
        "y = np.array([4,5,6])\n",
        "np.add(x,y)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ikNZptfLw3IU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Multi-dimensional Arrays with Numpy\n"
      ]
    },
    {
      "metadata": {
        "id": "WLXk0U0xw3IU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* numpy displays arrays in more user friendly way ( rows above rows)\n",
        "    * <img style=float src=\"attachment:ScreenClip.png\" align=\"left\"/>\n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "yRJPqLjVw3IV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* np.shape returns length of each dimensions (row, col, __) \n",
        "\n",
        "```python\n",
        "    y = np.array([[1,2,3],[4,5,6]])\n",
        "    print(y.shape) # (2,3)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "z_ubqwvbw3IW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Functions for Creating Arrays\n",
        "```python\n",
        "# np.zeroes(shape) and np.ones(shape)\n",
        "    np.zeros(5) # #one dimensional; 5 elements, all 0\n",
        "    np.zeros([2,2]) #two dimensional; 2x2 matrix\n",
        "    np.zeros([3,4,5]) #3 dimensional; 3 4x5 matrices\n",
        "    \n",
        "    np.ones(shape) # Returns 1's\n",
        "\n",
        "# np.full(shape,fill) \n",
        "    np.full(shape, fill) # fill array with arbitrary values\n",
        "    np.full(5, 3) #Create a 1d array with 5 elements, all of which are 3\n",
        "    np.full(5, range(5)) #Create  array with 5 elements (0-4) (ONLY WORKS WITH 1-2 DIMENSIONS)\n",
        "    \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "tRJOMZpjw3IW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NP Array Indexing / Subsetting\n",
        "```python\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
        "print(x.shape) #(4,3)\n",
        "#Result displays as:\n",
        "np.array([[1,2,3], \n",
        "          [4,5,6], \n",
        "          [7,8,9], \n",
        "          [10,11,12]])\n",
        "\n",
        "# Slice rows with 1 index:\n",
        "x[0] # array([1,2,3])\n",
        "\n",
        "#Slice rows, columns  \n",
        "# x[slice_dim1, slice_dim2]\n",
        "x[:,0] #All rows, column 0\n",
        "\n",
        "# If array has more than 2 dimensions:   \n",
        "print(\"NOTE: [!] If have multi-dim array (3+ dim), can't use row,col indexing!!\")\n",
        "\n",
        "#To slice along a second dimension with lists - list comprehension\n",
        "[i[0] for i in x] #returns first element from each row \n",
        "\n",
        "#Doing this in multiple dimensions with lists\n",
        "[i[1:3] for i in x[2:4]] #returns rows (second-third), columns (third:fourth) [[8,9],[11,12]]\n",
        "```\n",
        "\n",
        "#### Slicing 3D arrays\n",
        "```python \n",
        "#With an array\n",
        "x = np.array([\n",
        "              [[1,2,3], [4,5,6]],\n",
        "              [[7,8,9], [10,11,12]]\n",
        "             ])\n",
        "x\n",
        "    #returns: \n",
        "    array([[[ 1,  2,  3],\n",
        "            [ 4,  5,  6]],\n",
        "\n",
        "           [[ 7,  8,  9],\n",
        "            [10, 11, 12]]])\n",
        "\n",
        "# Array is 3-D\n",
        "x.shape #(2,2,3)\n",
        "# 3-D indexing\n",
        "x[:,:,-1]\n",
        "#returns last element of ebery row, col:\n",
        "array([[ 3,  6],\n",
        "   [ 9, 12]])\n",
        "```\n",
        "\n",
        "### Get unique vanlues and counts from a np array\n",
        "values, counts = np.unique(np_it, return_counts=True)"
      ]
    },
    {
      "metadata": {
        "id": "rPAYDUHkw3IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## STATISTICS AND PROBABILITY (Section 08)\n",
        "\n",
        "### Set definions\n",
        "#### set :  \n",
        "- a *well-defined colletion of objects*.\n",
        "- _Math notation:_\n",
        "    - define a set by $S$. \n",
        "    - If an element $x$ belongs to a set $S$:\n",
        "        - $x \\in S$.\n",
        "    - If $x$ does not belong to a set $S$:\n",
        "        - $x\\notin S$.\n",
        "        \n",
        "#### subset: \n",
        "- set $T$ is a subset of set $S$ if *every element* in set $T$ is also in set $S$. \n",
        "    - Notation for a subset is $T \\subset S$.   \n",
        "        - $T$ and $S$ can be the SAME\n",
        "    - If $T$ != $S$, but $T \\subset S$, called a '_proper subset_'\n",
        "        - Can use notation:  $T \\subsetneq S$ and $T \\subseteq S$ \n",
        "\n",
        "#### Universal set:\n",
        "- The collection of all possible outcomes in a certain context or universe.\n",
        "    -  often denoted by $\\Omega$.\n",
        "    - Example: all possible outcomes of a 6-sided die:\n",
        "        - $\\Omega = \\{1,2,3,4,5,6\\}$\n",
        "    - Can have infinite # of elements (e.g. the set of all real numbers!)\n",
        "\n",
        "### Set operations:\n",
        "- Data used in examples:\n",
        "\n",
        "Imagine you have two sets of numbers, say the first 4 multiples of 3 in set $S$:\n",
        "\n",
        "$ S = \\{3,6,9,12\\}$\n",
        "\n",
        " and the first 4 multiples of 2 in set $T$:\n",
        " \n",
        "$ T = \\{2,4,6,8\\} $.\n",
        "\n",
        "#### Union (combining elements)\n",
        "- the union of $S$ and $T$ is denoted as $S \\cup T$\n",
        "\n",
        "#### Intersection\n",
        "- contains all elements of $S$ that also belong to $T$. \n",
        "    - denoted as $S \\cap T$.\n",
        "    \n",
        "#### Relative complement / difference\n",
        "-  the relative complement of S contains all the elements of T that are NOT in S.\n",
        "    - relative complement of S (or $ T\\backslash S $) is $\\{2,4,8\\}$.\n",
        "    - relative complement  of T (or $ S\\backslash T $) is $\\{3,9,12\\}$.\n",
        "\n",
        "#### Absolute complement\n",
        "- The absolute complement of $S$, with respect to the Universal set $\\Omega$, is the collection of the objects in $\\Omega$ that don't belong to $S$.\n",
        "    -  absolute complement of $S$ is denoted as $S'$ or $S^c$.\n",
        "\n",
        "- Example: Let's define $\\Omega$ (box around the two venn diagrams) = multiples of both 2 and 3 until 20.\n",
        "\n",
        "    - Elements of $\\Omega$ are $\\{2,3,4,6,8,9,10,12,14,15,16,18,20\\}$. \n",
        "\n",
        "    - The absolute complement of $S$ (so $S'$ or $S^c$) is then given by $\\{2,4,8,10,14,15,16,18,20\\}$.\n",
        "    \n",
        "#### Inclusion Exclusion principle\n",
        "- When combining  2 sets, the method for obtaining the union of two finite sets is given by:\n",
        "\n",
        "    - $\\mid S \\cup T \\mid = \\mid S \\mid + \\mid T \\mid - \\mid S \\cap T \\mid $\n",
        "    \n",
        "        - Horizontal lines denote the *cardinality* of a set, which is the number of elements, considering a finite set. \n",
        "        \n",
        "        \n",
        "- *The formula expresses the fact that the sum of the sizes of the two sets may be too large since some elements may be counted twice. For the double-counted elements, one is substracted again.*\n",
        "\n",
        "### Empty \n",
        " - An **empty** set has no elements\n",
        " - denoted by $\\emptyset$ or simply $\\{\\}$\n"
      ]
    },
    {
      "metadata": {
        "id": "ydclwM1Yw3IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Into to probability \n",
        "#### Sample Space & Event Space\n",
        "##### Sample space:\n",
        "$$S = \\{ 1,2,3,4,5,6\\}$$ \n",
        "being the possible outcomes when throwing a dice.\n",
        "\n",
        "##### Event space:\n",
        "-   The **event space** is a subset of the sample space, $$E \\subseteq S$$\n",
        "-   Example:\n",
        "    -   Throwing an odd number would lead to an event space $$E = \\{ 1,3,5\\}$$.\n",
        "\n",
        "### Law of relative frequency\n",
        "- Limit of large infinite outcomes produce fixed numbers .\n",
        "$$P(E) = \\lim_{n\\to\\infty}\\frac{S(n)}{n}$$\n",
        "    - Probability of Event E having Successful(S) outcomes for $n$ trials\n",
        "    \n",
        "#### Probability axioms\n",
        "\n",
        "1.  Positivity : Prob is always 0 \\<= P(E) \\<=1\n",
        "\n",
        "2.  Probability of a certain event: P(S)=1\n",
        "\n",
        "3.  Additivity Union of 2 exclusive sets = sum prob of individual events\n",
        "    happening <br>\n",
        "If $A\\cap B = \\emptyset $, then $P(A\\cup B) = P(A) + P(B)$\n",
        "\n",
        "### Addition law of probability \n",
        "\n",
        "-   Prob of union of A and B is individual P minus intersection\n",
        "$$P(A\\cup B) = P(A) + P(B) - P(A \\cap B)$$\n"
      ]
    },
    {
      "metadata": {
        "id": "2yqWh1lBw3IY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### HOW TO: test probability of an event: \n",
        "\n",
        "1.  What is the prob of E happening at least once?\n",
        "\n",
        "    1.  Get Boolean result for E:  \n",
        "        Set_E =sample_population == E\n",
        "\n",
        "    2.  Verify condition:  \n",
        "        true_E=np.any(set_E, axis = 1)\n",
        "\n",
        "    3.  Prob_E=np.sum(true_E)/len(sample_population)"
      ]
    },
    {
      "metadata": {
        "id": "-eVvlckzw3IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Permutations and Factorials:\n",
        "----------------------------\n",
        "\n",
        "### Permutations of a subset\n",
        "\n",
        "How many ways can we select k elements out of a pool of n objects?\n",
        "- $k$-permutation of $n$:\n",
        "\n",
        "$n*(n-1)*...*(n-k+1)$ or in other words, $P_{k}^{n}= \\dfrac{n!}{(n-k)!}$\n",
        "\n",
        "### Permutations with replacement \n",
        "\n",
        "\\# of possible options doesn’t change, so n is raised to the power of j, the number of draws from the pop<br>\n",
        "$n^j$\n",
        "\n",
        "### Permutations with repetition ...?\n",
        "\n",
        "The \\# of permutations of *n* objects with identical objects of type 1<br>\n",
        "$(n_1^{j_1}* n_2^{j_2})$\n",
        "<img src=\"https://www.dropbox.com/s/5qrwxgv541u6kj5/00ff12464dd108477fd6a5dbeac9868d.png?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "90uxhG0jw3IZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Combinations\n",
        "- How many ways can we create a subset $k$ out of $n$ objects? \n",
        "    - Unordered\n",
        "$$\\displaystyle\\binom{n}{k} = \\dfrac{P_{k}^{n}}{k!}=\\dfrac{ \\dfrac{n!}{(n-k)!}}{k!} = \\dfrac{n!}{(n-k)!k!}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "t4afuY15w3Ia",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Distributions: Discrete vs Continuous \n",
        "#### Discrete Distributions\n",
        "-   Bernoulli = Repeated trials of binary outcome event. ( x successes in n trials)(flipping a coin)\n",
        "-   Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "-   Poisson = The probability of n events in a given time period when overall rate of occurrence is constant (i.e. receiving mail)\n",
        "-   Uniform = all outcomes equally likely\n"
      ]
    },
    {
      "metadata": {
        "id": "LbEnK7DMw3Ib",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Distributions (sect 19)\n",
        "- **Can be discrete or Continuous Probability Functions**\n",
        "<img src=\"https://www.dropbox.com/s/7qooiy76s3jvcr1/pmf_pdf.png?raw=1\" width=400>\n",
        "<img src=\"https://www.dropbox.com/s/ovrzewnefk2qc97/exp-var.png?raw=1\" width=400>\n",
        "\n",
        "- **Common Distributions:**\n",
        "<img src=\"https://www.dropbox.com/s/lu8iffegqjnp4kq/dists.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "id": "LBdDjOWJw3Ic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Discrete Distributions\n",
        "#### Bernoulli Distribution / Binomial Distribution\n",
        "- Probability of $x$ successes in $n$ trials for Bernoulli/binomial variable (binary outcome)\n",
        "    - Described by only one parameter $p$\n",
        "- For binomial *trial*: $Y = Bernoulli(p)$ and $p=P(Y=1)=0.8$\n",
        "- For binomial *distribution*, events are independent. \n",
        "$$ P(Y=k)= \\binom{n}{k} p^k(1-p)^{(n-k)}$$ \n",
        "\n",
        "#### Geometric Distribution\n",
        "- Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "\n",
        "#### Poisson\n",
        "- Represents the probability of $n$ events in a given time period when the rate of occurrence is constant\n",
        "\n",
        "#### Uniform\n",
        "- All outcomes are equally likely. \n",
        "- BOTH continuous AND discrete\n",
        "\n",
        "### Continuous Distributions\n",
        "#### Normal / Gaussian Distribution\n",
        "- Bell shape curve very common in natural data\n",
        "- Symmetrical, mean = median = mode \n",
        "- AUC == 1\n",
        "\n",
        "###### Normal Density Function\n",
        "- Density of normal distribution for given value of x\n",
        "- Can describe from its center and spread\n",
        "$$y = \\frac{1}{\\sigma \\sqrt{2}{2\\pi}}e^{\\frac{{(x -\\mu)}{^2}}{2 \\sigma ^{2}}}$$\n",
        "- $\\mu$ = mean\n",
        "- $\\sigma$ = standard deviation\n",
        "- $\\pi \\approx 3.14159$\n",
        "- $e \\approx 2.71828$\n",
        "\n",
        "#### Standardized Normal Distribution\n",
        "$$z = \\frac{x-\\mu}{\\sigma}$$"
      ]
    },
    {
      "metadata": {
        "id": "R4xed8CZw3Ic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Probability Mass Function (PMF) / probability distribution\n",
        "- Converts frequency of events to probability of a particular outcome of a **discrete** function, by normalizing so that the sum of all outcomes == 1.\n",
        "- Can test what is the probability that $x$ takes on a particular value $k$\n",
        "    - $P(X=k)$\n",
        "\n",
        "-   Gives probability for discrete random variables, if we have x outcomes, we want to know what is the probability of getting k (our value of interest) from x\n",
        "- Maps a value from its probability \n",
        "\n",
        "#### How to convert frequency to probability  for PMF\n",
        "```python\n",
        "import numpy as np  \n",
        "import collections  \n",
        "x = [1,1,1,1,2,2,2,2,3,3,4,5,5]\n",
        "counter = collections.Counter(x)  \n",
        "\\# Convert frequency to probability - divide each frequency value by total number of values\n",
        "pmf = []\n",
        "for key,val in counter.items():\n",
        "    pmf.append(round(val/len(x), 2))\n",
        "    print(counter.keys(), pmf)  \n",
        "  \n",
        "# Proof that is normalized to overall prob of 1 (needed for PMF)  \n",
        "np.array(pmf).sum()\n",
        "# Visualizing PMF – similar to histogram, but normalized to P=1*  \n",
        "import matplotlib.pyplot as plt  \n",
        "plt.style.use(‘ggplot’)  \n",
        "plt.stem(counter.keys(), pmf)  \n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/ghbwhp17z4ulyvc/e51d10e06e9b70069c792d9fa8172e5e.png?raw=1\" width=300>\n",
        "\n",
        "### CUMULATIVE DENSITY FUNCTION\n",
        "- With large sample space $S$ (# of possible outcomes) for values of $X$, too hard to visualize with pmf\n",
        "- maps a value from its percentile rank for **discrete** functions\n",
        "- calculated as the $$F(x) = P(X \\leq x)$$\n",
        "\n",
        "### PROBABILITY DENSITY FUNCTION\n",
        "- Essentially equivalent to the pmf, but for **continuous** functions\n",
        "- Line represents regions where observations most likely to occur (the density)\n",
        "<img src=\"https://www.dropbox.com/s/y8i8azec6ncpuum/pdf1.png?raw=1\" width=300>\n",
        "\n",
        "#### Calculate area under the curve around the value of interest\n",
        "$$F(X) = P(a \\leq x \\leq b) = \\int_a^b f(x) dx \\geq 0$$\n",
        "<img src=\"https://www.dropbox.com/s/5q9gnarklq769zt/pdf2.jpg?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "cvpxcVhWw3Id",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Kernel Density Estimation \n",
        "- Non-parametric estimation to plot a curve at every individual data point (kernels)\n",
        "- Added together to plot smooth density estimation ( most common kernel is Gaussian)\n",
        "- Below example histogram and kde are from the same data\n",
        "<img src=\"https://www.dropbox.com/s/vrgcphxmry5148l/Comparison_of_1D_histogram_and_KDE.png?raw=1\" width=400>"
      ]
    },
    {
      "metadata": {
        "id": "hdzJUmM7w3Id",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Skewness\n",
        "- Symmetrical distribution: skewness = 0\n",
        "- **Fisher-Pearson Coefficient of skewess:**\n",
        "$$∑ N_{i=1} \\frac{{(Yi−\\bar{Y})}^3}{N} / {\\sigma^3}$$\n",
        "- Rules of thumb\n",
        "    - Symmetrical-ish: -0.5 to +.05\n",
        "    - Moderate Skew:\n",
        "        - Negative skew: -1 to -0.5\n",
        "        - Positive skew: +0.5 to +1\n",
        "    - Highly skewed:\n",
        "        - Less than -1\n",
        "        - Greater than +1\n",
        "    \n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/mqr3kux0caa64nk/skew1.jpeg?raw=1\">\n",
        "\n",
        "\n",
        "### Kurtosis \n",
        "- Lengths of tails of distribution to describe extreme values (outliers)\n",
        "- Univariate kurtosis:\n",
        "$$\\Sigma N_{i=1} \\frac{{(Yi−\\bar{Y})}^4}{N} / {\\sigma^4}$$\n",
        "\n",
        "- **Mesokurtic:**\n",
        "    - Kurtosis similar to standard normal distribution\n",
        "- **Leptokurtic (Kurtosis >3)**\n",
        "    - Tails are fatter, peak is higher sharper\n",
        "    - Data are heavy-tailed or many outliers\n",
        "- **Platykurtic: (Kurtosis < 3)**\n",
        "    - Shorter peak, tails are thinner than the normal distribution. \n",
        "    - Data are light-tailed or lack of outliers vs normal dist\n",
        "<img src=\"https://www.dropbox.com/s/5ynsy7vkb196ilb/kurt2.jpg?raw=1\" width=300>\n"
      ]
    },
    {
      "metadata": {
        "id": "YyPLU2fow3Ie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Statistical Distributions Recap (Sect 23)"
      ]
    },
    {
      "metadata": {
        "id": "rNLT8dc0w3If",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Uniform distribution\n",
        "- Equal probability\n",
        "- Probability function:<br>\n",
        "$$\\rho_{uniform}(x) = \\dfrac{1}{b-a} \\quad \\mbox{ for } a \\leq x < b $$\n",
        "- Mean of uniform distribution:<br>\n",
        " $\\dfrac{b+a}{2}$\n",
        "- Variance of uniform distribution:<br>\n",
        "$V = \\dfrac{(b-a)^2}{12}$\n",
        "- Standard Deviation:<br>\n",
        "$\\sigma = \\dfrac{b - a}{2 \\sqrt{3}}$.\n",
        "#### Generate uniform in python"
      ]
    },
    {
      "metadata": {
        "id": "UKz6JTHuw3Ig",
        "colab_type": "code",
        "outputId": "29201d1c-bd29-4b17-8abd-38f7c5f5e7ab",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate uniform data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "values = np.random.uniform(-10.0, 10.0, 100000)\n",
        "\n",
        "fig = plt.figure(figsize=(4,4))\n",
        "plt.hist(values, 50) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I8np5K5-w3Ik",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Binomial Distribution\n",
        "- Discrete version of normal distribution describing the probability distribution of a given # of successes \n",
        "\n",
        "$$\\mu = n * p$$\n",
        "\n",
        "where $n$ is the number of trials, and $p$ is the probability of success for a given trial. \n",
        "\n",
        "- The **_Standard Deviation for a Binomial Distribution_** is:\n",
        "\n",
        "$$\\sigma = \\sqrt{n * p * (1 - p)}$$\n",
        "\n",
        "- The formula for the **_Point Probability of the Binomial Distribution_** is:\n",
        "\n",
        "$$ \\Big(\\frac{n!} {x! (n-x)!}\\Big) p^x (1 - p)^{n - x}$$\n",
        "\n",
        " where $n$ is the number of trials, $p$ is the probability of success for a given trial, and $x$ is the number of successes.\n",
        "\n",
        "- The formula for the **_Cumulative Probability of the Binomial Distribution_** is:\n",
        "\n",
        "$$\\sum_{i=0}^{x}  \\Big(\\frac{n!} {x! (n-x)!}\\Big) p^x (1 - p)^{n - x}$$\n",
        "\n",
        "where $n$ is the number of trials, $p$ is the probability of success for a given trial, and $x$ is the number of successes."
      ]
    },
    {
      "metadata": {
        "id": "rhPYaRHLw3Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normal Distributions\n",
        "- **_Probability Density of the Normal Distribution_** is:\n",
        "$$f(x\\ |\\ \\mu,\\ \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e$$\n",
        "\n",
        "- Where:\n",
        "$x$ is the **_point_** we want to calculate the probability for\n",
        "$\\mu$ is the **_mean_** of the sample\n",
        "$\\pi$ is a mathematical constant, the irrational number $3.14159$\n",
        "$\\sigma^2$ is the **_variance_** (since $\\sigma$ is the **_standard deviation_**)\n",
        "$e$ is **_Euler's Constant_**, also known as the **_Base of the Natural Logarithm_**, $2.71828$"
      ]
    },
    {
      "metadata": {
        "id": "k64fB1ERw3Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gaussian Distributions\n",
        "- For Gaussian distribution, the probability function is calculated as:\n",
        "$$\n",
        "\\rho_{Gaussian}(v) = \\dfrac{1}{\\sqrt{2 \\pi \\sigma}} e^{-\\frac{v^{2}}{2\\sigma^2}}\n",
        "$$\n",
        "- Mean of Gaussian distribution is $\\mu$,\n",
        "- Standard deviation is $\\sigma$.\n",
        "- Visualize Gaussian distributions with the probability density function ( scipy.stats.norm)"
      ]
    },
    {
      "metadata": {
        "id": "AP7L-4rRw3In",
        "colab_type": "code",
        "outputId": "2407104b-12cb-4212-8d32-7ab2efb0b014",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generating and Plotting Normal Distributions \n",
        "# Generate norm distribution\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Generating and Plotting Normal Distributions \n",
        "fig, ax = plt.subplots(1,4, figsize=(10,3))\n",
        "\n",
        "# Use scipy.stats.norm.pdf \n",
        "# to generate data for np array of x\n",
        "n=0\n",
        "ax[n].set_title(f'Continuous Norm From\\n scip.stats.norm')\n",
        "x = np.arange(-3, 3, 0.001) # Declare the range of x-values with np.arrange\n",
        "# Use scipy.stats.norm to generate continuous kerndel density estimation for those x-values\n",
        "ax[n].plot(x, norm.pdf(x), color='red')\n",
        "\n",
        "# Generate nomral distribution in numpy\n",
        "# using mean and std\n",
        "n+=2\n",
        "ax[n].set_title(f'Discrete Norm Data\\n from np.random.norm')\n",
        "values = np.random.normal(5.0, 2.0, 100000) #mean, std, size\n",
        "ax[n].hist(values, 50)\n",
        "\n",
        "# Showing the KDE for The Discrete norm distribution from numpy\n",
        "n+=1\n",
        "ax[n].set_title('Same Discrete Norm Data -> Kde')\n",
        "sns.distplot(values, ax=ax[n])\n",
        "\n",
        "# Finalize figure\n",
        "plt.delaxes(ax[1])\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAADQCAYAAADiUWxeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XdYFNf6B/DvbGOBBXEVewlosKAEwS5gwNh7BU3QaIyJid6fMRY0VmzYa9SYGMzVWGKJJvHeJHYFFSwhopForgWVIkWQum3O7w/cFaQs6u7OAu/neXwed/bMnHeG5czL2TPncIwxBkIIIYQQQqogkdABEEIIIYQQIhRKhgkhhBBCSJVFyTAhhBBCCKmyKBkmhBBCCCFVFiXDhBBCCCGkyqJkmBBCCCGEVFmCJ8M6nQ7h4eEYMmQIBg4ciD59+mDlypVQq9WvfMysrCyMHj3a8HrgwIF4+vSpKcI1qYcPH6JZs2bYv39/ke3bt29HSEiIRWI4dOgQvL29MXDgwCL/Tpw4YZH6CSHCe/jwIVq0aGH4/e/fvz+CgoLwn//8x1Bm/fr1OHz4sNljGTduHNLT019qn5CQEPTq1Qu5ublFtrdp0wYPHz40ZXilatasGfr374+BAwdiwIABGDJkCL7//vty7bt///5ylyWEmJ5E6AAWLFiAzMxMfPfdd3BwcEBubi6mTZuGL774AitXrnylY2ZmZiI2Ntbw+siRI6YK1+REIhGWL18Ob29vuLq6ChJD27Zt8dVXXwlSNyHEOsjl8iJt5aNHj/D+++9DLBajZ8+e+L//+z+LxBEZGflK+z169AhLlizBkiVLTBxR+X333XdQKpUAgPT0dHz88cdQqVQYN25cmftduXIFb775piVCJISUQNBk+OHDh/j5558REREBhUIBALCzs8PChQtx9epVAAW9vAsXLkRcXBw4joOvry+mTp0KiUSC1q1bY8KECYiMjMTjx48xfvx4jBo1CrNmzUJ+fj4GDhyIQ4cOoWXLlrhw4QJOnz6NY8eOQSQS4f79+5DL5Vi+fDmaNGmC4OBgvPvuu+jVqxcAFHl9+fJlrFixAnl5eZBKpZgyZQr8/Pxw6NAh/Pbbb4ZEsvDry5cvIywsDDzPAwA++ugj9OzZs9g1kMvlGDt2LKZNm4a9e/dCJpMVeb+s82/VqhW6deuGuLg4rFq1CqNGjcLYsWNx/vx55ObmYtKkSfj1119x69Yt1KpVC1u3boWdnV25fz6HDh3CgQMHkJeXB4VCgZ07d+LLL7/E0aNHIRaL4eLigrlz58LZ2RnBwcFwd3dHTEwM0tPTMWLECKSmpiI6Ohp5eXlYt24dmjVr9vIfEkKIIOrXr49//etf2L59O3r27ImQkBC8+eab+OCDD7BhwwYcO3YMUqkU1atXx7Jly1CrVi38+eefWLx4saGtnDFjBjp16lSsrbKzs8OSJUuQkZEBnU6H4OBgDBs2DLNmzQIAjBkzBtu2bYNIJEJoaCgSExOh0WjQt29ffPzxxyXGO3r0aBw5cgS//fZbiW3t8ePHsWnTJvA8D3t7e8yaNQseHh7YuHEjYmJi8PjxYzRr1gyNGzdGfHw8kpOTkZKSAnd3d3To0AGHDx/Gw4cPMX36dPTr18/o9VMqlQgJCcG//vUvjB07FmlpaZg3bx7S0tKQkpKC+vXrY926dbh69SpOnjyJyMhIyOVy9OzZs8RyNWrUeL0fKCGkdExAv/76Kxs6dGiZZWbMmMEWLVrEeJ5nKpWKjRs3jn311VeMMcbc3NzYzp07GWOMxcbGslatWrH8/Hz24MED5unpaTiGm5sbS0tLYwcPHmTe3t4sMTGRMcZYaGgomzFjBmOMsffee4/997//Neyjf52ens46derEYmJiGGOM3bp1i7Vv357Fx8ezgwcPsgkTJhj2Kfx69OjR7JdffmGMMXbz5k22YMGCYuemj1On07F3332XhYWFMcYY++abb9jMmTPLdf4//vhjkfP87rvvGGOMffXVV6xNmzYsKSmJ6XQ6NnjwYPbTTz8Vi+HgwYPMy8uLDRgwwPBv7ty5hvfatWvHsrKyGGOMHThwgAUGBrKcnBzGGGMbNmxg48aNM1yvSZMmMcYYi4mJYW5ubuzEiROMMcaWLFnC5syZU+LPlxAivBfbTL1bt26xt956izHG2MyZM9k333zDEhISmJeXF1OpVIwxxrZv386OHTvG1Go169KlCzt16hRjrKBN7tevH9PpdEXaKo1Gw/r06cOuX7/OGGPs6dOnrHfv3uyPP/5gjD1vrxljLDg42NCO5Ofns+DgYHb06NFicepjO3fuHGvfvj1LSEhgjDHm6enJHjx4wP755x/WuXNnFh8fzxhj7Pz586xLly4sKyuLbdiwgfXs2ZNpNBrGWEG75u/vz54+fcry8vJYu3bt2LJlyxhjjB07doz16NGjxGtYOG69nJwcw/YdO3YY2m6e59n48ePZ9u3bi8TPGCuzHCHEPATtGRaJRIae09KcPXsWe/bsAcdxkMlkCAoKwnfffYcJEyYAALp16wYAcHd3h1qtLjZm7EXu7u6oU6cOAKBly5Y4duxYmeWvXbuGRo0a4a233gIAvPnmm/Dy8kJ0dDQ4jit1v969eyM0NBQnT55E586dMXXq1FLLikQirFy5EoMGDYKPj89LnX/btm2LlNf3iDRq1Ahubm6oXbs2AKBBgwbIzMwssf6yhkk0a9bM0Gt/9uxZDBkyxNC7PHr0aGzdutUwvrt79+4AgIYNGwIAfH19DbFER0eXev6EEOvEcRzkcnmRbbVr10bz5s0xePBg+Pn5wc/PD506dcKNGzcgEonw9ttvAwBatWqFn3/+2bCfvq26d+8e4uPjMXv2bMN7+fn5+Ouvv+Dp6WnYlpubi0uXLiEzMxPr1683bIuLi0OfPn1KjNfHxweDBw/G9OnT8e9//9uw/eLFi+jYsaOhberUqROUSiWuX78OAPD09IRE8vx22LlzZzg4OAAAatWqVaQty8jIeKnrBwA2NjYYM2YMLl++jPDwcNy7dw+3b9823FcKK285QojpCJoMe3h44M6dO8jOzjYkXACQnJyMuXPnYsOGDeB5vkjSyfM8tFqt4bWNjQ2A540OY6zMOgs37BzHFSlf+P8ajQZAwQN+Lya9jDFotVrIZLIS9wGAoKAg+Pv7IzIyEufOncOmTZvw66+/GuJ9Ud26dbFw4ULMnDkTgwYNKnK+ZZ3/i8MepFJpif9/VYWPbyyWF4d4mKJ+QohwYmNj4ebmVmSbSCTCrl27EBsbiwsXLmDp0qXw9fXFgAEDirWVt27dMjwLoW9LdDodHBwcioxPTk1NNSSfejzPgzGGvXv3wtbWFkDBONzS2lC9qVOnIjAwEFu3bi1yrNLa8cKx6b3YlhVOlF9GbGwsGjRoAHt7e6xcuRLXrl3D0KFD0aFDB2i12hLvV+UtRwgxHUFnk6hduzb69++P2bNnIzs7GwCQnZ2NBQsWwMnJCXK5HD4+Pti1axcYY1Cr1fjhhx/QuXPnMo8rkUig0+leqgEp3Evwzz//4O+//wZQ0GNw584dXLt2DQBw+/ZtXLp0Ce3bt4dSqcTt27ehUqmg0Wjw22+/GY4XFBSEmzdvYsiQIVi0aBGePn2KlJSUMmPo1asX/Pz88N133xm2vcr5m4uvry8OHjxo6H3fuXMn2rVrV+zGQQip+O7evYvNmzcXe/grLi4O/fr1Q5MmTfDRRx/h/fffR2xsLFxdXcFxnOEBuBs3bmDMmDHFvv1zcXEp8rBeYmIi+vXrZ2h/xWIxtFotFAoFPD09ER4eDgB4+vQpRo4caXSmG5lMhtWrV+Pbb79Ffn4+gIKe4IiICDx48AAAcOHCBSQmJpq1xzU5ORmrVq0yXL+IiAiMGTMGgwYNQo0aNXD+/HnodDoAz8/ZWDlCiHkIPpvE/PnzsXnzZgQFBUEsFkOtVuOdd97B5MmTAQBz5szB4sWL0b9/f2g0Gvj6+pb6AIWes7MzPDw80Ldv33JPVzNx4kSEhITgzJkzcHV1NXylp1QqsX79eixatAj5+fngOA7Lli2Di4sLGjZsiHbt2qF3795wdnZGhw4dDEn0tGnTsHTpUqxbtw4cx2HSpElo0KCB0TjmzJmDK1euFHn9sudvLsOGDUNiYiKGDx8OnufRuHFjrFq1SpBYCCGmpX/oGCjo/bWxscHUqVMNwx70mjdvjt69e2Po0KGws7ODXC7HnDlzIJPJsHHjRixduhQrVqyAVCrFxo0bi/2xLJPJsHnzZixZsgTffPMNtFot/u///g/e3t4ACjoFgoODsXHjRqxatQqLFi1C//79oVar0a9fPwwYMMDoubi6umLmzJmYM2cOAKBp06aYP38+Jk2aBJ1OB7lcjq1btxbrjX5dY8aMgUgkglgsBgAMHToU7777LgDg008/xYoVK7B+/XpIpVJ4eXkhPj4eAODn54ewsDCj5Qgh5sEx+v6FEEIIIYRUUYIvukEIIYQQQohQKBkmhBBCCCFVFiXDhBBCCCGkyqJk+AUffvgh/vnnH5Mca9y4cUhPTzdZOUIIMZWIiAj4+/tj2LBhhlkXqpqPPvoIhw4dEjqMCiEmJgbBwcHo378/+vXrh/Hjx+P27dsWj+PQoUPw9vbGwIEDMXDgQPTv3x8ff/yxYTYSwLT38dI8ePDA8KD/ywgICMD06dOLbIuNjUVAQICpQitTVFQUPDw8ily/0aNH4/z58+Xaf86cOUWutTlFRUUVW+0xPDwcfn5+iIuLK1Z++/btCAkJeaW6BJ9Nwtp8/fXXJjuWfoohU5UjhBBTOXr0KIYPH45PPvlE6FCIlVOr1fjoo4/w7bffwt3dHQBw5MgRfPjhhzhx4oRh9gxLeXGhqPPnz2P8+PE4ePAg6tevb9L7eGkSEhJw9+7dV9r3119/hY+Pj2H2Fktr1KhRkXm+4+Li8MEHH2Dz5s1Gpxs8f/48AgMDX6v+L7/8Et26dUPz5s1far+1a9fi999/x549e1C/fv3XiuFFlT4Z3r17N/bu3QupVAobGxuEhoaiadOmuHv3LubNm4f09HSIRCJMnDgRffr0QUBAANavX4/c3FysWrUK9erVw507dyCXyxEWFoYmTZoUOX5OTg5mzZqF+/fvQyQSwd3dHaGhofjiiy8AFEy1s23bNsTFxeGrr76CWq1Geno6Bg0ahClTpmDWrFlFyp06darEeAvbuHEjHj16hJSUFDx69Ai1a9fGypUrUatWLdy+fRuhoaHIyMgAx3EYN24cBg0ahKioKCxZsgR2dnbIycnBjBkzsGnTJtStWxd3796Fra0tJkyYgJ07d+Lu3bvo0aNHkRWiCCGVxzfffIMTJ07AxsYGWVlZsLOzQ0xMDB4/foxmzZph2bJlCAsLw4ULFyAWi+Hh4YFZs2ZBoVAgICAA/fr1w8WLF5GZmYnx48fj6tWruHHjBiQSCbZs2WJY+VKvrDYrICAAffv2RWRkJLKysjB27FiMGjWqWMwBAQHw8PDA33//jalTp0IikZTYpkZFRWHt2rVo2LAhbt++Da1Wi4ULF8Lb2xvJyckICQnB48ePUa9ePaSlpRmOf/nyZaxYsQJ5eXmQSqWYMmUK/Pz8cOjQIfz+++/geR4JCQmoXbs2RowYgV27duHevXsYO3ZssbmYAaB169aYMGECIiMj8fjxY4wfP95wXl9++SWOHj0KsVgMFxcXzJ07F87OzggODka1atVw584djBw5Er///jvc3d0RExOD9PR0jBgxAqmpqYiOjkZeXh7WrVuHZs2amfjTUVxeXh6ysrKKrPA6YMAAKBQKw8JUS5cuxZ9//omcnBwwxrB48WJ4e3sjJCQEcrkct27dQlpaGgICAuDk5IRTp04hJSUFixcvRqdOnaBWq7Fq1SpcunQJOp0OLVu2xJw5c4osyFWazp07o3v37tizZw+mTZtmuI+7urqWeH8WiUQ4cOAAwsPDIRKJUL16dSxfvhzx8fFF7pMHDx5EREQEtmzZAo1GA7lcjpkzZ8LDwwNz5sxBcnIyPvjgA2zfvh1Xr17FqlWrkJeXB5FIhEmTJsHf37/EeD/77DMsXrwYXl5ehlURC7P056N58+YIDg7Gjh07sHbtWsTExGDlypVQq9VISUlB586dsXTpUqxduxaPHz/GtGnTsGLFCjDGSixnTP369TF37lxwHIfhw4ejb9++xRa+KYzneYSGhiIuLg67d+9G9erVARQsdLZ48WKcP38eNWrUQI0aNQzTJWZlZWHJkiW4desWNBoNOnXqhBkzZpS+gI7lV4C2HK1Wy9zd3VlycjJjjLEff/yR7d27lzHG2KBBg9iuXbsYY4wlJCSwbt26saysLObv78+uXbvGLl68yJo3b84uXbrEGGNs9+7dbPDgwcXq+PHHH9m4ceMM9X3xxRfs3r17jLHna9XzPM/ee+89dvfuXcYYY0lJSaxFixaGdez15cqKt7ANGzYY4mWMsY8++oitX7+eaTQa1q1bN/bbb78Z6vH19WVXr141nM/Dhw8ZY4xdvHiRtWjRgt24cYMxxtgHH3zAAgMDmUqlYmlpaczd3Z0lJSW9zuUnhFixmTNnsm+++YYxVtCm9OzZk2k0GsYYY+vXr2eTJk1iarWa6XQ6FhISwubOncsYY8zf358tXbqUMcbY0aNHWfPmzdnNmzcZY4x98sknbMuWLcXqKq3N0h9v7ty5jOd5lpiYyDp06MDi4uKKHcPf359t2rSJMcbKbFP1bdtff/3FGGNs+/bt7N133zXEt3btWsYYY/fu3WOenp7s4MGDLD09nXXq1InFxMQwxhi7desWa9++PYuPj2cHDx5k3t7eLCEhgel0OtanTx82efJkptPp2M2bN1nr1q2ZTqcrFq+bmxvbuXMnY4yx2NhY1qpVK5afn88OHDjAAgMDWU5OjuHa6O8h7733Hps1a5bhGO+99x6bNGkSY4yxmJgY5ubmxk6cOMEYY2zJkiVszpw5pfx0Te/bb79lHh4eLCAggE2bNo3t37+f5ebmMsYYu3r1quGaMMbYV199xT766CPGWMHnbPjw4UytVrPHjx8zNzc39u9//5sxxtiOHTvY2LFjGWOMbdy4kYWFhTGe5xljjK1evZrNnz+/WBwHDx5kEyZMKLZ9165d7MMPP2SMMcN9vLT7882bN1mHDh1YQkICY4yx8PBwNnfu3GL3ybt377J+/fqx9PR0xljB56JLly4sJyeHXbx4kfXt25cxxlhGRgbr0aMHe/DgAWOs4PPo5+fHHj16VCxOfWxr1qxhI0aMYBqNhl27do35+/szxpjZPx+F4y7s1KlTrE+fPowxxj777DN28eJFxhhj2dnZrEOHDiw2NrZI/MbKlUdcXBxbvHgxCwgIYOvWrSsx1p49e7KpU6cyNzc3dvr06SLv79ixg40ePZqpVCqWk5PDBg8ezGbOnMkYYywkJMTwOdNqtWzatGls27ZtpcZSqXuGxWIxevXqhaCgILz99tvw8fFB165dkZGRgbi4OAwfPhxAwVLIx48fL7Z/8+bNDYtvDB06FKGhoXjy5InhrxIA8Pb2xtq1axEcHIzOnTtjzJgxaNy4cZHjcByHrVu34vTp0/jll1/wv//9D4wx5OXllSvekrRv397wF3PLli2RmZmJe/fuQaVSoUePHgAKVvjr0aMHzp07hw4dOqBu3bpFvlpo0KABWrZsCaDgaxMHBwfIZDIolUrY29sjMzOzWA8PIaRy8vT0NPSanD17Fp999plhSfXg4GB8+umnhrL6NqZhw4aoWbOm4evORo0aITMzs8Tjl9Rm6Y0aNQocx6FOnTrw9fVFZGRkiT1a+vbYWJtar149tGjRwlDXjz/+CKDgK96ZM2cCABo3bowOHToAAK5du4ZGjRoZviJ+88034eXlhejoaHAch9atW6Nu3boACtpNHx8fiEQiNGzYECqVCnl5ebC3ty8Wb7du3QAA7u7uUKvVyM3NxdmzZzFkyBBDT9jo0aOxdetWqNXqIueo1717d8O1BgpWAtVf6+jo6BKvtTmMHTsWw4cPx6VLl3Dp0iV8/fXX+Prrr3HgwAG0adMG1apVw969e/HgwQNERUUVuR7+/v6QSqVwdnaGnZ1dkXPIyMgAAJw+fRpZWVmGsasajQY1atR4qRjlcnmR16Xdn8PDw+Hj42P4mb7//vsACsaoFr5P6nv19e8DBZ+9FxdBiYmJQUpKSpHfEY7j8Pfff6NevXolxjp58mRcuHABGzduxDvvvGPYLtTng+M4w/ULCwvD2bNnsXXrVty5cwcqlarItwJ65S1XGrFYDJFIBI7jIBKV/Ajb3bt30aZNGyxfvhwhISE4dOiQ4ed24cIF9OvXDzKZDDKZDP379zcsfHb69GnExsbiwIEDAGD0uYhKnQwDwKpVq3Dr1i2cP38e27Ztw5EjR7BkyRIAKLJW/Z07d4p9aEsaB/XitoYNG+LYsWOIiorCxYsXMXbsWISGhhYZDJ+bm4vBgwfjnXfeQdu2bTF06FAcP368xOWiS4p3/fr1xcoV/qXnOA6MMcPXVYUxxgzLfL74NcSLK0OV+vUBIaTSK9w+8DxfpC3heR4ajcbwunDboU+YjSmpzdIr3PbwPF/qjVEfo7E2tbS6Squ3rLZTKpW+cltpY2NjqFd/zJKurb6NLnyOei/WXd7rbUpXrlzBH3/8gfHjx8Pf3x/+/v6YOnUq+vXrh8jISMjlcixZsgRjx45Ft27d4Orqip9++smwf3muH8/zmD17tqEDKCcnByqVqtwxXr9+HW5ubkW2lXZ/FovFRX4G+fn5ePToEYDivwedOnXCunXrDNsSExNRq1YtXL582bBNp9OhSZMm2L9/v2FbcnIylEplqfFKJBKsXr0aQ4YMgZOTU5E6hfh8xMbGGq7fe++9h2bNmsHX1xe9e/fGn3/+WWK+Up5yycnJmDBhguH1tm3bEB0dje+//x5arRaBgYGYMmUKbG1tS4zrjTfewLJlywAAV69exeTJk7F79+5i5w0Uzc94nsf69esNQ1ufPn1a7He8sEo9m0R6ejq6du0KJycnvP/++5gyZQpiY2OhUCjg7u6Ow4cPAyj4cI8cORJZWVlF9o+LizM8sbhv3z60adMGjo6ORcrs3r0bs2bNgo+PD6ZPnw4fHx/89ddfAJ6vN3///n1kZ2djypQpCAgIQFRUFNRqNXieL1KutHjLy9XVFRKJBL///juAgg/hb7/9hs6dO7/aBSSEVEm+vr7Ys2cPNBoNeJ7H999/jy5dupitPn1bnJCQgMjISPj5+ZVZ3libWhpfX1/s27fPUFdUVBSAgl7xO3fu4Nq1awCA27dv49KlS2jfvv3rnlqJMRw8eNDQg7Zz5060a9euxJu7tVAqldiyZUuRBDAlJQXZ2dlwc3NDZGQk/P39MWrUKLRq1QrHjx+HTqd7qTp8fHzw/fffG36Oc+fOxZo1a8q175kzZ3D69OliD3aVdn/u0KEDLly4gMePHwMA9u7di5UrVxY7bqdOnRAZGYn//e9/hnoGDBiA/Px8iMViwx+Inp6euH//Pi5dugQAuHnzJnr27Ink5OQy427YsCG++OKLIucpxOfj2rVr2LNnD8aMGYOnT58iNjYW06ZNQ48ePZCUlIT4+Phi+Yqxcnq1a9fGkSNHDP9q166Ne/fuYe7cuThw4ACGDx9eaiIMFE3uv/jiC+h0OixcuBBAwbU6fPgwVCoVVCoV/vOf/xjK+vj4YMeOHWCMQa1WY+LEidi1a1ep9VTqrkClUomJEyfi/fffh1wuh1gsxuLFiwEAq1evxsKFC7Fz505wHIclS5bA2dm5yP41a9bEunXr8OjRIyiVSqxYsQJAwV9Qc+bMwZEjRzBo0CBER0ejT58+sLW1Rd26dREcHAwA6NWrF4KDg7F+/Xq8/fbb6N27N2QyGdzc3NC0aVPcv38fjRo1MpTbuHFjqfHu2bMH169fN/Rql0QqlWLz5s1YvHgxNm7cCJ1Oh08//RQdO3Y0NPqEEGLMxIkTsXz5cgwaNAharRYeHh6YO3eu2ep7+PAhhgwZgvz8fMyZMweurq4ACqbICgoKMgw30GvWrFmpbWpZScP8+fMxa9Ys9O7dG3Xq1DEM71AqlVi/fj0WLVqE/Px8cByHZcuWwcXFBX/88Ue5z2PgwIFYvHgxWrduXWqZYcOGITExEcOHDwfP82jcuDFWrVpV7jqE4OLigi+//BJr165FUlISbGxs4ODggKVLl8LV1RVBQUH4/PPP0b9/f2i1WnTp0sXw0GF5ffLJJ1i+fDkGDx4MnU6HFi1alDpN1uXLlw0zMXAch1q1amH79u3F7uGl3Z+rVauG6dOnY/z48QAAZ2dnLF26FPfu3Suyf9OmTREaGoqpU6eCMWZ4QNTe3h5NmzaFjY0Nhg0bhv3792PDhg1YsWIFVCoVGGNYsWIFGjRoYPS8Bw0ahIiICFy9ehWAZT4f8fHxhusnEomgUCiwatUqw+/DhAkTMHjwYNjZ2aF27drw8vLC/fv30alTJ3Tv3h3Tp0/HggULyixXlleZkg4o+KZl/fr1GDx4MDw8PBAUFIT4+Hj069cPTk5ORYaofvHFF1iyZAn69+8PjUaDzp07G37eJeFYSX3fBFFRUVi0aBF++eUXoUMhhJBKS//kf1kJJCGEmFOlHiZBCCGEEEJIWahnmBBCCCGEVFnUM0wIIYQQQqosSoYJIYQQQkiVZfHZJFJSsowXMoHq1e3w5En5J3+2NGuOz1KxOTs7mL0OQqoaS7Sx1tJ+URxlx1FR2lhL5QV61vLzEoK1n7tQn9lK2zMskRRfMMOaWHN81hwbIUR41tJGUBxFWUsc1q4qX6eqfO5lqbTJMCGEEEIIIcZQMkwIIYQQQqoso2OGeZ7HggUL8Pfff0Mmk2Hx4sVFVvnQl5kwYQK6deuGkSNHmi1YQgghhFiGsfv/jh07cPToUQBA165dMWnSJOTn52P69OlIS0uDvb09li9fDqVSKdQpEFIuRnuGjx8/DrVajX379uHzzz9HWFhYsTLr1q1DZmamWQIkhBBCiOWVdf9/8OABfvrpJ+zduxf79u1DREQE4uLisGfPHri5uWH37t0YNGgQNm9wbcSHAAAgAElEQVTeLOAZEFI+RpPhK1euwNfXFwDg6emJ69evF3n/119/Bcdx8PPzM0+ElYj03Bk4vjcCyvZvAf7+sDn4A0BrnhBCCLFCZd3/69Spg2+++QZisRgikQharRY2NjZF9vHz88OFCxcEiZ2Ql2F0mER2djYUCoXhtVgshlarhUQiwa1bt/DLL79gw4YN+PLLL8tVYfXqdhZ7mtFqppVhDJgzB1i6tOC1szNw5gwcT58GTv4G7NwJ2NgIGuKLrObaEUJIIePCTgIAvg0JEDiSyq+s+79UKoVSqQRjDCtWrEDLli3h4uKC7OxsODgU3D/s7e2RlWV82jRL5gV6lrzH/XrhHgCgV6c3LFZnWej+XpzRZFihUCAnJ8fwmud5SCQFux0+fBjJyckYM2YMHj16BKlUivr165fZS2yp+e2cnR0sPndhaWzXr4Zi6VLo3nDB023h0Hp6wTk7FZqR70K6fz/ydQxZW7YDHCd0qAAsd+3oF5IQQqxXWfd/AFCpVJg9ezbs7e0xf/78Yvvk5OTA0dHRaD2WnvfW0vnBk8xc5OZrkZiUCYlY2HkLrCk3KolQeYHRZNjLywunTp1Cnz59EBMTAzc3N8N7M2bMMPx/48aNqFmzJg2XeIE08hwUSxZCV78Bnvz8O1jt2gVvuLgg44fDcBraH/JDB6Bp1xH5H0wQNlhCCCHkmbLu/4wxfPLJJ+jQoQMmTJhQZJ8zZ87Aw8MDZ8+ehbe3txChWw2eMZy48hDJ6Xk4+2cCPh7QCk0bVBM6LPICo8lw9+7dERkZiaCgIDDGsHTpUoSHh6NRo0bo1q2bJWKsuPLyoJg6GUwkwtPt/36eCOvZ2uLptztRvWtH2C9eAHXvvuDr1RckVEIIqaho6IR5lHX/53ke0dHRUKvVOHfuHABg6tSpGDlyJGbOnImRI0dCKpVi9erVAp+FsCKvJSI5PQ8cgCdPVVi66wqUjjZwdrKFl5szurdtKHSIBOVIhkUiEUJDQ4tsa9KkSbFykydPNl1UlYTtts2Q3L2D3I8+hdarbYll+Dp1kTNvERw+mwT70HnI2rrdwlESQgghxRm7/8fGxpa434YNG8waV0Vy8uojiDhgSFdXuNatht+i43En8Sn+js9ATp6GkmErYTQZJq+Ge5oJuy/Xg3dyQu6MWWWWzR/5HuTffg2bHw8g97Pp0DVrbqEoCSGkYtL3BhNirdIy83E/OQv1atrBTi5F0pNcvPVmTbRqUgO/Rz/Aw5QcPHicjYa1FMYPRsyKVqAzE9ttWyDKyEDup/8H5mDkAQKRCLkzZoNjDHaris/jTAghhJCK5Y/bKQBQLNkVizi0blKwEMmJKw8sHhcpjnqGzUGlgu23X4Ov5lTuh+LUPXpB0/ot2Px8GDkPH4BvQF+dEEKIHvUEk4rm7J8JAIAGzsV7fuvXtIdMKsKNu08sHRYpAfUMm4HNz4chSk1B/qhgMEU5pwnhOOR9+DE4noftDho3TAghhFRUPGN4nJEHha0U9rbSYu9zHIfa1e2Q9jQfqZl5AkRICqNk2Axsv/0ajOOQ9/4HL7WfauAQ8Eol5Lt2APn55gmOEEIIIWaVkJoDtYZHreq2pZaprSx47+/4DEuFRUpBybCJif+6AenlaKi7dQfv4vpyO9vaIn/UaIjS02Hz61HzBEgIIYQQs7r9oCDBLTsZtiso+zDTIjGR0lEybGLyA/sAAPkjg19p//zAUQAAm/17TRYTIYRUBePCThr+ESKk/yU8BVB2MlxdYQORiMP1u2mWCouUgpJhU+J52Px4ALxjNai793ylQ+iaNYfGwxOyk8fBpaaaOEBCCCGEmNu9pCxIxBwc7WWllhGJOCgdbJCRpYJWx1swOvIiSoZNSHrxPMSPHkLVbwAgl7/ycVTDA8HpdLA5fMCE0RFCCCHE3PLVWiSm5qCGoxwijiuzrNLRBjwDHqXkWCg6UhJKhk3I5uAPAADV0BGvdZz8wcPBRCLID1EyTAghhFQk95OywADUqGa8U0zpWFDmfnKWmaMiZaFk2FS0Wtgc/Qm6WrWh6ezzWoditWpB07EzpJejIUpOMlGAhBBCCDG3e0kFiW15kuEa+mQ4iZJhIVEybCLSS1EQpadD3asvIBa/9vHUffoBAGT/pVklCCGEkIrCkAw7Gk+GnRxkEHHUMyw0SoZNRJ+0qnv3McnxVL0LkmGb//xskuMRQgghxPzuJT6FnY0EDnbFF9t4kVgkgpODDR48zoaOp4fohELLMZsCY7D59Sh4ewXUPl1Ncki+YSNoPDwhjTgLLjMDrJqTSY5LCCEVBU2RRiqa3HwNkp/koW4NO3BGHp7TUzrKkf5UhcTUXDSoVXzpZmJ+1DNsAuJbf0N87y40Ae8ANjYmO666Tz9wWi1kx3832TEJIZb11VdfITAwEEOGDMH+/ftx//59jBw5EqNGjcL8+fPBP+sN2rRpE4YNG4agoCBcu3YNAEotSwixTi8zREJP6WhTZF9ieZQMm4Ds2Wpxql6mGSKhp+rRu+D4J46Z9LiEEMuIiorCH3/8gT179mDnzp1ISkrCsmXLMGXKFOzevRuMMZw4cQI3btxAdHQ09u/fjzVr1mDhwoUAUGJZQoj10o/9Lc/Dc3o1nyXOd5OemiUmYhwNkzABm9/+CyYWQ/1OD5MeV+feCrradSA7fQLgeUBEf7sQUpFERETAzc0Nn376KbKzszFjxgz88MMPaN++PQDAz88PkZGRcHFxgY+PDziOQ7169aDT6ZCeno4bN24UK9u9e/cy66xe3Q4Syes/xGuMs7OD2et4HZaOz1quh7XEUVXFJ2cDeN7bWx7VHeWQiEW484iSYaFQMvyauMwMSK5ehta7HVh1pYkPzkEd8A5s9+yCJPZPaN9qY9rjE0LM6smTJ0hISMDWrVvx8OFDTJw4EYwxw1hCe3t7ZGVlITs7G05Oz58L0G8vqazxOnPNczKFODs7ICXFur/StWR81nI9XoyDEmPLi0/OglQsgsLW+MNzemIRh8a1FbiXlAWVRgcbqfn/mCVFUVfja5JGnAPH81C/HWCW42sC3gEAyE4eN8vxCSHm4+TkBB8fH8hkMri6usLGxqZIQpuTkwNHR0coFArk5OQU2e7g4ABRoW+D9GVJ+YwLO0kP4BGLUml0SErPRXVHm3I/PKcnk4qh4xnNNywQSoZfk+x0QWNrrmRY7fc2mEhE44YJqYC8vb1x7tw5MMaQnJyMvLw8dOrUCVFRUQCAs2fPom3btvDy8kJERAR4nkdCQgJ4nodSqUTLli2LlSWEWKdHKTlgDFA6vPyD9DWdCsYN30mgoRJCoGESr0l2+gR4x2rQtvE2y/FZdSW03u0guRwNLuMJmFN1s9RDCDE9f39/XLp0CcOGDQNjDPPmzUODBg0wd+5crFmzBq6urujZsyfEYjHatm2LwMBA8DyPefPmAQBmzpxZrCwhxDrFPy7o1a3+EjNJ6Dk72QIA/peQadKYSPlQMvwaRHfvQHz/HlR9+gMS811KdcA7kF6KgvTcGaj7DzJbPYQQ05sxY0axbbt27Sq2bfLkyZg8eXKRbS4uLiWWJYRYnwf6h+deoWfYXi6BrY2YeoYFQsMkXoPszCkA5hsioafu6l9Q37kzZq2HEEIIIa8m/nEWxCIOTgrZS+/LcRxqVrPFkywV0p/mmyE6UhZKhl+DuccL62k9vcArHCCNOGvWegghhBDy8nie4eHjHNStYQex+NVSKxo3LBwaJvGqtFpIz52BrvEb4N9wMW9dEgk0HTvB5vjvECUlgq9T17z1EUKIgGgWCFLRJD/JhUqjg+w1pkVTOhQkww9TstG2eS1ThUbKgXqGX5Hk+jWIsp5C7fe2RerT+HQFAOodJoQQQqzMo5SCqRGrv8J4Yb3qDrIixyKWQ8nwK5JePA8A0HTsbJH6ND6+BfVSMkwIIYRYlaT0gsVuqtm//HhhPVsbCezlEjxMpWTY0owmw/ppfgIDAxEcHIz79+8Xef/777/H0KFDMWzYMJw6dcpsgVob6cULACyXDGvdW4N3coIs4pxF6iOEEEJI+eiTYcfXSIY5jkP9mvZ4/CQXao3OVKGRcjCaDB8/fhxqtRr79u3D559/jrCwMMN76enp2L17N/bu3YsdO3ZgwYIFYIyZNWCrwBikUeehq98AfMNGlqlTLIamsy/E8fcgir9vvDwhhBBCLCIpPRciDi+1DHNJ6tdSgDEgMc38y6qT54wmw1euXIGvb8FX9J6enrh+/brhPaVSiSNHjkAqlSI1NRWOjo4vvQRhRSS+fQuitDSL9QrrqfVDJSKpd5gQQoh5GftmGCjoFOvRowdUKhUAgDEGX19fBAcHIzg4GKtXr7Z02BbHGENSWi4c7GQQiV4vB2pQ0x5AwUN0xHKMziaRnZ0NhUJheC0Wi6HVaiF5tsiERCLBrl27sHHjRgQHBxutsHp1O0gkr/605ctwdnYwz4F/vAoAkHcPgPw16njp+Ab0AWbPgOOl88C/Jr5yveVhtmtHCCEWpJ+Z4tsQ806BWRkV/mY4JiYGYWFh2LJli+H9c+fOYfXq1UhNTTVsi4+Ph7u7O7Zu3SpEyILIytMgV6VFg2oK44WNeJyZBwC4cCMJXVrTzFGWYjQZVigUyMl5Ppib53lDIqz33nvvYcSIEfjwww9x8eJFdOzYsdTjPXlima5/Z2cHpKRkmeXYDsdOQg4g3d0Lules45Xic26IGjWdwU6eQvrjp4CZeuHNee1erIcQQoh1KuubYQAQiUQIDw/H0KFDDdtu3LiB5ORkBAcHQy6XY9asWXB1dS2zHkt2kumZ8v7z+E5awTGdbOGgePmlmAuTygryq+w8rdnukXTvLc5oMuzl5YVTp06hT58+iImJgZubm+G9O3fuYM2aNdi4cSOkUilkMhlEoso/QYX04nnwSiV0bs0sWzHHQdOhE2yO/gTRg3jwjRpbtn5CCCFVhrFvhrt06VJsH2dnZ0yYMAG9e/fG5cuXMX36dBw8eLDMeizVSaZn6g6fuDsFPeNymQhZ2a+/epydXILUjDyzdEpZqrPrVQmVqBtNhrt3747IyEgEBQWBMYalS5ciPDwcjRo1Qrdu3dC8eXMEBgaC4zj4+vqiffv2lohbMKKHDyB++ACq3v3M1jNbFk3HgmRYevE8VJQME0IIMZPyfDP8olatWkEsLujlbdu2LZKTk8EYq9TPE5liJonCnBQ2SEjNQU6+Bvby13sgj5SP0WRYJBIhNDS0yLYmTZoY/j9p0iRMmjTJ9JFZKUvPL/wifb3SqAtQjRgpSAyEEEIqv7K+GS7Npk2b4OTkhA8//BBxcXGoV69epU6EASBZnwzbmSoZliEhNQePUnLg1tDJJMckZaPlmF/S8/mFOwlSv9a9NXh7hSEpJ4QQQszB2DfDJZkwYQKmT5+OM2fOQCwWY9myZRaO2vKS0nNhZyOBXGaacc/VFAVJdXJ6LiXDFkLJ8EuSRp0Hs7OHtvVbwgQgkUDbrj1kp0+CS00Fq1lTmDgIIYRUasa+GdY7efKk4f/VqlXDtm3bzB6btdDxPB4/yUPjOg4m6wHX9zAnWXgsdVVW+Z92MyEuLQ2Sv+OgadseMDJuypwKD5UghBBCiDBSM/Kh4xnqKO1Mdkz92OPk9DyTHZOUjXqGX4I++dR0Ema8sJ4hGb54Huq+/QWNhRBCTEU/JzAhFcWxyw8AALkqrcmOKZeJIZWIDA/mEfOjnuGXIPTDc3qaNt5gUimkUTRumBBCCBHK0xw1AKCaiWaSAACO4+BoL8PjJ7ngeWay45LSUTL8EqRR58GkUmi82gobiK0ttJ5ekFz7E1y29c4XSAghhFRmmc+SYVNNq6bnaCeFVseQ+vT15y0mxlEyXF7Z2ZBc+xPat9oAtrZCRwNNx87geB6SS9FCh0IIIYRUSfqeYQc7084H7PDsIbqUDBo3bAmUDJeT9HI0OJ0Omk7FV9wRgn5qNxoqQQghxo0LO2n4R4ipPM1Vw14ugURs2nRKn1xHxiaa9LikZJQMl9Pz8cLCzC/8Ik37jmAcZ5j3mBBCCCGWk6fSIk+lM/kQCQBQ2BYkw9m5GpMfmxRHyXA5SaMugHEcNO07Ch0KAIBVc4KuhTukVy8DKpXQ4RBCCCFVin62B1M+PKen7xnOyqNk2BIoGS4PtRrSK5ega+EOVs16VoPRdOwELj8fkj9jhA6FEEIIqVL0ybA5eoZtbSQQiTjqGbYQSobLQRLzB7j8fMHnF35R4fmGCSGEEGI5SWnmS4Y5joPCVoqsPLXJj02Ko2S4HKxlfuEXPV+JjpJhQgghxJKSn5gvGQYAB1sp1BoeufmmW9CDlIyS4XLQJ5vWlgzzdepC1/gNSKOjAJ4XOhxCCCGkykhKy4VYxMFebp7FfBXPxg2nZtL0auZGybAxOh2kURehe8MFfO06QkdTjKZjZ4gyMyC++ZfQoRBCCCFVAs8Ykp7kwtFeBo7jzFKHw7MZJWiuYfOjZNgI8c2/IHqaCbWVzC/8Iho3TAghhFhWRpYKag1vtiESwPOe4ZQMWoXO3CgZNsJah0joGRbfiKb5hgkhhBBLMOdMEnoK6hm2GEqGjdAvaqHpYB2LbbxI59oUfE3ngjgZEzocQgghpNJ7PsewaZdhLszQM0xjhs2OkuGyMAbpxfPQ1aoN3sVV6GhKxnHQdOwMcWICRPH3hY6GEEIIqfTMOa2ankwiho1UTMMkLICS4TKI7t2FODmpYIiEmQbIm4JhqASNGyaEEELMzjBMws58yTBQsBJdWmYeeJ6++TUn88wHUkkY5he2ssU2XqQfwiGNugBV4CiBoyGEvCgtLQ1DhgzBt99+C4lEgpCQEHAchzfffBPz58+HSCTCpk2bcPr0aUgkEsyePRseHh64f/9+iWUrk3FhJ4UOgZCXdi8pC3KZGDKp2Kz1KGylSM3MR0a2CkpHuVnrqsoqV6tqYoZkuIN1J8Na99bg7RXUM0yIFdJoNJg3bx7k8oIb2bJlyzBlyhTs3r0bjDGcOHECN27cQHR0NPbv3481a9Zg4cKFpZYlhAhLo9UhO0+DamYcIqH3fEYJGjdsTpQMl0F68Tx4x2rQtWgpdChlk0igbdcekn9ug0tJEToaQkghy5cvR1BQEGrVqgUAuHHjBtq3bw8A8PPzw/nz53HlyhX4+PiA4zjUq1cPOp0O6enpJZYlhAgr+UlBYmrO8cJ6z+capnHD5kTDJErBJSdDcvcOVO/0AMTm/RrEFDQdO0N2+iSkUReg7jdA6HAIIQAOHToEpVIJX19fbNu2DQDAGDNM0m9vb4+srCxkZ2fDycnJsJ9+e0lljale3Q4SifnbLGdnB7PXYS7miN1aroe1xFGZWeLhOT3qGbYMSoZLYe3zC7/IsPhG1HlKhgmxEgcPHgTHcbhw4QJu3ryJmTNnIj093fB+Tk4OHB0doVAokJOTU2S7g4NDkfHB+rLGPHmSa9qTKIGzswNSUown5tbK1LFby/V4MQ5KjM0j+YkFk2Fbml7NEmiYRClkFyIBABorXXnuRZo23mBSqWFeZEKI8L7//nvs2rULO3fuRIsWLbB8+XL4+fkhKioKAHD27Fm0bdsWXl5eiIiIAM/zSEhIAM/zUCqVaNmyZbGyhBBh6XuGLTFm2F4uhYjjqGfYzCgZLoX0wnkwW1to32ojdCjlY2sLracXJLF/gssWvoeCEFKymTNnYuPGjQgMDIRGo0HPnj3RqlUrtG3bFoGBgZg8eTLmzZtXallCiLCS0nPBcc97bc1JJOJQo5oNjRk2M6PDJHiex4IFC/D3339DJpNh8eLFaNy4seH9HTt24OjRowCArl27YtKkSeaL1kK4J+kQ37wBjY8fIDP/X36mounYGdJLUZBcvgTN2wFCh0MIKWTnzp2G/+/atavY+5MnT8bkyZOLbHNxcSmxLHk9+uncvg2hdpK8HMYYktJz4WArhUhkmfUHJGIRUjLykZuvhZ2cRreag9Ge4ePHj0OtVmPfvn34/PPPERYWZnjvwYMH+Omnn7B3717s27cPERERiIuLM2vAliCNjgLHmNUuwVwaWnyDEEIIMZ+sPA1y8rUWGS+s56SwAQAkpucYKUleldFk+MqVK/D19QUAeHp64vr164b36tSpg2+++QZisRgikQharRY2Njbmi9ZCpBVsvLCepn1HMI6DNIrGDRNCCCGmlpxuuYfn9PR16ccqE9Mz2t+enZ0NhUJheC0Wi6HVaiGRSCCVSqFUKsEYw4oVK9CyZUu4uLiUeTxLTfsDvMaTtJcvAhIJnHoFAHZ2pg2qEJM/6evsALRuDdmVS3CuZvNaQzzoKWRCCKnajA2TBID09HQEBQXh559/ho2NDfLz8zF9+nSkpaXB3t4ey5cvh1KpFOgMTM+SD8/pVVMU1JWQRj3D5mI0GX5xyh+e5yGRPN9NpVJh9uzZsLe3x/z5841WaIlpf4DXmOomOxs1r1yBto03MnJ0QI55HkYz11Q8Cu/2sL12DU+On4W2XYdXOoalpgmihJsQQqxX4WGSMTExCAsLw5YtWwzvnzt3DqtXr0Zqaqph2549e+Dm5obJkyfj6NGj2Lx5M+bMmSNE+GaRJEDPsD7xTkylnmFzMTpMwsvLC2fPngUAxMTEwM3NzfAeYwyffPIJmjVrhtDQUIgrwOIUxkgvR4PT6SrcEAk9w3zDNMUaIYSQ11DWMEkAEIlECA8PL7JgTOF9/Pz8cOFC5boXCZEMy2ViyKQiJFLPsNkY7Rnu3r07IiMjERQUBMYYli5divDwcDRq1Ag8zyM6OhpqtRrnzp0DAEydOhVt2lSQ6chKIL2oHy9cMRbbeFHhxTfyJk8ROBpCCCmZfkYHYr3KGiYJAF26FO80ys7OhoNDwbd+1rZqYmGv+s3kvaQsyKQiOCvtDatDWkINRzmS03PhVN0O0te8VvStbHFGk2GRSITQ0NAi25o0aWL4f2xsrOmjEpD0wnkwjoOmfUehQ3klfN160DV6A9LoiwDPAyKaSpoQQsjLMzZM0tg+1rRqYmGvOhRQx/PIzFZB6ShHdo7KDJGVzt5WCp4BN249Rn1nhfEdSmEtqyWWRqhEnTKlwvLzIb16GdpWHmCO1YSO5pVpOnaCKCMD4ribQodCCCGkgiprmGRZ+5w5cwZAwaqJ3t7eZo3RklIz88Ezyw6R0DOMG6YZJcyCkuFCpDFXwalUFXaIhN7zccM03zAhhJBX0717d8hkMgQFBWHZsmWYNWsWwsPDceLEiVL3GTlyJG7fvo2RI0di3759lWIhLj39TBKCJMM0o4RZ0VImhRjmF+5YMR+e0zMkw9EXkD/uQ4GjIYQQUhEZGyapd/Lk8/Hftra22LBhg9ljE4IQcwzrUc+weVHPcCHSyAgAqHArz71I16Qp+JrOkJ6PBBgTOhxCCCGkwtPPJFHNXmrxuhW2UsgkIiSmUs+wOVDPsJ5KBWn0BWhbuIM5OwsdzevhOKh9fCE/fAjif25D96bxcV6EEFLVFJ7R4tuQAAEjIRWBPhl2sLN8zzDHcbC3leJRag54xiCy4EwWVQH1DD8jvRwNLj8fal8/oUMxCY3v2wAA6dnTgsZBCCGEVAaJ6bmwl0sgEQuTOlVTyKDjGdIz8wWpvzKjZPgZ6bmCp1/1SWRFp/btCgCQRZwVOBJCCCGkYstTaZGZrRZkvLCeftxwAo0bNjlKhp+RnTsDJhJV+Jkk9PjGb0DXsBGkkWcBnU7ocAghhJAKK/mJcA/P6VVT2AAArURnBpQMA+CysyD54wq0bbwq9PzCRXAc1L5dIcrIgOT6NaGjIYQQQios/bRq1aygZ5iSYdOjZBgF8/FyWi00Pl2FDsWkNM+GSkjP0VAJQggh5FUlCTitmp6jvRQcR8MkzIGSYTxPFvXjbCsL9bPkXnbutLCBEEIIIRWYNSTDYpEIDnYyJKTkgNG0qSZFyTAKHp5jNjbQtOsgdCgmxWrXhrZZc0ijLgBqtdDhEEIIIRVSYlouZFIR7OXCzkjrpJAhV6VFRjbd002pyifDXHoapNevFSTCtrZCh2Nyat+u4HJzIb1ySehQCCGEkAqH5xkS03JRt4Y9OIHn963uUPAQ3cOUbEHjqGyqfDIsfTb1mMancswv/CLDfMPPpo4jhBBCSPmlZORBq+NRr4a90KHA6dmMEo9S6CE6U6ryK9DJTh4HAKj9uwkciXloOncBE4shO30SuTNmCx0OIaQKK7ziGyEVxaNnSyCrNFqBIymcDFPPsClV7Z5hxiA7eRx8jRrQvtVG6GjMglVzgrZte0iuXgaXniZ0OIQQQkiFkvAsGdbP8yskBzspJGIRHqZSz7ApVelkWHzjOsRJiVC/3Q0QVd5Loe7WHRzPQ3aaemUIIYSQl6FPhp0Uws0koScScahXww6JqTngeZpRwlQqbwZYDrKTxwAUJIuVmf78ZCeOCRwJIYQQUrEkpOZALOKgsJUKHQoAoL6zAmotj5SMPKFDqTSqeDJ8HIzjCnqGKzFtKw/oateB7NRxgOeFDocQQgipEHieITE9F9UUMsFnktBr4FzwIN9DeojOZKpsMsxlPYU0+iK0nm3AatYUOhzz4jioA96BKDUVkj//EDoaQgixOuPCTtIDfqSYlMw8aLS84cE1a5CWlQ8AeJRKD9GZSpVNhqVnToPTaqEOqNxDJPTU7/QAQEMlCCGEkPJKSNE/PCf8eGE9fWL+8DElw6ZSZZPhqjJeWE/j93bBFGsnfhc6FEIIIaRCeGR4eM56eobt5RLIpCLEUzJsMlUzGeZ52Pz2X/A1a0LbxlvoaCyCVXOCpl0HSK5eAZeaKnQ4hBBCiNVLSLOemST0OI6D0kGOx0/ykKcSfu7jyqBKJsOSK5cgSnkMVc8+gFgsdDgWo+7RGxxjsPn9v0KHQgghhFi9hJQcyCQi2FvJTBJ6SseCnuoH1DtsElUyGbb571EAgLp3X4EjsSxVn34AANl/fhY4Eq35M8wAABidSURBVEIIIcS66WeSqFPDDiIrmUlCT58MxydnCRxJ5VD1kmHGIPvPz2B29lD7vi10NBbFuzaBtoU7ZKdPgsumXyBCCCGkNPqZJOrXtBc6lGKUDnIAQHwy9QybQpVLhsW3b0Fy539QB7wD2NoKHY7Fqfr0A6dW06wShBBCSBn0K8/Vs8Jk2NFeBqlERD3DJiIROgBLk/33FwCAqooNkdBT9R0A+9XLITv6E1QDhwgdDiGVmkajwezZs/Ho0SOo1WpMnDgRTZs2RUhICDiOw5tvvon58+dDJBJh06ZNOH36NCQSCWbPng0PDw/cv3+/xLIVDc3fSyqiiGuJAID0LJXVjRkWiTg0cFYgPjkLWh0PibjitQvWxOjV43ke8+bNQ2BgIIKDg3H//v1iZdLT09GjRw+oVCqzBGlKNkd/AhOLoe7eU+hQBKFzbwVdozcgO/Y7kJ8vdDiEVGo//fQTnJycsHv3bnz99ddYtGgRli1bhilTpmD37t1gjOHEiRO4ceMGoqOjsX//fqxZswYLFy4EgBLLEkIs40lWQU5jTTNJFNa4tgI6nuERrUT32oz2DB8/fhxqtRr79u1DTEwMwsLCsGXLFsP7586dw+rVq5FaAabrEt35H6Qxf0Ad8A6YU3WhwxEGx0HVtz/stmyE7OwpqHv0FjoiQiqtXr16oWfP5394i8Vi3LhxA+3btwcA+Pn5ITIyEi4uLvDx8QHHcahXrx50Oh3S09NLLNu9e9lzo1evbgeJxPyz5Dg7O5i9DiHoe7F/Xj3wpfazluthLXFUBk+yVJBKRFBYWa+wXp5aBwA4dvkBxvdrKXA0FZvRZPjKlSvw9fUFAHh6euL69etF3heJRAgPD8fQoUPLVaGlGmqghEZha8EsCrIxwVbRYAgWw+hRwJaNqPafI8C7I0osYg3Xh5CKzt6+YKxhdnY2/vWvf2HKlClYvnw5uGdPptvb2yMrKwvZ2dlwcnIqsl9WVhYYY8XKGvPkSa4ZzqQoZ2cHpKRU7rGKL3N+1nI9XoyD2vFXp1LrkJmjRu3qtobfQWujn1Ei/Sl9y/u6jCbD2dnZUCgUhtdisRharRYSScGuXbp0eakKLdFQAyU0Toyh+q7vIZbLkebTDUzghkvQxtO1JZRvuEB0+DBS7yYChX6+loyNGmpSFSQmJuLTTz/FqFGj0L9/f6xcudLwXk5ODhwdHaFQKJCTk1Nku4ODQ5HxwfqyhBDze5hSMEuD0lEucCSlq+5gAw4FY5rJ6zE6ZvjFRprneUMiXJGIb1yH5NbfUL/TE8yhit9QOA75Q0eAy82FzbMHCgkhppeamopx48Zh+vTpGDZsGACgZcuWiIqKAgCcPXsWbdu2hZeXFyIiIsDzPBISEsDzPJRKZYllCbEUY88M/fDDDxgyZAhGjBiBU6dOAQAyMjLQoUOH/2/vzsOjqu89jr9nyWQmM9k3FklMaKMVjBIpUCmliCmWi22xLCESL8LTgrUqsiqyFSLgpeBWItVaaqNXQJAWWq5aWe+DXCqRxSQGFCUIsgRClskyk5k594+QsJqQhMw5Z/J9PQ8PMjNmPgmHyXd++X5/P7KyssjKyuKNN95QI3qbNRx1HBmqnWOYr2Q2GQlzWCitqMWnKGrH0bVmq9q0tDS2bdvG0KFD2b9/PykpKf7IdcNZN6wDoPaBkSon0QbXiFHYlz2Hdf1aXCMz1I4jREBauXIlFRUV5OTkkJOTA8AzzzxDdnY2y5cvJzk5mSFDhmAymejduzejR49uLEAAZs6cyZw5cy57rBD+0tTMUElJCbm5uaxfvx6Xy0VmZib9+/ensLCQYcOGMWfOHJXTt83XF7Ysa2hF0Kqo0GDKnW5KztcQHxWidhzdarYYTk9PZ9euXWRkZKAoCosWLWLVqlUkJCQwePBgf2RsO6+X4PVr8YWG4b73J2qn0QRv9+9S1yuNoO1bMZw5gxIXp3YkIQLO7NmzmT179lW3v/nmm1fd9thjj/HYY49ddltSUtI1HyuEPzQ1M3Tw4EF69eqFxWLBYrGQkJBAUVER+fn5FBQUMHbsWKKiopg9ezZxzXx/8ecsUYPm2vROltZgNBi4qVMYJg1vZ9g51sFXJyspq/XQ8zpbD6VF8WrNFsNGo5EFCxZcdlv37t2vetzWrdrdR9KyfQumb05Q89B4sGq3/8ffXCNGE7TvE6wb3qFm4qNqxxFCCKEhTc0MOZ1OQkMvFlV2ux2n00lycjI9e/bk7rvvZuPGjWRnZ/PSSy81+Tz+miVq0NxcjM+n8NU35YQ7LFRXu/2YrOXswfVvIvI/L+GWLs23gGpl2PPbqFWoa/ftzg1kffOvANSOfUjlJNpSO3wkisWCNfcvIP1GQgghLtHUzNC3DX3269ePvn37AvU/WS4sLPRv6BvgVGk1bo9P8y0ScPFY5mI5ia5NAr4YNpw5g+X9zXh63I7njl5qx9EUJSYG13/cj/nwIYL27FY7jhBCCA1JS0tj586dAFfNDKWmppKXl4fL5aKyspIjR46QkpLC7Nmzef/99wHYvXs3PXr0UCV7Wxw7c6FfOFT7P0kOtpiwW818fdqpdhRd09+2EC1kXfs2Bo+HmrEPgUb3ClRT7X9OwLphPdY3/kxdv7vVjiOEEEIjmpsZysrKIjMzE0VRePLJJwkODmbq1KnMmjWLt99+G5vNRnZ2ttqfRosdOVEBQHS49leGASLDrBw/46Tc6SLcoY/MWhPYxbDXi+2N11GsVly/vPbhEh1d3Q/64/luCsGb/oYz+zmU6Gi1IwkhAkTDaW5Cn5qbGRo1ahSjRl3+vbVbt27k5ub6JV972fd5CUajgehw7a8MQ/2OEsfPOCk+7SRViuFWCeg2Cct7mzEVH6V2ZEbHPX65OQYDtQ89jMHtxvrf+n4BE0IIIdqixuXhfIWLmHCrpneRuFRD0X70VIXKSfRLH3/TrWT74woAan79G5WTaFttxoP47A5sr70Cbm1PzgohhBDt5cuTFShAbIRN7SjXLeZCMdzQ3iFaLnCL4bw8LP/3Ee5Bg/HecqvaaTRNCY+gNmscplMnCX73HbXjCCGEEKr47Oh5ADpF6acYtgWbiYuw8eU35XISXSsFbjG8dCkA1bJ/7nWpmfgbFLOZkBUvgs+ndhwhhFDV+CVbG3+JjqPgaClGA8RF6us0N0dIEFW1Hk6d8++ezYEiIIthU9FnsHYtdXf0om6QTk7JU5mv6024ho/AfKgINm1SO44QQgjhV86aOo6dqiQ2wkaQWV/lUWxEfavE4eNlKifRJ339bV+nkGXPgaJQPf0p2U6tBaofn4JiMMCcObI6LIQQokPJ//IcCtA5xq52lBbrFFWfuaHNQ7RMwBXDpsICgjdugN69caffp3YcXfHeciuukRnw6afSOyyEEKJDyTtcAkBCnKOZR2pPmD2IEKuZz4rPS99wKwTWPsOKgmPeLAyKAgsWyKpwK1TNmIV1wzrszz2L62fDwWJRO5IQQkekx1bokavOy4EvzhIWEkS4Q3/f9wwGA52jQzhyooJjpyu5uVOY2pF0JaBWhi0fvIdlxzbcgwbDfbIq3Bq+hESYNAlT8VFsr76idhwhhBCi3RV8VYrHq5AQH4pBpwtpXS+0dxz84pzKSfQncIphlwv73KdRTCacCxbLqnBbzJ+PLzoa++8XYzxxXO00QgghRLvKO3ShRaKT/lokGnSJsWMyGtj3+Vm1o+hOwBTD9t8vwfzVl9RM+LXsK9xWUVE452VjqK7G8cxMtdMIIYSqZIu1wObx+jjwxVlCrGaiw/RxBPO1WIJMxEXaKD5dSWlFrdpxdCUgimHzvjxsLz+PNyGRqqfmqB0nILhGZ+LudzfBmzcRvH6t2nGEEEKIdpH/VSnVLg+JOm6RaJAQX7+y/XHRGZWT6Iv+i2Gnk9DHJmHw+ah8/g/g0O+PODTFYKDyxRx8dgeOGVMwHitWO5EQQghxw+3OPwVAUpdQlZO0XWKnUAwG2FN4Wu0ouqLvYlhRCJ32OObDh6j+1STqBgxUO1FA8SUl41y8FGNlBWGTJoDLpXYkIYRGSSuB0KPqWg95h0sIt1t03SLRwGox0yXaztFTlZw4W6V2HN3QdTFs++MKrO+uo653H6rmZasdJyC5RmdS+8AIgvb+m9Dpk0H2LxRCCBEg9h46g8+nkNwlTPctEg2+2y0cgC17v1Y5iX7othgO3rAO+7xn8MXGUfGnN2Q/3PZiMFD5/ArqeqVhXf0WIc8vVTuREEIIcUNcbJEInH15b4pzEBNu5aP8Uzhr6tSOowu6LIYt720m9LcTURyhlK3ZgK9LV7UjBTabjYq/rsZ7UzfsS7KxvfyC2omEEMLvpBUksJw8V8Whr8uIj7ThsAWpHeeGMRoM3Nw5FLfHx479J9SOowu6K4aDV79F2MMPQlAQFbmr8fa8Xe1IHYIvvhNl7/4Db5euOBbOJWTJQvD51I4lhBBCtMq/Pq5vI7g1MVLlJDfed24KJ8hkZEveceo8XrXjaJ5+iuG6OuzzZxP2+CMooaGUrdtI3d0/VDtVh+K7OYmyDf/Em3gz9uVLCfvVOAzOSrVjCSGEEC1yrryWXfmniAm30i0+8HahsphNpCSEU+Z0s/UTWR1uji6KYdOhIiJ+/lNCcl7C0/07lG36AE/vPmrH6pB8Scmcf29b/R7Em/5G5I/7E7R7l9qxhBAqkdYBoUfrdhyhzuPjloQIjAEyOHelnknR2ILN/OOjo1TXSu9wUzRdDBtKz2FfOI/Ie/oTtPff1A7/JWX/2iEnzKlMiY6mfN1Gqp+YivH4MSJ+/lNCf/MrjF8fUzuaEEK0u4Y3APImQJ/2fnaaPYWniQ6zkhxAg3NXCraY+F5iBFW1Hlb+vUDtOJqmyWLYdORz7PNnE3XX7YS8/Dy+uHjK/7qayj+uQnHof1PsgGCxUPXMPMo2vU9dz1Ss69YQ9YM0Qn87EfOBfWqnE0IIIa5SXethxTv7MRkN/KBnfMBsp/Ztbk2MJMRqprD4PCfPyb7D38asdgAAFAVTQT6WrR8S/P5mgj7eA4A3Lh7nU89Qk/UwhISoHFJci+f7fSn7cCfB69YQ8sLvsa59G+vat/Gk3IJr2M9wp9+H545eYNbGpSaEaLv7p/5d7QhCtMqL6w5wtryW1O7RRAXAIRvNMZuM9PleHNv3fcOq/yliWUq82pE0qdkKxefzMX/+fA4dOoTFYiE7O5vExMTG+9euXcvq1asxm8088sgjDBo0qMUhQh/9NdZ1awBQDAbcAwdRO2YsrqH3gzXwL1bdMxpxjRqDa8RogrZvxZb7FyxbPsC+fCn25Uupu7MXZR/sUDulEEKIDqzwaCmfHy8nOtzK7d2j1Y7jNwnxoSTGO/jieDn/3PUV/W6NVTuS5jRbDH/44Ye43W7WrFnD/v37WbJkCa+88goAJSUl5Obmsn79elwuF5mZmfTv3x9LCw/AqOvTD8xm3AMH4R54D0pMTOs+G6Euo5G6e+6l7p57wenEsu1DLDu244uLUzuZEEK0i4a+4T8/dY/KSURTyqvc/OkfhRgMcE/vbpiMgd0ecaU+t8VzsrSaP/39UxzBd9AzqeO8GbgezRbDeXl5DBgwAIA777yT/Pz8xvsOHjxIr169sFgsWCwWEhISKCoqIjU19Vs/XmRkCGaz6fIbp08G4EavAcfGaru/WMv52pwtNhSSsmB8FgD2G5BJCCGEaKmq2jpefOcAZU43aSkxxEWGUOmsVTuWX9mCzQzq1ZUP9x5nxbv5TMu4k+5dw9WOpRnNFsNOpxOH4+IefCaTCY/Hg9lsxul0Ehp6sWiy2+04nc4mP97589VtiHv9YmNDKSnR7h64Ws7nr2xafjMghLia7J7w7S792sgqsXacOFvFH979lNOl1XTvGkaPpCi1I6kmPiqEn/RN5L3dR1ny1idM/FkPet8qP7mF6yiGHQ4HVVUXJxB9Ph/mC8NQV95XVVV1WXEshBBC36QAFnq1t+gMr24qwONV6JEURVpKTMDvHtGc5K7h/DitK/974Bty/pbP4LSb+Gm/hA4xTNiUZovhtLQ0tm3bxtChQ9m/fz8pKSmN96WmpvLCCy/gcrlwu90cOXLksvuFEEK0TXNDzEK0l9YM0JeWljJt2jRqa2uJi4tj8eLF2Gw2P+VVOFtew9dnnOwpPM3eQyWYTQYG3tmFxE6yUNegW5yD+/om8PFnZ9jyyXG27jvO7cnR/PD2zqQkRBAW0rK5r0DQbDGcnp7Orl27yMjIQFEUFi1axKpVq0hISGDw4MFkZWWRmZmJoig8+eSTBAcH+yO3EEJ0CE0NMbcnWRFuvSu/dnptm2jNAH1OTg7Dhg3jgQce4NVXX2XNmjWMGzeuxc/tcnupcXvwehW8Ph9en4LXq+D2+Khxeahxeah2eThXXsvJc1WcLK3mdGk1Hq/S+DGiw63079mJiFCpS64UFWbl3u/fxJETFXx+vJyDR85x8Mi5C/cFExdhIzbCRlxk/e9hIRaCgoxYzCYsZiMGowEDYDCAAQMNC+4Gg+HCbfV31v9+4b4Lz20yGgmxamu71WbTGI1GFixYcNlt3bt3b/zvUaNGMWrUqBufTAghRJNDzG0lBa9/XOvrrIcCuTUD9Hl5eUycOBGAH/3oRyxfvrzFxfDJc1XM+/PHeLy+6/5/zCYD4fZgwh0Wwu0W4qNCiI2wdvi2iKaYjEZSukWQ0i2C85W1FJ9ycq68lvOVLoqOlVF0rKzdnvvhobcyILVLu338lvJ7ae7PoSmtD2hpOZ+WswnRkTQ1xHwtLfm3u2nZz9ucT2jLjXztbs0A/aW32+12KiubH8a+MnNsbCgb/uv+G/RZCNE8TR7HLIQQol5TQ8xCtKfWDNBfentVVRVhYWH+DS1EK0gxLIQQGpaWlsbOnTsBrhpiFqI9NXXtpaamkpeXh8vlorKysnGAPi0tjR076k8c3blzJ3fddZcq2YVoCYOiKErzDxNCCKGGhon+w4cPNw4xXzq3IUR7uda1t3PnzsYB+rVr17JmzRoURWHixIkMGTKEs2fPMnPmTKqqqoiMjGTZsmWEhISo/akI0SQphoUQQgghRIclbRJCCCGEEKLDkmJYCCGEEEJ0WFIMCyGEEEKIDitgi+HKykomTZrE2LFjGT16NPv27VM7Ej6fj7lz5zJ69GiysrIoLi5WO9Jl6urqmD59OpmZmYwYMYItW7aoHUkIoSFaeg37xS9+QVZWFllZWTz99NN+f/4DBw6QlZUFQHFxMWPGjCEzM5N58+bh813/YRE3MkdBQQEDBgxo/Lps3rzZbzm0TkvXrj9p5TrVuoDdrHLVqlX069ePcePG8eWXXzJ16lQ2bNigaia1jlW9Xhs3biQiIoKlS5dy/vx5hg8fzuDBg9WOJYTQCK28hrlcLgByc3P9/twAr732Ghs3bsRmswGwePFiJk+eTN++fZk7dy5btmwhPT3d7zkKCwt5+OGHGT9+fLs/t95o5dr1J61cp3oQsCvD48aNIyMjAwCv10twsPpnk7fnsao3wn333ccTTzzR+GeTyaRiGiGE1mjlNayoqIiamhrGjx/PQw89xP79+/36/AkJCbz88suNfy4oKKBPnz5A/RHEH330kSo58vPz2b59Ow8++CCzZs3C6XT6JYceaOXa9SetXKd6EBDF8DvvvMOwYcMu+3X06FGsVislJSVMnz6dKVOmqB3zW4+21Aq73Y7D4cDpdPL4448zefJktSMJITREK69hVquVCRMm8Prrr/O73/2OadOm+TXHkCFDLjsFUFEUDAYDcP1HELdHjtTUVGbMmMFbb71Ft27dWLFihV9y6IFWrl1/0sp1qgcB0SYxcuRIRo4cedXthw4dYsqUKcyYMaPx3ZCa9HCs6smTJ3n00UfJzMzk/vvlbHghxEVaeQ1LSkoiMTERg8FAUlISERERlJSU0LlzZ79nATAaL64rqXkEcXp6euNzp6ens3DhQlVyaJFWrl01aeU61aKAWBm+li+++IInnniCZcuWMXDgQLXjANo/VvXs2bOMHz+e6dOnM2LECLXjCCE0RiuvYevWrWPJkiUAnD59GqfTSWxsrCpZAG677Tb27NkD1B9B3Lt3b1VyTJgwgYMHDwKwe/duevTooUoOLdLKtasmrVynWhSwb4uWLVuG2+3m2WefBerfFardLJ+ens6uXbvIyMhoPNpSS1auXElFRQU5OTnk5OQA9Q34VqtV5WRCCC3QymvYiBEjePrppxkzZgwGg4FFixapuso3c+ZM5syZw/Lly0lOTmbIkCGq5Jg/fz4LFy4kKCiImJgYWRm+hFauXTVp5TrVIjmOWQghhBBCdFgB2yYhhBBCCCFEc6QYFkIIIYQQHZYUw0IIIYQQosOSYlgIIYQQQnRYUgwLIYQQQogOS4phIYQQQgjRYUkxLIQQQgghOqz/BzCDGC36P6jTAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dqBG210rw3Iq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exponential Distribution\n",
        "- **For exponential distribution, the probability function is:**\n",
        "$$\n",
        "\\rho_{exponential}(t) = \\dfrac{ e^{-\\frac{t}{\\tau}} }{ \\tau } \\mbox{ for } t \\geq 0\n",
        "$$\n",
        "- Mean is $\\tau$\n",
        "- Std is $\\sigma = \\tau$\n",
        "- From scipy.stats import expon\n",
        "    - expon.pdf to generate pdf <br>\n",
        "  \n",
        "#### Probability Density Function:\n",
        "- Probability that our random variable $X$ will be a specific value $x$\n",
        "$$PDF(x)=\\lambda e^{-\\lambda x}$$\n",
        "\n",
        "- $\\lambda$  = **decay parameter**(a.k.a. $m$)\n",
        "    \n",
        "$$\\lambda = \\frac{1}{\\mu}$$\n",
        "\n",
        "#### Cumulative Density Function:\n",
        "\n",
        "$$CDF(x) = 1 - e^{-\\lambda x}$$\n",
        "- distribution is unique:\n",
        "    - $\\sigma = \\mu$\n",
        "  \n",
        "#### Generate expoenential distribution"
      ]
    },
    {
      "metadata": {
        "id": "19srlQPMw3Ir",
        "colab_type": "code",
        "outputId": "877a13d5-1f0c-4885-fc6d-2c63b1800053",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Generate Expon Distibution\n",
        "from scipy.stats import expon\n",
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(0, 10, 0.001)\n",
        "plt.plot(x, expon.pdf(x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x175acc0bba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kfcCbLb7w3It",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "    \n",
        "### Poisson Distribution\n",
        "- Allows us to calculate the prob of a given event by examining the mean number of events that happen in a given time period. \n",
        "    - Described by parameters:\n",
        "        - $\\mu$:average # of successes over given time period \n",
        "        - $x$:our random variable - the number of successes we want to find the pmf for. \n",
        "- Probability mass function gives way to predict the odds of getting another value instead, on a given future day/interval\n",
        "$$P(X) = \\frac{\\lambda^x e^{-\\lambda}}{X!}$$\n",
        "- $\\lambda$ is average # of successful events\n",
        "- $X\\$ is  number of successes\n",
        "- scipy.stats.poisson\n",
        "#### Generate Poisson Disbtribution"
      ]
    },
    {
      "metadata": {
        "id": "dtyN0GXew3Iu",
        "colab_type": "code",
        "outputId": "2578a283-85f3-4310-a8cf-b218f95fb8fe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generate poisson distribution\n",
        "from scipy.stats import poisson\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "mu = 500\n",
        "x = np.arange(400, 600, 0.5)\n",
        "plt.plot(x, poisson.pmf(x, mu))\n",
        "plt.axvline(550, color= 'g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x175acae4e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "CnuN9U_Dw3Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Distribution Cheat Sheet\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/k6qgj702dwn7vfr/distribution%20cheatsheet.jpg?raw=1\" width=800>"
      ]
    },
    {
      "metadata": {
        "id": "XtsXDMrHw3Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Negative binomial distribution\n",
        "#### Negative binomial trials \n",
        "- Describes number of failures\n",
        "\n",
        "#### Negative binomial distribution describes the ways negative binomial trials \n",
        "- Describes the of successes $k$ until observing a pre-determined # of failures $r$ for $x$ trials, where the probability for success for each independent trial is $p$.\n",
        "- Calculating **Negative Binomial Probability** by multiplying binomial probability by the probabiltiy of failure on trial x:\n",
        "    - $P^r∗(1−P)^{x−r}$\n",
        "$$b(x, r, P) =\\  _{x-1}C_{\\ r-1} * P^{\\ r} * (1-P)^{\\ x-r}  $$\n",
        "\n",
        "where C is the binomial distribution equation $$_{x-1}C_{\\ r-1}$ = \\frac{(x-1)!}{((n-1)-(r-1))!(r-1)!}$$.  \n",
        "\n",
        "#### Characteristics of Negative Binomial Distribution:\n",
        "\n",
        "- **_mean_**:\n",
        "\n",
        "$$\\mu = \\frac{r}{p}$$\n",
        "\n",
        "- **_variance_**:\n",
        "\n",
        "$$\\sigma^2 = \\frac{r\\ (1-p)}{p^{\\ 2}}  $$"
      ]
    },
    {
      "metadata": {
        "id": "NbrX3dQtw3Ix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Geometric Distribution\n",
        "- Geometric = Repeated trials, but examines the probability that the first success will occur on trial n.\n",
        "- Same constraints as negative binomal dist:\n",
        "    -Multiple trials \n",
        "    - Outcome is binary\n",
        "    - Prob success same across trials\n",
        "    - Trials are independent \n",
        "- **Geometric Distribution Equation:**\n",
        "$$P(X=x) = q^{(x\\ -\\ 1)}p$$\n",
        "\n",
        "Where $$q = 1 - p$$\n",
        "\n",
        "- $X$ denotes the _Discrete Random Variable_,\n",
        "- $x$ the trial that we want to calculate the *Geometric Probability*\n",
        "- $p$ the probability of failure for a given trial\n",
        "- $q$ (1-p) is probability for success for given trial \n",
        "\n",
        "- **If p == q (equal prob), equation simplifies:\n",
        "$$P(X=x) = q^x$$"
      ]
    },
    {
      "metadata": {
        "id": "xPqhsqWpw3Iy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Distribution descriptions  in words\n",
        "**_Binomial Distribution_**: \"I flip a fair coin 5 times. What are the chances that I get heads 0 times? 1 time? 2 times? Etc...\"\n",
        "\n",
        "**_Negative Binomial Distribution_**: I flip a fair coin 5 times. What are the chances it takes me two flips to get heads twice? How about 3 flips to get heads twice? 4 Flips? Etc...\n",
        "\n",
        "The **_Exponential Distribution_** describes the probability distribution of the amount of time it may take before an event occurs.  In a way, it solves the inverse of the problem solves by the Poisson Distribution.\n",
        "\n",
        "The **_Poisson Distribution_** lets us ask how likely any given number of events are over a set interval of time.  \n",
        "\n",
        "The **_Exponential Distribution_** lets us ask how likely the _length of an interval of time_ is before an event occurs exactly once. \n",
        "\n",
        "Another way to think of the Exponential Distribution is as the continuous analogue of the **_Geometric Distribution_**. "
      ]
    },
    {
      "metadata": {
        "id": "VNBGdkb9w3Iy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-G7_Rvf_w3Iz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kolmogorov-Smirnov Test\n",
        "\n",
        "#### Noramlity assumption is important for many models-\n",
        "- Examine with plots:\n",
        "    - qqplots\n",
        "    - boxplot\n",
        "- Test with stats:\n",
        "    - The Shapiro-Wilk test;\n",
        "    - The Anderson-Darling test, and;\n",
        "    - The Kolmogorov-Smirnov test.\n",
        "    \n",
        "#### KS test used observed/empirical CDFs for comparisons:**\n",
        "- Uses CDFs to compare data to either:\n",
        "    - an ideal normal distribtuion for a one-sample KS test\n",
        "    - or another population for a two-sample KS test. \n",
        "- Similar to t-test but is sensitive to changes in the mean, variance, and shape of the data. \n",
        "    \n",
        "<img src=\"https://www.dropbox.com/s/jle5rdzan84qmfj/d.gif?raw=1\" width=400>\n",
        "\n",
        "- **Empirical distribution function:**   \n",
        "    - If X is a random variable with CDF $F(x)=P(X≤x)$ <br>\n",
        "      and  $x1,…,xn$ are i.i.d. random variables sampled from X empirical distribution function.\n",
        "\n",
        "$$\\hat{F}(x) = \\frac{\\text{# of elements in sample} \\leq x}{n} = \\frac{1}{n} \\Sigma_{i=1}^n I(x_i \\leq x) \\tag{1}$$\n",
        "\n",
        "\n",
        "#### One-Sample KS Test\n",
        "- Must provide completely specified theoretical distribution fucntion \n",
        "- Sensitive to mean, variance, shape. \n",
        "- Used to test normality assumption\n",
        "$$\n",
        "d\t   =    \tmax(abs[F_0(X)-F_r(X)])\n",
        "$$\n",
        "where\n",
        "- **d** is the maximum deviation Kolmogorov statistic \n",
        "- **F<sub>0</sub>(X)** = (No.of observations ≤ X)/(Total no.of observations) i.e. the non parametric empirical distribution\n",
        "- **F<sub>r</sub>(X)** = The theoretical frequency distribution of X - parametric (e.g. based on mean value) \n",
        "\n",
        "#### Two-Sample KS test\n",
        "- checks if two **independent** samples have been drawn from the same population, or, equivalently, from two identical populations (X = Y).\n",
        "- compares two **sample** distributions (instead of theoretical)\n",
        "\n",
        "$$d\t   =    \tmax[abs[{F_{n1}(X)-F_{n2}(X)}]]$$\n",
        "- $n_1$ = Observations from first sample.\n",
        "\n",
        "- $n_2$ = Observations from second sampl\n",
        "\n",
        "\n",
        "##### Interpreting d statistics\n",
        "- When the CDF shows large maximum deviation d reflects difference between the two sample distributions.\n",
        "    - Critical value of d for samples where n1=n2 and is ≤ 40, the K-S table for two sample case is used. \n",
        "    - When n1 and/or n2 > 40 then the K-S table for large samples of two sample test should be used.\n",
        "- The null hypothesis is accepted if the calculated value is less than the table value and vice-versa."
      ]
    },
    {
      "metadata": {
        "id": "WS62kvwrw3I0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Gm9In0TWw3I1",
        "colab_type": "code",
        "outputId": "5e6e267f-3b0e-4023-8d59-26960cb66176",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run me!O\n",
        "from IPython.display import HTML, display\n",
        "display(HTML(\"<table><tr><td><img src='https://www.dropbox.com/s/dcug9z684le4813/dists1.png?raw=1' width=600></td><td><img src='https://www.dropbox.com/s/3h6gmpy8iy11z91/dists2.png?raw=1' width=400 ></td></tr></table>\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table><tr><td><img src='https://www.dropbox.com/s/dcug9z684le4813/dists1.png?raw=1' width=600></td><td><img src='https://www.dropbox.com/s/3h6gmpy8iy11z91/dists2.png?raw=1' width=400 ></td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vZXrNZA_w3I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple Linear Regression\n",
        "### Using statsmodels to run Ordinary Least Squares Regressions*"
      ]
    },
    {
      "metadata": {
        "id": "i2qcWV_cw3I4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# TESTING ASSUMPTIONS AND RUNNING LINEAR REGRESSION\n",
        "\\# For all the variables, check if they hold normality assumption\n",
        "for column in data:\n",
        "    data[column].plot.hist(normed=True, label = column+' histogram')\n",
        "    data[column].plot.kde(label =column+' kde')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "![](media/a0ddfd1b41d9348b678840beeb05cd27.png)\n",
        "\n",
        "# [Test linearity assumption] visualize the relationship between the preditors and the target using scatterplots\n",
        "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
        "for idx, channel in enumerate(['TV', 'radio', 'newspaper']):\n",
        "    data.plot(kind='scatter', x=channel, y='sales', ax=axs[idx], label=channel)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "![](media/f216f3686df0bc39bd30a6cd13f45993.png)\n",
        "\n",
        "# Run a simple regression in **statsmodels**\n",
        "# import libraries\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# build the formula\n",
        "f = 'sales\\~TV'\n",
        "\n",
        "# create a fitted model in one line\n",
        "model = smf.ols(formula=f, data=data).fit()\n",
        "model.summary() \\# Will spit out stastics and coefficients, R2\n",
        "\n",
        "## Draw the prediction line from the model with the scatter plot:  \n",
        "# We can use model.predict() functions to predict start and end point of regression line for min and max values in variable]\n",
        "\n",
        "# create a DataFrame with the minimum and maximum values of TV\n",
        "X_new = pd.DataFrame({'TV': [data.TV.min(), data.TV.max()]})\n",
        "print(X_new.head())\n",
        "\n",
        "\\# make predictions for those x values and store them\n",
        "preds = model.predict(X_new)\n",
        "print (preds)\n",
        "\n",
        "\\# first, plot the observed data and the least squares line\n",
        "data.plot(kind='scatter', x='TV', y='sales')\n",
        "plt.plot(X_new, preds, c='red', linewidth=2)\n",
        "plt.show()\n",
        "```\n",
        "![](media/79706ce0909dbf6a29f02a441cc4dd4a.png)\n",
        "\n",
        "```python\n",
        "# Visualize the error term for variance and heteroscedasticity:\n",
        "fig = plt.figure(figsize=(15,8))\n",
        "fig = sm.graphics.plot_regress_exog(model, \"TV\", fig=fig)\n",
        "plt.show()\n",
        "```\n"
      ]
    },
    {
      "metadata": {
        "id": "X9isALZvw3I5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](media/8b847a77d81a31166697e6c519f543c6.png)\n",
        "\n",
        "**For the four graphs we see above:**\n",
        "\n",
        "-   The “Y and Fitted vs. X” graph plots the dependent variable against our\n",
        "    predicted values with a confidence interval. The positive relationship shows\n",
        "    that height and weight are correlated correlated, i.e., when one variable\n",
        "    increases the other increases.\n",
        "\n",
        "-   The “Residuals versus height” graph shows our model's errors versus the\n",
        "    specified predictor variable. Each dot is an observed value; the line\n",
        "    represents the mean of those observed values. Since there's no pattern in\n",
        "    the distance between the dots and the mean value, the OLS assumption of\n",
        "    homoskedasticity holds.\n",
        "\n",
        "-   The “Partial regression plot” shows the relationship between height and\n",
        "    weight, taking in to account the impact of adding other independent\n",
        "    variables on our existing height coefficient. We'll see later how this same\n",
        "    graph changes when we add more variables.\n",
        "\n",
        "-   The Component and Component Plus Residual (CCPR) plot is an extension of the\n",
        "    partial regression plot, but shows where our trend line would lie after\n",
        "    adding the impact of adding our other independent variables on the weight.\n",
        "    We shall look at this in more detail in multiple regression.\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "czs6nSt4w3I6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Regression Diagnostics in Statsmodels\n",
        "- We’ve already used R2 value (from ols model.summary()) and visualization to confirm if the data and residuals fit the assumptios. Here we will learn procedures to further understand our model and results.\n",
        "\n",
        ">   *Regression diagnostic is a set of procedures available for regression\n",
        ">   analysis that seek to assess the validity of a model in any of a number of\n",
        ">   different ways. This assessment may be an exploration of the model's\n",
        ">   underlying statistical assumptions, an examination of the structure of the\n",
        ">   model by considering formulations that have fewer, more or different\n",
        ">   explanatory variables, or a study of subgroups of observations, looking for\n",
        ">   those that are either poorly represented by the model (outliers) or that\n",
        ">   have a relatively large effect on the regression model's predictions.*\n",
        ">   [Wiki](https://en.wikipedia.org/wiki/Regression_diagnostic)"
      ]
    },
    {
      "metadata": {
        "id": "z6YFE_xCw3I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Q-Q Plots to check normality (also called normal density plots when used with standard normal quantiles)\n",
        "\n",
        "- These plots are good way to inspect the distribution of model errors."
      ]
    },
    {
      "metadata": {
        "id": "ecuBP1Uvw3I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.api as sms\n",
        "import statsmodels.formula.api as smf\n",
        "import scipy.stats as stats\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "data = pd.read_csv('Advertising.csv', index_col=0)\n",
        "f = 'sales\\~TV' \n",
        "f2 = 'sales\\~radio' \n",
        "model = smf.ols(formula=f, data=data).fit() \n",
        "model2 = smf.ols(formula=f2, data=data).fit() \n",
        "resid1 = model.resid \n",
        "resid2 = model2.resid \n",
        "\n",
        "fig = sm.graphics.qqplot(resid2, dist=stats.norm, line='45', fit=True) \n",
        "fig.show() \n",
        "```\n",
        "~~img src=\"media/9707e080f47e37b45f414bc7adcf1ad0.png\" width=400>~~"
      ]
    },
    {
      "metadata": {
        "id": "Titc7cdew3I8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normal Q-Q Plots are a direct visual assessment of how well our residuals\n",
        "match what we would expect from a normal distribution.**\n",
        "\n",
        "In terms of Q-Q plots above, we can see that residuals are better normally\n",
        "distributed in the case of TV than that of radio. We can also spot an outlier in\n",
        "the left tail of radio residuals, dealing with this might help improve the\n",
        "fitness of the model. Outliers, skew, heavy and light-tailed aspects of\n",
        "distributions (all violations of normality) can be assessed from Q-Q plots\n",
        "\n",
        "-   Example Q-Q plots vs histogram/density plot (to help learn what Q-Q plot is\n",
        "    saying:\n",
        "<img src=\"media/bea1c75ce827d7327861c28b229667b2.png\" width=600>\n"
      ]
    },
    {
      "metadata": {
        "id": "8mzckl1uw3I9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression*\n",
        "\n",
        "\n",
        "### HOW TO: BLOG POST ON LINEAR REGRESSION IN PYTHON:\n",
        "\n",
        "<https://www.dropbox.com/s/bzg4o8ndtu70byg/Linear%20Regression%20in%20Python%20-%20Blog%20Post.pdf?dl.0=0>\n",
        "\n",
        "- Step 1: visualization\n",
        "    1.  Look for linear relationship – use Seaborn’s pairplot sns.pairplot(data, x_vars = [b1,b2,b3], y_vars=’Sales’,kind=’reg’)  \n",
        "        \\# Note, can also pass ‘size= “ for change plot size.  \n",
        "        \\# kind = ‘reg’ attempts to add line of best fit and 95% confidence interval (will aim to minimize the sum of squared error)\n",
        "\n",
        "- Step 2: SK Learn – Setting Variables\n",
        "    1.  Scikit-Learn expects X to be a ‘feature matrix’ (Pandas DataFrame) and y to be a ‘response vector’\n",
        "    2.  X=dataframe. y = y from the dataframe\n",
        "    \n",
        "- Step 3: SK Learn – Splitting our data\n",
        "```python\n",
        "from sklearn.cross_validation import test_train_split  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "```\n",
        "- Step 4: SK Learn – Training our model\n",
        "\n",
        "```python \n",
        "# Import linear regression and instantiate  \n",
        "from sklearn.linear_model import LinearRegression  \n",
        "linreg = LinearRegression()  \n",
        "\n",
        "# Fit model to training data  \n",
        "linrg.fit(X_train, y_train)\n",
        "```\n",
        "- Step 5: Interpreting Coefficients\n",
        "```python \n",
        "print(lingreg.intercept_) \\# prints y-intercept, BO  \n",
        "print(linreg.coef_) \\# prints beta coeffiicents in same order as passed  \n",
        "zip(feature_cols, linreg.coef_) \\# Pair feature names and coefficients\n",
        "```\n",
        "- Step 6: Making predictions  \n",
        "```python\n",
        "y_pred = linreg.predict(X_test)\n",
        "```\n",
        "- Step 7: Model Evaluation  \n",
        "```python \n",
        "from sklearn import metrics  \n",
        "\\# Most popular metric to use is root-mean-square-error (RMSE)  \n",
        "print(np.sqrt(metrics.mean_squared_error(y_true, y_pred)))  \n",
        "\\#People also use Mean Absolute Error or Mean-Squared Error, but harder to interpret\n",
        "```\n",
        "- Step 8: Feature selection:\n",
        "\n",
        "    1.  Once have error metric, take note which X’s have minimal impact on y.\n",
        "        1.  Removing some of these may increase the accuracy of the model\n",
        "    2.  Now, process of trial and error, starting over again (dropping columns) until reach a satisfactory model\n",
        "    3.  Recommended Steps:\n",
        "        1.  Replace feature_cols & X\n",
        "        2.  Train_test_split your data\n",
        "        3.  Fit the model to linreg again using linreg.fit\n",
        "        4.  Make predictions using (y_pred = linreg.predict(X_test))\n",
        "        5.  Compute RMSE\n",
        "        6.  Repeat until RMSE satisfactory"
      ]
    },
    {
      "metadata": {
        "id": "NHvNraTZw3I9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Code from: FEATURE SCALING AND NORMALIZATION LAB:\n",
        "\n",
        "1.  Performing binning / as categories for numerical categorical variables for\n",
        "    regression, create dummy variables ( and replace orig):\n",
        "    \n",
        "```python\n",
        "# first, create bins for based on the values observed. 5 values will result\n",
        "in 4 bins\n",
        "\n",
        "bins = [0, 3, 4 , 5, 24]\n",
        "bins_rad = pd.cut(boston_features['RAD'], bins)\n",
        "bins_rad = bins_rad.cat.as_unordered()\n",
        "\n",
        "# first, create bins for based on the values observed. 5 values will result in 4 bins\n",
        "\n",
        "bins = [0, 250, 300, 360, 460, 712]\n",
        "bins_tax = pd.cut(boston_features['TAX'], bins)\n",
        "bins_tax = bins_tax.cat.as_unordered()\n",
        "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\")\n",
        "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\")\n",
        "\n",
        "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n",
        "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)\n",
        "boston_features = boston_features.drop(\"NOX\",axis=1)\n",
        "```\n",
        "\n",
        "2.  Filtering out the columns of a dataframe using drop, filter, and regex :\n",
        "\n",
        "```python \n",
        "df= boston_features\n",
        "boston_cont = df[df.columns.drop(list(df.filter(regex='TAX')))]\n",
        "boston_cont = boston_cont[boston_cont.columns.drop(list(boston_cont.filter(regex='RAD')))]\n",
        "boston_cont= boston_cont.drop(['CHAS'], axis=1)\n",
        "```\n",
        "\n",
        "3.  Different Tpes of transformations on the dataframe:\n",
        "\n",
        "```python\n",
        "data_log = df_log\n",
        "age = boston_cont[\"AGE\"]\n",
        "b = boston_cont[\"B\"]\n",
        "rm = boston_cont[\"RM\"]\n",
        "logcrim = data_log[\"CRIM\"]\n",
        "logdis = data_log[\"DIS\"]\n",
        "logindus = data_log[\"INDUS\"]\n",
        "loglstat = data_log[\"LSTAT\"]\n",
        "logptratio = data_log[\"PTRATIO\"]\n",
        "features_final= pd.DataFrame([])\n",
        "\n",
        "features_final[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n",
        "features_final[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
        "features_final[\"RM\"] = (rm-min(rm))/(max(rm)-min(rm))\n",
        "features_final[\"DIS\"] = (logdis-np.mean(logdis))/np.sqrt(np.var(logdis))\n",
        "features_final[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n",
        "features_final[\"LSTAT\"] = (loglstat-np.mean(loglstat))/(max(loglstat)-min(loglstat))\n",
        "features_final[\"AGE\"] = (age-np.mean(age))/(max(age)-min(age))\n",
        "features_final[\"PTRATIO\"] = (logptratio)/(np.linalg.norm(logptratio))\n",
        "```\n",
        "### Code from: Regression modeling with Boston Housing Dataset\n",
        "\n",
        "![](media/05194d71a28f0a54e57e63ea704f485b.png)\n",
        "\n",
        "```python\n",
        "\\# Your code here\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import scipy.stats as stats\n",
        "import statsmodels.stats.api as sms\n",
        "\n",
        "# The results will be saved in results list\n",
        "results = [['ind_var','r_sqared','intercept','slope','p-value','norm_JB']]\n",
        "\n",
        "# TO LOOP THROUGH LIST OF DATACOLUMNS TO RUN OLS REGRESSION + PRINT/SAVE RESULTS*\n",
        "for idx, val in enumerate(['crim','dis','rm','zn','age']):\n",
        "    print (\"Boston Housing DataSet - Regression Analysis and Diagnostics for\n",
        "    formula: medv\\~\" + val)\n",
        "\n",
        "    print\n",
        "    (\"-------------------------------------------------------------------------------------\")\n",
        "\n",
        "    f = 'medv\\~' + val\n",
        "    model = smf.ols(formula=f,data=data).fit()\n",
        "    X_new = pd.DataFrame({val: [data[val].min(),data[val].max()]}\n",
        "    preds= model.predict(X_new)\n",
        "\n",
        "    data.plot(kind='scatter',x=val,y='medv')\n",
        "    plt.plot(X_new,preds,c='red',linewidth=2)\n",
        "    plt.show()\n",
        "\n",
        "    fig=plt.figure(figsize=(15,8))\n",
        "    fig = sm.graphics.plot_regress_exog(model, val, fig=fig)\n",
        "    fig = sm.graphics.qqplot(model.resid,dist=stats.norm, line='45',fit=True )\n",
        "    plt.show\n",
        "                         \n",
        "    results.append([val,model.rsquared,model.params[0],model.params[1],model.pvalues[1],sms.jarque_bera(model.resid)[0]])\n",
        "    input('Press Enter to continue...')\n",
        "```\n",
        "### Code from: Dealing with categorical variables lab\n",
        "```python\n",
        "# Get list of column names (to use for plotting from df)*\n",
        "names = boston_df.columns\n",
        "nameList = [str(x) for x in names]\n",
        "col_names = nameList[1:]\n",
        "print(col_names)\n",
        "\n",
        "# Loop through each column to plot\n",
        "for col in col_names:\n",
        "plt.figure()\n",
        "plt.scatter(boston_df[col],boston_df['MEDV'],label=col,marker='.')\n",
        "plt.legend()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "o7U20CLWw3I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### REGRESSION MODEL VALIDATION\n",
        "\n",
        "- using train-test-split\n",
        "\n",
        "![](media/480152d587e701dde0f1599c9d684426.png)"
      ]
    },
    {
      "metadata": {
        "id": "1dN0DugIw3I_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Using train-test-split from sklearn*\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression  \n",
        "lingreg=LinearRegression(X_train, y_train)\n",
        "\n",
        "y_hat_train = linreg.predict(X_train)  \n",
        "y_hat_test = linreg.predict(X_test)\n",
        "\n",
        "train_residuals = y_hat_train – y_train  \n",
        "test_residuals = y_hat_test – y_test\n",
        "\n",
        "mse_train = np.sum((y_train – y_hat_train)\\*\\*2/len(y_train)  \n",
        "mse_test = np.sum((y_test – y_hat_test)\\*\\*2/len(y_test)\n",
        "```\n",
        "\n",
        "**Select columns using regex**\n",
        "```python\n",
        "df.filter(regex=('Mark'),axis=1).describe()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Bj5Y_43tw3I_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## OUR FIRST EXAMPLE COMPLETE PROJECT (Section 12)\n",
        "\n",
        "### Modeling Our Data Lab/Lesson:\n",
        "\n",
        "-   Load in pre-cleaned file\n",
        "    -   This is after having cleaned the dataset and made dummy variables.\n",
        "    -   Must re-cast categories as categories when reloading data\n",
        "\n",
        "-   If there are a lot of possible predictors, should try starting with single\n",
        "    linear regressions (on CONTINUOUS)\n",
        "    -   Using statsmodels.formula.api as smf\n",
        "    \n",
        "```python\n",
        "\n",
        "import statsmodels.formula.api as smf  \n",
        "# .describe used to select non-categorical values, then drop target var\n",
        "col_names = dataframe.describe().columns.drop(['Target_Var'])                                             \n",
        "results = [['ind_var', 'r_squared', 'intercept', 'slope', 'p-value' ]]                                               \n",
        "                                               \n",
        "# Use loop to run ols model with f=’Target_Variable\\~’+val\n",
        "for idx, val in enumerate(col_names):\n",
        "\n",
        "    print (\"Walmart: Weekly_Sales\\~\" + val)\n",
        "    print (\"------------------------------\")\n",
        "\n",
        "    f = 'Weekly_Sales\\~' + val\n",
        "    model = smf.ols(formula=f, data=walmart).fit()\n",
        "\n",
        "    X_new = pd.DataFrame({val: [walmart[val].min(), walmart[val].max()]})\n",
        "    preds = model.predict(X_new)\n",
        "\n",
        "    results.append([val, model.rsquared, model.params[0], model.params[1], model.pvalues[1] ])\n",
        "    print(results[idx+1])                    \n",
        "                                               \n",
        "pd.DataFrame(results)\n",
        "                                               \n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "pqLDDq3Rw3JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- **Examine outputs:**\n",
        "\n",
        "        -   What do the parameter estimates mean? Do they make sense?\n",
        "        -   What do the p-values tell us?\n",
        "        -   What does the R-squared tell us?\n",
        "\n",
        "    -   If poor R-squared, re-examine distributions\n",
        "        -   Dataframe.hist()\n",
        "        \n",
        "    -   If skewed data can log transform:\n",
        "        -   If negative data:\n",
        "        ```python\n",
        "            -   walmart_log= walmart[walmart[\"Weekly_Sales\"]\\ 0]\n",
        "            -   walmart_log[\"Weekly_Sales\"]= np.log(walmart_log[\"Weekly_Sales\"])\n",
        "        ```\n",
        "-   **Re-run loop from earlier:**\n",
        "\n",
        "    -   compare and constrast the results with the results obtained when we did not take the log(sales)\n",
        "        -   Which one would you want to proceed with based on this?\n",
        "\n",
        "-   Build a model with each category variable as a predictor (can re-run data vs data-log, re-examine the R-square output)\n",
        "    -   Put all categories for one categorical variable in 1 model (so 4 models if 4 different categorical variables\n",
        "        -   IF USED DUMMY CODES, MUST DROP 1 FOR BETTER RESULTS (not explained)\n",
        "    -   Use output to judge choice of data vs data_log.\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "26yQIuG2w3JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "-   **Use the model results to identify variables that we can drop from the\n",
        "    model.**\n",
        "\n",
        "    -   Can do manually (drop from dataframe and re-run)\n",
        "    -   **Can Use RECURSIVE FEATURE ELIMINATION FOR X NUMBER OF FEATURES**\n",
        "\n",
        "        -   Create a for loop (below is 5-\\ 85 by 10’s)\n",
        "        \n",
        "```python\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linreg = LinearRegression()\n",
        "r_list = []\n",
        "adj_r_list = []\n",
        "list_n = list(range(5,86,10))\n",
        "for n in list_n:\n",
        "    select_n = RFE(linreg, n_features_to_select = n)\n",
        "    select_n = select_n.fit(X, np.ravel(y))\n",
        "    selected_columns = X.columns[select_n.support\\_ ]\n",
        "\n",
        "    linreg.fit(X[selected_columns],y)\n",
        "    yhat = linreg.predict(X[selected_columns])\n",
        "\n",
        "    SS_Residual = np.sum((y-yhat)\\*\\*2)\n",
        "    SS_Total = np.sum((y-np.mean(y))\\*\\*2)\n",
        "\n",
        "    r_squared = 1 - (float(SS_Residual))/SS_Total\n",
        "    print(r_squared)\n",
        "\n",
        "    adjusted_r_squared = 1 - (1-r_squared)\\*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
        "    print(adjusted_r_squared)\n",
        "    r_list.append(r_squared)\n",
        "    adj_r_list.append(adjusted_r_squared)\n",
        "```\n",
        "\n",
        "> “What we see is that both MSE keeps improving when we add variables. It seems like a bigger model improves our performance, and the test and train performance don't really diverge. It is important to note however that is not an unusual result. The performance measures used typically will show this type of behavior. In order to really be able to balance the curse of dimensionality (which will become more important in machine learning), we need other information criteria such as AIC and BIC. You'll learn about them later! Now, let's perform cross-validation on our model with 85 predictors!”\n",
        "\n",
        "-   Can do a 10-fold cross validation with the final model.\n",
        "```python\n",
        "        from sklearn.metrics import mean_squared_error\n",
        "        from sklearn.model_selection import cross_val_score\n",
        "        # select 85 best predictors\n",
        "        select_85 = RFE(linreg, n_features_to_select = 85)\n",
        "        select_85 = select_n.fit(X, np.ravel(y))\n",
        "        selected_columns = X.columns[select_n.support_]\n",
        "        cv_10_results = cross_val_score(linreg, X[selected_columns], y, cv=10,\n",
        "        scoring=\"neg_mean_squared_error\")\n",
        "        cv_10_results\n",
        "```\n",
        "> “Running our 10-fold cross-validation highlights some issues for sure! Have a look at your list of 10 MSEs. Where most MSEs are manageable, some are very high. The cure of dimensionality is already pretty clear here. The issue is that we have many (dummy) categorical variables that result in columns with many zeroes and few ones. This means that for some folds, there is a risk of ending up with columns that almost exclusively contain 0's for prediction, which might\n",
        "cause weird results. Looking at this, a model with less predictors might make sense again. This is where we conclude for now. It's up to you now to explore other model options! Additionally, it is encouraged to try some of the \"level up\" exercises below. Good luck!”"
      ]
    },
    {
      "metadata": {
        "id": "Fd5Spg6Iw3JB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MOD 1 FINAL PROJECT Workflow Notes (section12)\n",
        "\n",
        "### Order of Processing (using OSEMN model)\n",
        "1.  **OBTAIN: Import data, inspect, check for datatypes to convert and null\n",
        "    values**\n",
        "\n",
        "    -   Display header and info\n",
        "\n",
        "    -   Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
        "\n",
        "2.  **SCRUB: cast data types, identify outliers, check for multicollinearity,\n",
        "    normalize data**\n",
        "\n",
        "    -   Check and cast data types\n",
        "\n",
        "        -    Check for \\#'s that are store as objects (df.info())\n",
        "\n",
        "            -   when converting to \\#'s, look for odd values (like many 0's), or\n",
        "                strings that can't be converted\n",
        "\n",
        "            -   Decide how to deal weird/null values (df.unique(),\n",
        "                df.isna().sum(), df.describe()-min/max, etc\n",
        "\n",
        "        -    Check for categorical variables stored as integers (for now cast as\n",
        "            strings)\n",
        "\n",
        "    -   Check for missing values (df.isna().sum())\n",
        "\n",
        "        -   Can drop rows or colums\n",
        "\n",
        "        -   For missing numeric data with median or bin/convert to categorical\n",
        "\n",
        "        -   For missing categorical data: make NaN own category OR replace with\n",
        "            most common category\n",
        "\n",
        "    -   Check for multicollinearity\n",
        "\n",
        "        -   use seaborn to make correlation matrix plot [Evernote\n",
        "            Link](https://www.evernote.com/l/AArNyaEwjA5JUL6I9PazHs_ts_hU-m7ja1I/)\n",
        "\n",
        "            -   Good rule of thumb is anything over 0.75 corr is high, remove\n",
        "                the variable that has the most correl with the largest \\# of\n",
        "                variables\n",
        "\n",
        "    -   Normalize data (may want to do after some exploring)\n",
        "\n",
        "        -   Most popular is Z-scoring (but won't fix skew)\n",
        "\n",
        "        -   Can log-transform to fix skewed data\n",
        "\n",
        "3.  **EXPLORE: Check distributions, outliers, etc**\n",
        "\n",
        "    -   Check scales, ranges (df.describe())\n",
        "\n",
        "    -   Use histograms to get an idea of distribut(df.hist())\n",
        "\n",
        "        -   Can also do kernel density estimates\n",
        "\n",
        "    -    use scatterplots to check for linearity and possible categorical\n",
        "        variables (df.plot(kind-'scatter')\n",
        "\n",
        "        -   categoricals will look like vertical lines\n",
        "\n",
        "    -    Use pd.plotting.scatter_matrix to visualize possible relationships\n",
        "\n",
        "    -   ADVANCED pair-wise comparison\n",
        "        via [joint-plots](https://seaborn.pydata.org/generated/seaborn.jointplot.html)\n",
        "\n",
        "        -   ns.jointplot(x= \\<column\\>, y= \\<column\\>, data=\\<dataset\\>,\n",
        "            kind='reg')\n",
        "\n",
        "    -   **Check for linearity**\n",
        "\n",
        "4.  **Fit an intiial model**\n",
        "\n",
        "    -   Various forms, detail later...\n",
        "\n",
        "    -   **Assessing the model:**\n",
        "\n",
        "        -   Assess parameters (slope,intercept)\n",
        "\n",
        "        -   Check if the model explains the variation in the data (RMSE, F,\n",
        "            R_square)\n",
        "\n",
        "        -   *Are the coeffs, slopes, intercepts in appropriate units?*\n",
        "\n",
        "        -   *Whats the impact of collinearity? Can we ignore?*\n",
        "\n",
        "5.  **Revise the fitted model**\n",
        "\n",
        "    -   Multicollinearity is big issue for lin regression and cannot fully\n",
        "        remove it\n",
        "\n",
        "    -   Use the predictive ability of model to test it (like R2 and RMSE)\n",
        "\n",
        "    -   Check for missed non-linearity\n",
        "\n",
        "6.  **Holdout validation / Train/test split**\n",
        "\n",
        "    -   use sklearn train_test_split"
      ]
    },
    {
      "metadata": {
        "id": "JBmYRi5aw3JB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Regular Expression in Beautiful Soup\n",
        "```python\n",
        "# Import required packages\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas\n",
        "import requests\n",
        "import re\n",
        "\n",
        "\\# Use beautiful soup to get declared url\n",
        "url = 'https://www.azlyrics.com/p/panicatthedisco.html' \\#Put the URL of\n",
        "your AZLyrics Artist Page here!\n",
        "\n",
        "html_page = requests.get(url) \\#Make a get request to retrieve the page\n",
        "soup = BeautifulSoup(html_page.content, 'html.parser') \\#Pass the page contents to beautiful soup for parsing\n",
        "\n",
        "# Print html-nested structured result\n",
        "print(soup.prettify()[:1000])\n",
        "\n",
        "# Get all links that have 'panic'\n",
        "def get_links(soup,str='panic'):\n",
        "link_list=[]\n",
        "for link in soup.find_all('a'):\n",
        "\ttest_link = link.get('href')\n",
        "\n",
        "\tif str in test_link:\n",
        "        link_list.append(test_link)\n",
        "    return link_list\n",
        "\n",
        "# Use function\n",
        "panic_links = get_links(soup,’panic’)\n",
        "\n",
        "# Constructing reg exp to find the last 2 branches of web address (using / ... /... .html), and saves the band and song strings\n",
        "pattern = **r**'\\\\/(?P\\<band\\\\\\w\\*)\\\\/(?P\\<song\\\\\\w\\*).html'\n",
        "exp = re.compile(pattern) \\# the exp is a re object and can be used in methods OR functions.\n",
        "\n",
        "# save a list of the captured band and song tokens O\n",
        "result = []\n",
        "[result.append(exp.findall(x)) for x in panic_links]\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "p8Hkw-0YQuR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hypothesis Testing "
      ]
    },
    {
      "metadata": {
        "id": "L3EDboKNQx01",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The Scientific Method\n",
        "<img src=\"https://www.dropbox.com/s/xcd5832r97ubxs9/The%2BScientific%2BMethod.jpg?raw=1\"  width=400>\n",
        "\n",
        "1. Make an Observation\n",
        "2. Examine the Research\n",
        "3. Form a hypothesis\n",
        "4. Conduct an Experiment\n",
        "5. Analyze Experimental Results\n",
        "6. Draw Conclusions \n",
        "\n",
        "### Foundations of a Sound Experiment\n",
        "1. Control group / random controlled \n",
        "2. Appropriate sample sizes\n",
        "3. Reproducibility\n",
        "\n",
        "### P - Values and Null Hypothesis \n",
        "- Null hypothesis ($H_0$):  There is no relatinship between A and B\n",
        "- Alternative hypothesis ($H_0$): There is a ____ kind of relationship between A & B\n"
      ]
    },
    {
      "metadata": {
        "id": "Ndy04LvyTVk-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://www.dropbox.com/s/wsukib2gmsm5fea/one-sample-discrete-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/vd8j1jtshj5wrj0/two-sample-discrete-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/manaq0po9s7dyho/one-sample-continuous-data.png?raw=1\">\n",
        "<img src=\"https://www.dropbox.com/s/q1dgponudr11tz5/two-sample-continuous-data.png?raw=1\">\n"
      ]
    },
    {
      "metadata": {
        "id": "UOM2QLiWUB7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Effect Sizes\n",
        "- P value = probability sample Means are the same.\n",
        "- (1 – P) or C.L. = probability sample Means are different.\n",
        "- Effect Size = how different sample Means are.\n",
        "    - Large effect sizes are visible even with small samples\n",
        "    - Ideally measured in standardized units\n",
        "\n",
        "\n",
        "### Cohen's $d$/ Hedge's $g$\n",
        "- Cohen's $d$ is the effect size\n",
        "Cohen's $$d = \\frac{(Mean_A - Mean_B)}{Pooedl StDev}$$\n",
        "- Hedge's $g$ is the _corrected effect size_  [See article](https://www.statisticshowto.datasciencecentral.com/hedges-g/)\n",
        "$$Hedges'  g = d \\times (\\frac{N-3}{N-2.25})\\times \\sqrt{ \\frac{N-2}{N}}$$\n",
        " - At small sample sizes (N<20) Hedge's is JUST Cohen's $d$\n",
        " - With large sample sizes (N>20), Hedge's adds the correction.\n",
        " \n",
        "- Interpretation: Rules of Thumb\n",
        "    - Small effect = 0.2 ( cannot be seen by naked eye)\n",
        "    - Medium effect  = 0.5\n",
        "    - Large Effect = 0.8 (can be seen by naked eye)\n",
        "    ___\n",
        "    \n",
        "<img src=\"https://www.dropbox.com/s/bdxp1li38lsqcoy/Effect%20size%20graph.png?raw=1\" width=600>\n",
        "\n",
        "### Power Analysis to Determine Required Sample Size from Effect SIze\n",
        "\n",
        "$$n = (\\frac{Z \\times Group S.D.}{Effect Size})^2 $$\n",
        "\n",
        "- where t-stat or Z Value = Difference in Means/Group Standard Error\n",
        "\n",
        "#### Unstandardized Effect Sizes\n",
        "- **Relative DIfference of means(%):**\n",
        "\n",
        "$\\frac{ M_1 - M_2}{M_1} \\times 100$ \n",
        "\n",
        "\n",
        "- **Simple Overlap Threshold**\n",
        "\n",
        "threshold = $\\frac{M_1+M_2}{2}$\n",
        "___\n",
        "\n",
        "### Overlap Threshold of Prob. Density Functions:** [Use this]\n",
        "\n",
        "$ thresh  = \\frac{(std_1\\times M_2 + std_2\\times M_1)}{(std_1+std_2)}$\n",
        "\n",
        "- Overlap is total **Area Under the Curves** of overlap\n",
        "\n",
        "$overlap = \\frac{(M_1 < T)}{n_1} + \\frac{M_2 >T}{n_2}$\n",
        "\n",
        "where $T$ = threshold\n",
        "    \n",
        "- Missclassification rate = $\\frac{overlap}{2}$\n",
        "\n",
        "### Probability of Superiority\n",
        "-  \"non-parametric\" way to quantify the difference between distributions. The probability that \"a randomly-chosen man is taller than a randomly-chosen woman\"\n",
        "\n",
        "-Overlap (or misclassification rate) and \"probability of superiority\" have two good properties:\n",
        "\n",
        "    - As probabilities, they don't depend on units of measure, so they are comparable between studies.\n",
        "\n",
        "    - They are expressed in operational terms, so a reader has a sense of what practical effect the difference makes.\n",
        "```python    \n",
        "def overlap_superiority(group1, group2, n=1000):\n",
        "\"\"\"Estimates overlap and superiority based on a sample.\n",
        "\n",
        "group1: scipy.stats rv object\n",
        "group2: scipy.stats rv object\n",
        "n: sample size\n",
        "\"\"\"\n",
        "\n",
        "# Get a sample of size n from both groups\n",
        "group1_sample = group1.rvs(n)\n",
        "group2_sample = group2.rvs(n)\n",
        "\n",
        "# Identify the threshold between samples\n",
        "thresh = (group1.mean() + group2.mean()) / 2\n",
        "print(thresh)\n",
        "\n",
        "# Calculate no. of values above and below for group 1 and group 2 respectively\n",
        "above = sum(group1_sample < thresh)\n",
        "below = sum(group2_sample > thresh)\n",
        "\n",
        "# Calculate the overlap\n",
        "overlap = (above + below) / n\n",
        "\n",
        "# Calculate probability of superiority\n",
        "superiority = sum(x > y for x, y in zip(group1_sample, group2_sample)) / n\n",
        "\n",
        "return overlap, superiority\n",
        "```\n",
        "___\n",
        "\n",
        "#### Cohen's d\n",
        "```python\n",
        "def Cohen_d(group1, group2):\n",
        "    # Compute Cohen's d.\n",
        "    # group1: Series or NumPy array\n",
        "    # group2: Series or NumPy array\n",
        "    # returns a floating point number \n",
        "    diff = group1.mean() - group2.mean()\n",
        "\n",
        "    n1, n2 = len(group1), len(group2)\n",
        "    var1 = group1.var()\n",
        "    var2 = group2.var()\n",
        "\n",
        "    # Calculate the pooled threshold as shown earlier\n",
        "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
        "    \n",
        "    # Calculate Cohen's d statistic\n",
        "    d = diff / np.sqrt(pooled_var)\n",
        "    \n",
        "    return d\n",
        "\n",
        "\n",
        "def plot_pdfs(cohen_d=2):\n",
        "    \"\"\"Plot PDFs for distributions that differ by some number of stds.\n",
        "    \n",
        "    cohen_d: number of standard deviations between the means\n",
        "    \"\"\"\n",
        "    group1 = scipy.stats.norm(0, 1)\n",
        "    group2 = scipy.stats.norm(cohen_d, 1)\n",
        "    xs, ys = evaluate_PDF(group1)\n",
        "    pyplot.fill_between(xs, ys, label='Group1', color='#ff2289', alpha=0.7)\n",
        "\n",
        "    xs, ys = evaluate_PDF(group2)\n",
        "    pyplot.fill_between(xs, ys, label='Group2', color='#376cb0', alpha=0.7)\n",
        "    \n",
        "    o, s = overlap_superiority(group1, group2)\n",
        "    print('overlap', o)\n",
        "    print('superiority', s)\n",
        "   \n",
        "```\n",
        "<img src=\"https://www.dropbox.com/s/folsno68jidkroj/output_61_1.png?raw=1\">"
      ]
    },
    {
      "metadata": {
        "id": "fkIrbGw-lAXW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Statistical Power\n",
        "Power = 1 - P (Type II error) = probability of finding an effect that is there\n",
        " - Same as $ \\beta = (1 - \\alpha)$"
      ]
    },
    {
      "metadata": {
        "id": "RqNKY67U2RiI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ff2dCpS8_ikW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# [MODULE 3 NOTEBOOK:](https://colab.research.google.com/drive/1DE6VT590W3xlZGXVf0Vye14stdBMddPd)\n",
        "- Separated notebook 3 from original nb on 04/11/19"
      ]
    },
    {
      "metadata": {
        "id": "7iKbRzNm_pzl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}